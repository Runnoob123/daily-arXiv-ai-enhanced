<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 10]
- [cs.LG](#cs.LG) [Total: 61]
- [cs.CL](#cs.CL) [Total: 49]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.CV](#cs.CV) [Total: 79]
- [stat.AP](#stat.AP) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [eess.SY](#eess.SY) [Total: 2]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.RO](#cs.RO) [Total: 9]
- [stat.ME](#stat.ME) [Total: 2]
- [eess.AS](#eess.AS) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [cs.ET](#cs.ET) [Total: 1]
- [eess.SP](#eess.SP) [Total: 3]
- [nlin.AO](#nlin.AO) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.GR](#cs.GR) [Total: 7]
- [hep-ph](#hep-ph) [Total: 1]
- [math.ST](#math.ST) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [stat.ML](#stat.ML) [Total: 6]
- [eess.IV](#eess.IV) [Total: 13]
- [quant-ph](#quant-ph) [Total: 5]
- [cs.DB](#cs.DB) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.IR](#cs.IR) [Total: 5]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]
- [math.DS](#math.DS) [Total: 2]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models](https://arxiv.org/abs/2505.04784)
*Pedro Pinacho-Davidson,Fernando Gutierrez,Pablo Zapata,Rodolfo Vergara,Pablo Aqueveque*

Main category: cs.CR

TLDR: 提出了一种新的风险评估指标，用于评估生成式AI聊天机器人对组织、用户和第三方的潜在威胁，并通过改进的开源框架验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI和大型语言模型（LLM）的聊天机器人带来新的操作风险，需多维度评估以保障安全性和可靠性。

Method: 结合技术复杂性和上下文因素设计风险评估指标，利用改进的Garak框架测试威胁向量。

Result: 验证了指标的有效性，展示了在检索增强生成（RAG）场景中的应用，强调多维风险评估的重要性。

Conclusion: 多维风险评估对安全可靠的AI驱动对话系统至关重要，需短期缓解和长期改进结合。

Abstract: The emergence of Generative AI (Gen AI) and Large Language Models (LLMs) has
enabled more advanced chatbots capable of human-like interactions. However,
these conversational agents introduce a broader set of operational risks that
extend beyond traditional cybersecurity considerations. In this work, we
propose a novel, instrumented risk-assessment metric that simultaneously
evaluates potential threats to three key stakeholders: the service-providing
organization, end users, and third parties. Our approach incorporates the
technical complexity required to induce erroneous behaviors in the
chatbot--ranging from non-induced failures to advanced prompt-injection
attacks--as well as contextual factors such as the target industry, user age
range, and vulnerability severity. To validate our metric, we leverage Garak,
an open-source framework for LLM vulnerability testing. We further enhance
Garak to capture a variety of threat vectors (e.g., misinformation, code
hallucinations, social engineering, and malicious code generation). Our
methodology is demonstrated in a scenario involving chatbots that employ
retrieval-augmented generation (RAG), showing how the aggregated risk scores
guide both short-term mitigation and longer-term improvements in model design
and deployment. The results underscore the importance of multi-dimensional risk
assessments in operationalizing secure, reliable AI-driven conversational
systems.

</details>

### [2] [Safeguard-by-Development: A Privacy-Enhanced Development Paradigm for Multi-Agent Collaboration Systems](https://arxiv.org/abs/2505.04799)
*Jian Cui,Zichuan Li,Luyi Xing,Xiaojing Liao*

Main category: cs.CR

TLDR: Maris是一种隐私增强的开发范式，通过在多智能体协作系统（MACS）中嵌入参考监视器，有效控制敏感数据泄漏风险。


<details>
  <summary>Details</summary>
Motivation: 多智能体协作系统（MACS）在解决复杂问题时存在敏感数据泄漏风险，现有系统缺乏隐私控制机制。

Method: 提出Maris范式，通过在多智能体对话组件中嵌入参考监视器，实现严格的消息流控制。

Result: Maris在医疗、供应链优化和个性化推荐等隐私关键场景中表现出色，效果和性能开销均令人满意。

Conclusion: Maris为MACS提供了一种实用的隐私保护解决方案，具有较高的可采纳性。

Abstract: Multi-agent collaboration systems (MACS), powered by large language models
(LLMs), solve complex problems efficiently by leveraging each agent's
specialization and communication between agents. However, the inherent exchange
of information between agents and their interaction with external environments,
such as LLM, tools, and users, inevitably introduces significant risks of
sensitive data leakage, including vulnerabilities to attacks like prompt
injection and reconnaissance. Existing MACS fail to enable privacy controls,
making it challenging to manage sensitive information securely. In this paper,
we take the first step to address the MACS's data leakage threat at the system
development level through a privacy-enhanced development paradigm, Maris. Maris
enables rigorous message flow control within MACS by embedding reference
monitors into key multi-agent conversation components. We implemented Maris as
an integral part of AutoGen, a widely adopted open-source multi-agent
development framework. Then, we evaluate Maris for its effectiveness and
performance overhead on privacy-critical MACS use cases, including healthcare,
supply chain optimization, and personalized recommendation system. The result
shows that Maris achieves satisfactory effectiveness, performance overhead and
practicability for adoption.

</details>

### [3] [Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](https://arxiv.org/abs/2505.04806)
*Chetan Pathade*

Main category: cs.CR

TLDR: 本文系统研究了针对大型语言模型（LLMs）的越狱策略，分析了1400多个对抗性提示的成功率，并提出了分层缓解策略。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs能力强大，但仍易受对抗性攻击（如提示注入和越狱）的影响，需要研究其安全性和防御措施。

Method: 对GPT-4、Claude 2、Mistral 7B和Vicuna等模型测试了1400多个对抗性提示，分析其成功率和构造逻辑。

Result: 揭示了越狱策略的有效性和通用性，测试了不同模型的脆弱性。

Conclusion: 建议采用混合红队和沙盒方法，提出分层缓解策略以增强LLM安全性。

Abstract: Large Language Models (LLMs) are increasingly integrated into consumer and
enterprise applications. Despite their capabilities, they remain susceptible to
adversarial attacks such as prompt injection and jailbreaks that override
alignment safeguards. This paper provides a systematic investigation of
jailbreak strategies against various state-of-the-art LLMs. We categorize over
1,400 adversarial prompts, analyze their success against GPT-4, Claude 2,
Mistral 7B, and Vicuna, and examine their generalizability and construction
logic. We further propose layered mitigation strategies and recommend a hybrid
red-teaming and sandboxing approach for robust LLM security.

</details>

### [4] [Memory Under Siege: A Comprehensive Survey of Side-Channel Attacks on Memory](https://arxiv.org/abs/2505.04896)
*MD Mahady Hassan,Shanto Roy,Reza Rahaeimehr*

Main category: cs.CR

TLDR: 该研究综述了内存侧信道攻击（SCAM），分类了攻击技术并评估了防御机制，旨在为研究者和从业者提供改进内存安全的指导。


<details>
  <summary>Details</summary>
Motivation: 内存侧信道攻击通过利用内存子系统的漏洞泄露敏感信息，威胁系统安全，需系统研究以应对新兴威胁。

Method: 研究首先识别内存系统中的主要漏洞（如缓存计时、推测执行等），然后提出分类法系统分类攻击，并评估现有防御策略。

Result: 研究提供了对SCAM的全面概述，包括攻击分类和防御策略的优缺点。

Conclusion: 该研究为理解和缓解内存侧信道攻击风险提供了重要见解，有助于推动内存安全领域的进步。

Abstract: Side-channel attacks on memory (SCAM) exploit unintended data leaks from
memory subsystems to infer sensitive information, posing significant threats to
system security. These attacks exploit vulnerabilities in memory access
patterns, cache behaviors, and other microarchitectural features to bypass
traditional security measures. The purpose of this research is to examine SCAM,
classify various attack techniques, and evaluate existing defense mechanisms.
It guides researchers and industry professionals in improving memory security
and mitigating emerging threats. We begin by identifying the major
vulnerabilities in the memory system that are frequently exploited in SCAM,
such as cache timing, speculative execution, \textit{Rowhammer}, and other
sophisticated approaches. Next, we outline a comprehensive taxonomy that
systematically classifies these attacks based on their types, target systems,
attack vectors, and adversarial capabilities required to execute them. In
addition, we review the current landscape of mitigation strategies, emphasizing
their strengths and limitations. This work aims to provide a comprehensive
overview of memory-based side-channel attacks with the goal of providing
significant insights for researchers and practitioners to better understand,
detect, and mitigate SCAM risks.

</details>

### [5] [Enhancing Blockchain Cross Chain Interoperability: A Comprehensive Survey](https://arxiv.org/abs/2505.04934)
*Zhihong Deng,Chunming Tang,Taotao Li,Parhat Abla,Qi Chen,Wei Liang,Debiao He*

Main category: cs.CR

TLDR: 区块链互操作性（跨链互操作性）是解决不同区块链间数据与资产交换问题的关键，本文通过系统分析150多篇高影响力文献，提供了现有方法、技术和架构的分类，并探讨了学术研究与行业实践的融合。


<details>
  <summary>Details</summary>
Motivation: 区块链技术的快速发展导致了架构、共识机制和数据标准的不一致，形成了数据和价值孤岛，阻碍了多链生态系统的发展。区块链互操作性被视为解决这一问题的方案。

Method: 通过分析150多篇高影响力文献，系统研究了区块链互操作性的现有方法、技术和架构，并对其进行了分类。

Result: 提出了包括原子交换、侧链、轻客户端等在内的互操作性方法分类，并强调了学术研究与行业实践结合的重要性。

Conclusion: 研究结果为研究人员、政策制定者和行业领袖提供了关键的战略见解，以推动区块链互操作性的发展，实现多链生态系统的整合。

Abstract: Blockchain technology, introduced in 2008, has revolutionized data storage
and transfer across sectors such as finance, healthcare, intelligent
transportation, and the metaverse. However, the proliferation of blockchain
systems has led to discrepancies in architectures, consensus mechanisms, and
data standards, creating data and value silos that hinder the development of an
integrated multi chain ecosystem. Blockchain interoperability (a.k.a cross
chain interoperability) has thus emerged as a solution to enable seamless data
and asset exchange across disparate blockchains. In this survey, we
systematically analyze over 150 high impact sources from academic journals,
digital libraries, and grey literature to provide an in depth examination of
blockchain interoperability. By exploring the existing methods, technologies,
and architectures, we offer a classification of interoperability approaches
including Atomic Swaps, Sidechains, Light Clients, and so on, which represent
the most comprehensive overview to date. Furthermore, we investigate the
convergence of academic research with industry practices, underscoring the
importance of collaborative efforts in advancing blockchain innovation.
Finally, we identify key strategic insights, challenges, and future research
trajectories in this field. Our findings aim to support researchers,
policymakers, and industry leaders in understanding and harnessing the
transformative potential of blockchain interoperability to address current
challenges and drive forward a cohesive multi-chain ecosystem.

</details>

### [6] [ChainMarks: Securing DNN Watermark with Cryptographic Chain](https://arxiv.org/abs/2505.04977)
*Brian Choi,Shu Wang,Isabelle Choi,Kun Sun*

Main category: cs.CR

TLDR: ChainMarks提出了一种安全的DNN水印方案，通过引入密码链和两阶段蒙特卡洛方法，提高了水印的鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有DNN水印方案易受移除和模糊攻击，且水印存在判定标准模糊，ChainMarks旨在解决这些问题。

Method: 通过哈希函数生成触发输入作为水印数据集，结合数字签名生成目标标签，训练模型时同时使用原始和水印数据集。水印验证时比较预测标签与目标标签，并使用更准确的决策阈值。

Result: 实验表明ChainMarks在鲁棒性和安全性上优于现有方案，且具有更高的水印存在概率保证。

Conclusion: ChainMarks为DNN模型提供了一种更安全、鲁棒的水印方案，具有实际应用价值。

Abstract: With the widespread deployment of deep neural network (DNN) models, dynamic
watermarking techniques are being used to protect the intellectual property of
model owners. However, recent studies have shown that existing watermarking
schemes are vulnerable to watermark removal and ambiguity attacks. Besides, the
vague criteria for determining watermark presence further increase the
likelihood of such attacks. In this paper, we propose a secure DNN watermarking
scheme named ChainMarks, which generates secure and robust watermarks by
introducing a cryptographic chain into the trigger inputs and utilizes a
two-phase Monte Carlo method for determining watermark presence. First,
ChainMarks generates trigger inputs as a watermark dataset by repeatedly
applying a hash function over a secret key, where the target labels associated
with trigger inputs are generated from the digital signature of model owner.
Then, the watermarked model is produced by training a DNN over both the
original and watermark datasets. To verify watermarks, we compare the predicted
labels of trigger inputs with the target labels and determine ownership with a
more accurate decision threshold that considers the classification probability
of specific models. Experimental results show that ChainMarks exhibits higher
levels of robustness and security compared to state-of-the-art watermarking
schemes. With a better marginal utility, ChainMarks provides a higher
probability guarantee of watermark presence in DNN models with the same level
of watermark accuracy.

</details>

### [7] [SoK: A Taxonomy for Distributed-Ledger-Based Identity Management](https://arxiv.org/abs/2505.05100)
*Awid Vaziry,Sandro Rodriguez Garzon,Patrick Herbke,Carlo Segat,Axel Kupper*

Main category: cs.CR

TLDR: 本文提出了一种基于区块链的身份管理分类框架，通过分析390篇科学论文和专家讨论，构建了包含22个维度和113个特征的分类法，分为信任锚实现、身份架构和账本规范三组。


<details>
  <summary>Details</summary>
Motivation: 区块链与身份管理的交叉领域缺乏系统分类框架，阻碍了解决方案的分析与设计。

Method: 通过分析390篇论文和专家讨论，开发了方法论驱动的分类法，包含22个维度和113个特征。

Result: 分类法成功应用于两种不同架构，为系统分析、比较和设计提供了工具。

Conclusion: 该分类法首次以方法论驱动，推动了标准化，为研究和实践提供了结构化框架。

Abstract: The intersection of blockchain (distributed ledger) and identity management
lacks a comprehensive framework for classifying distributed-ledger-based
identity solutions. This paper introduces a methodologically developed taxonomy
derived from the analysis of 390 scientific papers and expert discussions.
  The resulting framework consists of 22 dimensions with 113 characteristics,
organized into three groups: trust anchor implementations, identity
architectures (identifiers and credentials), and ledger specifications. This
taxonomy facilitates the systematic analysis, comparison, and design of
distributed-ledger-based identity solutions, as demonstrated through its
application to two distinct architectures.
  As the first methodology-driven taxonomy in this field, this work advances
standardization and enhances understanding of distributed-ledger-based identity
architectures. It provides researchers and practitioners with a structured
framework for evaluating design decisions and implementation approaches.

</details>

### [8] [A Weighted Byzantine Fault Tolerance Consensus Driven Trusted Multiple Large Language Models Network](https://arxiv.org/abs/2505.05103)
*Haoxiang Luo,Gang Sun,Yinqiu Liu,Dongcheng Zhao,Dusit Niyato,Hongfang Yu,Schahram Dustdar*

Main category: cs.CR

TLDR: 提出了一种基于加权拜占庭容错（WBFT）区块链共识机制的Trusted MultiLLMN框架，以提高多LLM协作的可靠性、安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有MultiLLMN架构在开放环境中存在可靠性和安全性问题，且集中式协调效率低下。

Method: 采用WBFT机制，根据LLM的响应质量和可信度动态分配投票权重，激励可靠行为并减少恶意节点影响。

Result: WBFT显著提升了共识安全性和效率，Trusted MultiLLMN能生成更高质量和可信的响应。

Conclusion: WBFT支持的Trusted MultiLLMN为构建健壮、去中心化的AI协作网络提供了可行方案。

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide
range of applications. However, individual LLMs often produce inconsistent,
biased, or hallucinated outputs due to limitations in their training corpora
and model architectures. Recently, collaborative frameworks such as the
Multi-LLM Network (MultiLLMN) have been introduced, enabling multiple LLMs to
interact and jointly respond to user queries. Nevertheless, MultiLLMN
architectures raise critical concerns regarding the reliability and security of
the generated content, particularly in open environments where malicious or
compromised LLMs may be present. Moreover, reliance on centralized coordination
undermines system efficiency and introduces single points of failure. In this
paper, we propose a novel Trusted MultiLLMN framework, driven by a Weighted
Byzantine Fault Tolerance (WBFT) blockchain consensus mechanism, to ensure the
reliability, security, and efficiency of multi-LLM collaboration. In WBFT,
voting weights are adaptively assigned to each LLM based on its response
quality and trustworthiness, incentivizing reliable behavior, and reducing the
impact of malicious nodes. Extensive simulations demonstrate that WBFT
significantly improves both consensus security and efficiency compared to
classical and modern consensus mechanisms, particularly under wireless network
conditions. Furthermore, our evaluations reveal that Trusted MultiLLMN
supported by WBFT can deliver higher-quality and more credible responses than
both single LLMs and conventional MultiLLMNs, thereby providing a promising
path toward building robust, decentralized AI collaboration networks.

</details>

### [9] [QUIC-Exfil: Exploiting QUIC's Server Preferred Address Feature to Perform Data Exfiltration Attacks](https://arxiv.org/abs/2505.05292)
*Thomas Grübl,Weijie Niu,Jan von der Assen,Burkhard Stiller*

Main category: cs.CR

TLDR: QUIC协议因其高效、安全和抗审查特性被广泛采用，但也因其动态IP和端口变化等特点，使得基于QUIC的数据外泄攻击难以被防火墙检测。本文提出了一种利用QUIC服务器首选地址特性的新型数据外泄方法，并通过实验证明现有异常检测分类器无法有效识别此类攻击。


<details>
  <summary>Details</summary>
Motivation: QUIC协议的动态性和加密特性使其在提升性能的同时，也为攻击者提供了隐蔽的数据外泄途径。现有防火墙技术难以区分正常的QUIC连接迁移和恶意攻击，亟需研究其安全风险。

Method: 提出了一种基于QUIC服务器首选地址特性的数据外泄攻击方法，并开发了Rust实现的工具进行概念验证。通过训练五种异常检测分类器（如随机森林、自编码器等）对70万+ QUIC数据包进行分析。

Result: 实验表明，五种分类器均无法有效检测数据外泄攻击，且流量分析未发现可识别的指纹。此外，主流防火墙厂商目前未具备区分正常与恶意QUIC连接迁移的能力。

Conclusion: QUIC协议的数据外泄攻击具有隐蔽性，现有检测技术存在局限性，需进一步研究防御方法。

Abstract: The QUIC protocol is now widely adopted by major tech companies and accounts
for a significant fraction of today's Internet traffic. QUIC's multiplexing
capabilities, encrypted headers, dynamic IP address changes, and encrypted
parameter negotiations make the protocol not only more efficient, secure, and
censorship-resistant, but also practically unmanageable by firewalls. This
opens doors for attackers who may exploit certain traits of the QUIC protocol
to perform targeted attacks, such as data exfiltration attacks. Whereas
existing data exfiltration techniques, such as TLS and DNS-based exfiltration,
can be detected on a firewall level, QUIC-based data exfiltration is more
difficult to detect, since changes in IP addresses and ports are inherent to
the protocol's normal behavior. To show the feasibility of a QUIC-based data
exfiltration attack, we introduce a novel method leveraging the server
preferred address feature of the QUIC protocol and, thus, allows an attacker to
exfiltrate sensitive data from an infected machine to a malicious server,
disguised as a server-side connection migration. The attack is implemented as a
proof of concept tool in Rust. We evaluated the performance of five anomaly
detection classifiers - Random Forest, Multi-Layer Perceptron, Support Vector
Machine, Autoencoder, and Isolation Forest - trained on datasets collected from
three network traffic scenarios. The classifiers were trained on over 700K
benign and malicious QUIC packets and 786 connection migration events, but were
unable to detect the data exfiltration attempts. Furthermore, post-analysis of
the traffic captures did not reveal any identifiable fingerprint. As part of
our evaluation, we also interviewed five leading firewall vendors and found
that, as of today, no major firewall vendor implements functionality capable of
distinguishing between benign and malicious QUIC connection migrations.

</details>

### [10] [SUUM: Timestamp-based Nakamoto-style Blockchains are Vulnerable](https://arxiv.org/abs/2505.05328)
*Junjie Hu,Na Ruan*

Main category: cs.CR

TLDR: 论文介绍了两种高级攻击策略（UUM和SUUM），通过时间戳操纵和分叉选择规则漏洞，永久破坏区块链的安全性和激励机制。SUUM攻击尤其危险，允许攻击者零成本持续攻击，最大化收益。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示时间戳基础的Nakamoto-style区块链协议中存在的严重安全漏洞，这些漏洞可能被攻击者利用以永久破坏系统的公平性和激励机制。

Method: 通过理论建模和仿真，分析了UUM和SUUM攻击策略，特别是SUUM如何通过时间戳操纵、区块保留和难度风险控制实现无限制攻击。

Result: SUUM攻击在奖励优势上远超UUM和RUM攻击，且能零成本持续攻击，永久削弱协议的安全假设。

Conclusion: 研究强调了时间戳基础协议存在的系统性风险，呼吁采取紧急对策以确保长期稳定性。

Abstract: We introduce two advanced attack strategies, the Unrestricted Uncle Maker
(UUM) Attack and the Staircase-Unrestricted Uncle Maker (SUUM) Attack, which
fundamentally threaten the security of timestamp-based Nakamoto-style
blockchains by inflicting permanent systemic harm. Unlike prior work that
merely enhances adversarial rewards, these attacks exploit vulnerabilities in
timestamp manipulation and fork selection rules to irreversibly destabilize
blockchain fairness and incentive mechanisms. Specifically, the SUUM attack
enables adversaries to persistently launch attacks at zero cost, eliminating
constraints on block withholding and risk-free conditions, while systematically
maximizing rewards through coordinated timestamp adjustments and strategic
block release.
  Our analysis demonstrates that SUUM adversaries achieve disproportionate
reward advantages over both UUM and the original Riskless Uncle Maker (RUM)
Attack [CCS '23], with all three strategies surpassing honest mining.
Crucially, SUUM's cost-free persistence allows adversaries to indefinitely
drain rewards from honest participants by maintaining minimal difficulty risks
through precise timestamp manipulation. This creates a self-reinforcing cycle:
adversaries amplify their profits while suppressing honest returns, thereby
permanently eroding the protocol's security assumptions. Through rigorous
theoretical modeling and simulations, we validate how SUUM's combination of
timestamp tampering, block withholding, and difficulty risk control enables
unmitigated exploitation of consensus mechanisms. This work underscores the
existential risks posed by timestamp-based Nakamoto-style protocols and
advocates urgent countermeasures to ensure long-term stability.

</details>

<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [MatMMFuse: Multi-Modal Fusion model for Material Property Prediction](https://arxiv.org/abs/2505.04634)
*Abhiroop Bhattacharya,Sylvain G. Cloutier*

Main category: cs.LG

TLDR: 论文提出了一种多模态融合模型MatMMFuse，结合了CGCNN的结构感知嵌入和SciBERT的文本嵌入，显著提升了材料属性预测的性能。


<details>
  <summary>Details</summary>
Motivation: 单一模态模型无法充分利用不同表示的优势，而多模态融合可以结合局部和全局特征，提升预测效果。

Method: 使用多头注意力机制融合CGCNN和SciBERT的嵌入，端到端训练模型。

Result: 在四个关键属性上均优于单模态模型，形成能预测提升40%（CGCNN）和68%（SciBERT），且零样本性能更优。

Conclusion: MatMMFuse适用于数据稀缺的工业场景，展现了多模态融合的潜力。

Abstract: The recent progress of using graph based encoding of crystal structures for
high throughput material property prediction has been quite successful.
However, using a single modality model prevents us from exploiting the
advantages of an enhanced features space by combining different
representations. Specifically, pre-trained Large language models(LLMs) can
encode a large amount of knowledge which is beneficial for training of models.
Moreover, the graph encoder is able to learn the local features while the text
encoder is able to learn global information such as space group and crystal
symmetry. In this work, we propose Material Multi-Modal Fusion(MatMMFuse), a
fusion based model which uses a multi-head attention mechanism for the
combination of structure aware embedding from the Crystal Graph Convolution
Network (CGCNN) and text embeddings from the SciBERT model. We train our model
in an end-to-end framework using data from the Materials Project Dataset. We
show that our proposed model shows an improvement compared to the vanilla CGCNN
and SciBERT model for all four key properties: formation energy, band gap,
energy above hull and fermi energy. Specifically, we observe an improvement of
40% compared to the vanilla CGCNN model and 68% compared to the SciBERT model
for predicting the formation energy per atom. Importantly, we demonstrate the
zero shot performance of the trained model on small curated datasets of
Perovskites, Chalcogenides and the Jarvis Dataset. The results show that the
proposed model exhibits better zero shot performance than the individual plain
vanilla CGCNN and SciBERT model. This enables researchers to deploy the model
for specialized industrial applications where collection of training data is
prohibitively expensive.

</details>

### [12] [Conformal Prediction with Corrupted Labels: Uncertain Imputation and Robust Re-weighting](https://arxiv.org/abs/2505.04733)
*Shai Feldman,Stephen Bates,Yaniv Romano*

Main category: cs.LG

TLDR: 论文提出了一种在标签数据被噪声或缺失污染时进行鲁棒不确定性量化的框架，基于共形预测方法，并分析了特权共形预测（PCP）对权重估计不准确的鲁棒性，同时提出了一种新的共形方法——不确定插补（UI）。


<details>
  <summary>Details</summary>
Motivation: 解决在标签数据被污染（噪声或缺失）情况下，传统共形预测方法因i.i.d假设失效而无法提供有效预测的问题。

Method: 提出特权共形预测（PCP）方法，利用特权信息（PI）重新加权数据分布；进一步提出不确定插补（UI）方法，通过保留不确定性的方式插补被污染的标签。

Result: 理论分析和实验验证表明，PCP在权重估计不准确时仍能提供有效的不确定性估计，UI方法无需依赖权重估计且效果显著。

Conclusion: 通过整合PCP和UI，构建了一个三重鲁棒框架，确保只要至少一种方法有效，预测结果即具有统计有效性。

Abstract: We introduce a framework for robust uncertainty quantification in situations
where labeled training data are corrupted, through noisy or missing labels. We
build on conformal prediction, a statistical tool for generating prediction
sets that cover the test label with a pre-specified probability. The validity
of conformal prediction, however, holds under the i.i.d assumption, which does
not hold in our setting due to the corruptions in the data. To account for this
distribution shift, the privileged conformal prediction (PCP) method proposed
leveraging privileged information (PI) -- additional features available only
during training -- to re-weight the data distribution, yielding valid
prediction sets under the assumption that the weights are accurate. In this
work, we analyze the robustness of PCP to inaccuracies in the weights. Our
analysis indicates that PCP can still yield valid uncertainty estimates even
when the weights are poorly estimated. Furthermore, we introduce uncertain
imputation (UI), a new conformal method that does not rely on weight
estimation. Instead, we impute corrupted labels in a way that preserves their
uncertainty. Our approach is supported by theoretical guarantees and validated
empirically on both synthetic and real benchmarks. Finally, we show that these
techniques can be integrated into a triply robust framework, ensuring
statistically valid predictions as long as at least one underlying method is
valid.

</details>

### [13] [SetONet: A Deep Set-based Operator Network for Solving PDEs with permutation invariant variable input sampling](https://arxiv.org/abs/2505.04738)
*Stepan Tretiakov,Xingjian Li,Krishna Kumar*

Main category: cs.LG

TLDR: SetONet是一种新型神经网络架构，通过将Deep Sets原理融入DeepONet框架，解决了标准DeepONet在输入函数采样位置固定时的局限性，适用于变量传感器配置、缺失数据或不规则网格场景。


<details>
  <summary>Details</summary>
Motivation: 标准DeepONet需要输入函数在固定位置采样，限制了其在变量传感器配置、缺失数据或不规则网格场景中的应用。SetONet旨在解决这一问题。

Method: SetONet通过分支网络处理输入函数为无序的位置-值对集合，确保输入点的排列不变性，并显式处理空间坐标和函数值以学习更丰富的空间感知输入表示。

Result: SetONet在多个基准问题（如导数/反导数算子、1D Darcy流和2D弹性）中表现优异，能在变量输入采样条件下学习算子，且对传感器丢失具有鲁棒性。

Conclusion: SetONet扩展了神经算子工具包的灵活性和鲁棒性，显著拓宽了算子学习在变量或不完整输入数据问题中的应用范围。

Abstract: Neural operators, particularly the Deep Operator Network (DeepONet), have
shown promise in learning mappings between function spaces for solving
differential equations. However, standard DeepONet requires input functions to
be sampled at fixed locations, limiting its applicability in scenarios with
variable sensor configurations, missing data, or irregular grids. We introduce
the Set Operator Network (SetONet), a novel architecture that integrates Deep
Sets principles into the DeepONet framework to address this limitation. The
core innovation lies in the SetONet branch network, which processes the input
function as an unordered \emph{set} of location-value pairs. This design
ensures permutation invariance with respect to the input points, making SetONet
inherently robust to variations in the number and locations of sensors. SetONet
learns richer, spatially-aware input representations by explicitly processing
spatial coordinates and function values. We demonstrate SetONet's effectiveness
on several benchmark problems, including derivative/anti-derivative operators,
1D Darcy flow, and 2D elasticity. Results show that SetONet successfully learns
operators under variable input sampling conditions where standard DeepONet
fails. Furthermore, SetONet is architecturally robust to sensor drop-off;
unlike standard DeepONet, which requires methods like interpolation to function
with missing data. Notably, SetONet can achieve comparable or improved accuracy
over DeepONet on fixed grids, particularly for nonlinear problems, likely due
to its enhanced input representation. SetONet provides a flexible and robust
extension to the neural operator toolkit, significantly broadening the
applicability of operator learning to problems with variable or incomplete
input data.

</details>

### [14] [When Bad Data Leads to Good Models](https://arxiv.org/abs/2505.04741)
*Kenneth Li,Yida Chen,Fernanda Viégas,Martin Wattenberg*

Main category: cs.LG

TLDR: 研究探讨了预训练数据中‘毒性’数据比例对模型后训练控制的影响，发现更多毒性数据能简化毒性特征的线性表示，并使其更容易被移除。


<details>
  <summary>Details</summary>
Motivation: 重新审视数据‘质量’的定义，探索预训练数据中‘毒性’数据比例对模型后训练控制的影响。

Method: 通过玩具实验研究数据组成对特征几何的影响，并利用Olmo-1B模型进行控制实验，比较不同毒性数据比例的效果。

Result: 毒性数据比例增加会简化毒性特征的线性表示，并使其更容易被移除，后训练技术（如ITI）能更好地平衡毒性减少与模型能力保留。

Conclusion: 考虑后训练时，‘坏’数据可能有助于生成更好的模型。

Abstract: In large language model (LLM) pretraining, data quality is believed to
determine model quality. In this paper, we re-examine the notion of "quality"
from the perspective of pre- and post-training co-design. Specifically, we
explore the possibility that pre-training on more toxic data can lead to better
control in post-training, ultimately decreasing a model's output toxicity.
First, we use a toy experiment to study how data composition affects the
geometry of features in the representation space. Next, through controlled
experiments with Olmo-1B models trained on varying ratios of clean and toxic
data, we find that the concept of toxicity enjoys a less entangled linear
representation as the proportion of toxic data increases. Furthermore, we show
that although toxic data increases the generational toxicity of the base model,
it also makes the toxicity easier to remove. Evaluations on Toxigen and Real
Toxicity Prompts demonstrate that models trained on toxic data achieve a better
trade-off between reducing generational toxicity and preserving general
capabilities when detoxifying techniques such as inference-time intervention
(ITI) are applied. Our findings suggest that, with post-training taken into
account, bad data may lead to good models.

</details>

### [15] [Primal-dual algorithm for contextual stochastic combinatorial optimization](https://arxiv.org/abs/2505.04757)
*Louis Bouvier,Thibault Prunet,Vincent Leclère,Axel Parmentier*

Main category: cs.LG

TLDR: 本文提出了一种结合运筹学和机器学习的新方法，用于解决不确定性下的决策问题。通过神经网络和组合优化层编码策略，最小化经验风险，并展示了算法的线性收敛性和高效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法未能充分利用上下文信息，因此需要新算法来改进不确定性下的决策。

Method: 使用神经网络与组合优化层编码策略，提出替代学习问题和通用的原始-对偶算法，适用于多种组合优化场景。

Result: 算法在特定条件下线性收敛，实验证明其在上下文随机最小生成树问题中高效且可扩展。

Conclusion: 新方法在性能上与基于拉格朗日启发式的模仿学习相当，且更具通用性。

Abstract: This paper introduces a novel approach to contextual stochastic optimization,
integrating operations research and machine learning to address decision-making
under uncertainty. Traditional methods often fail to leverage contextual
information, which underscores the necessity for new algorithms. In this study,
we utilize neural networks with combinatorial optimization layers to encode
policies. Our goal is to minimize the empirical risk, which is estimated from
past data on uncertain parameters and contexts. To that end, we present a
surrogate learning problem and a generic primal-dual algorithm that is
applicable to various combinatorial settings in stochastic optimization. Our
approach extends classic Fenchel-Young loss results and introduces a new
regularization method using sparse perturbations on the distribution simplex.
This allows for tractable updates in the original space and can accommodate
diverse objective functions. We demonstrate the linear convergence of our
algorithm under certain conditions and provide a bound on the non-optimality of
the resulting policy in terms of the empirical risk. Experiments on a
contextual stochastic minimum weight spanning tree problem show that our
algorithm is efficient and scalable, achieving performance comparable to
imitation learning of solutions computed using an expensive Lagrangian-based
heuristic.

</details>

### [16] [Prediction via Shapley Value Regression](https://arxiv.org/abs/2505.04775)
*Amr Alkhatib,Roman Bresson,Henrik Boström,Michalis Vazirgiannis*

Main category: cs.LG

TLDR: ViaSHAP是一种新方法，通过学习计算Shapley值的函数，直接从预测中推导Shapley值，避免了传统后处理的高计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统Shapley值计算需要后处理，增加了推理时的计算成本，ViaSHAP旨在解决这一问题。

Method: 提出ViaSHAP方法，基于通用逼近定理和Kolmogorov-Arnold表示定理实现。

Result: ViaSHAP在表格数据上表现与最先进算法相当，且解释准确性显著高于FastSHAP。

Conclusion: ViaSHAP通过直接学习Shapley值函数，提高了计算效率和解释准确性。

Abstract: Shapley values have several desirable, theoretically well-supported,
properties for explaining black-box model predictions. Traditionally, Shapley
values are computed post-hoc, leading to additional computational cost at
inference time. To overcome this, a novel method, called ViaSHAP, is proposed,
that learns a function to compute Shapley values, from which the predictions
can be derived directly by summation. Two approaches to implement the proposed
method are explored; one based on the universal approximation theorem and the
other on the Kolmogorov-Arnold representation theorem. Results from a
large-scale empirical investigation are presented, showing that ViaSHAP using
Kolmogorov-Arnold Networks performs on par with state-of-the-art algorithms for
tabular data. It is also shown that the explanations of ViaSHAP are
significantly more accurate than the popular approximator FastSHAP on both
tabular data and images.

</details>

### [17] [Robust ML Auditing using Prior Knowledge](https://arxiv.org/abs/2505.04796)
*Jade Garcia Bourrée,Augustin Godinot,Martijn De Vos,Milos Vujasinovic,Sayan Biswas,Gilles Tredan,Erwan Le Merrer,Anne-Marie Kermarrec*

Main category: cs.LG

TLDR: 论文提出了一种防止机器学习系统在公平性审计中被操纵的新方法，强调审计者需利用先验知识而非公共数据集。


<details>
  <summary>Details</summary>
Motivation: 随着ML决策系统的广泛应用，如何防止平台在审计中操纵结果以通过公平性检查成为关键问题。

Method: 通过分析审计者的先验知识，提出防止操纵的形式化条件，并在标准数据集上验证方法的有效性。

Result: 实验表明，平台在审计中隐藏不公平性的能力有限，审计者的先验知识能有效防止操纵。

Conclusion: 研究为更鲁棒的公平性审计提供了新方向，强调先验知识的重要性。

Abstract: The rapid adoption of ML decision-making systems across products and services
has led to a set of regulations on how such systems should behave and be built.
Among all the technical challenges to enforcing these regulations, one crucial,
yet under-explored problem is the risk of manipulation while these systems are
being audited for fairness. This manipulation occurs when a platform
deliberately alters its answers to a regulator to pass an audit without
modifying its answers to other users. In this paper, we introduce a novel
approach to manipulation-proof auditing by taking into account the auditor's
prior knowledge of the task solved by the platform. We first demonstrate that
regulators must not rely on public priors (e.g. a public dataset), as platforms
could easily fool the auditor in such cases. We then formally establish the
conditions under which an auditor can prevent audit manipulations using prior
knowledge about the ground truth. Finally, our experiments with two standard
datasets exemplify the maximum level of unfairness a platform can hide before
being detected as malicious. Our formalization and generalization of
manipulation-proof auditing with a prior opens up new research directions for
more robust fairness audits.

</details>

### [18] [ORBIT-2: Scaling Exascale Vision Foundation Models for Weather and Climate Downscaling](https://arxiv.org/abs/2505.04802)
*Xiao Wang,Jong-Youl Choi,Takuya Kurihaya,Isaac Lyngaas,Hong-Jun Yoon,Ming Fan,Nasik Muhammad Nafi,Aristeidis Tsaris,Ashwin M. Aji,Maliha Hossain,Mohamed Wahib,Dali Wang,Peter Thornton,Prasanna Balaprakash,Moetasim Ashfaq,Dan Lu*

Main category: cs.LG

TLDR: ORBIT-2是一个用于全球高分辨率气候降尺度的基础模型，通过Reslim轻量架构和TILES算法解决了现有方法的泛化问题和计算复杂度问题，实现了高效的大规模并行处理和高精度预测。


<details>
  <summary>Details</summary>
Motivation: 稀疏观测和低分辨率气候模型限制了区域决策的有效性，现有AI方法在变量和地理泛化上表现不佳，且受限于ViT自注意力的二次复杂度。

Method: ORBIT-2结合了Reslim（轻量残差学习架构）和TILES（线性复杂度自注意力算法），支持大规模并行处理。

Result: ORBIT-2在32,768个GPU上扩展到100亿参数，实现了1.8 ExaFLOPS的吞吐量，7 km分辨率下R^2得分达0.98-0.99。

Conclusion: ORBIT-2为气候降尺度提供了高效、可扩展的解决方案，显著提升了精度和计算效率。

Abstract: Sparse observations and coarse-resolution climate models limit effective
regional decision-making, underscoring the need for robust downscaling.
However, existing AI methods struggle with generalization across variables and
geographies and are constrained by the quadratic complexity of Vision
Transformer (ViT) self-attention. We introduce ORBIT-2, a scalable foundation
model for global, hyper-resolution climate downscaling. ORBIT-2 incorporates
two key innovations: (1) Residual Slim ViT (Reslim), a lightweight architecture
with residual learning and Bayesian regularization for efficient, robust
prediction; and (2) TILES, a tile-wise sequence scaling algorithm that reduces
self-attention complexity from quadratic to linear, enabling long-sequence
processing and massive parallelism. ORBIT-2 scales to 10 billion parameters
across 32,768 GPUs, achieving up to 1.8 ExaFLOPS sustained throughput and
92-98% strong scaling efficiency. It supports downscaling to 0.9 km global
resolution and processes sequences up to 4.2 billion tokens. On 7 km resolution
benchmarks, ORBIT-2 achieves high accuracy with R^2 scores in the range of 0.98
to 0.99 against observation data.

</details>

### [19] [Piecewise Constant Spectral Graph Neural Network](https://arxiv.org/abs/2505.04808)
*Vahan Martirosyan,Jhony H. Giraldo,Fragkiskos D. Malliaros*

Main category: cs.LG

TLDR: 论文提出了一种名为PieCoN的图神经网络，通过结合常数谱滤波器和多项式滤波器，更灵活地利用图结构，解决了现有谱GNN因多项式阶数限制而无法充分捕捉谱特性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有谱GNN使用低阶多项式滤波器，可能无法完全识别图的谱特性，而增加多项式阶数又会导致计算成本高或性能下降。

Method: 提出PieCoN，结合常数谱滤波器和多项式滤波器，并通过自适应划分谱区间来扩展可学习的谱特性范围。

Result: 在九个基准数据集上的实验表明，PieCoN在异配性数据集上表现尤为突出。

Conclusion: PieCoN为解决谱GNN的局限性提供了一种有效方法，具有广泛的应用潜力。

Abstract: Graph Neural Networks (GNNs) have achieved significant success across various
domains by leveraging graph structures in data. Existing spectral GNNs, which
use low-degree polynomial filters to capture graph spectral properties, may not
fully identify the graph's spectral characteristics because of the polynomial's
small degree. However, increasing the polynomial degree is computationally
expensive and beyond certain thresholds leads to performance plateaus or
degradation. In this paper, we introduce the Piecewise Constant Spectral Graph
Neural Network(PieCoN) to address these challenges. PieCoN combines constant
spectral filters with polynomial filters to provide a more flexible way to
leverage the graph structure. By adaptively partitioning the spectrum into
intervals, our approach increases the range of spectral properties that can be
effectively learned. Experiments on nine benchmark datasets, including both
homophilic and heterophilic graphs, demonstrate that PieCoN is particularly
effective on heterophilic datasets, highlighting its potential for a wide range
of applications.

</details>

### [20] [Guide your favorite protein sequence generative model](https://arxiv.org/abs/2505.04823)
*Junhao Xiong,Hunter Nisonoff,Ishan Gaur,Jennifer Listgarten*

Main category: cs.LG

TLDR: ProteinGuide是一个通用的框架，用于在预训练的蛋白质生成模型中实现统计条件化，支持多种生成模型类型，并能根据用户指定的属性生成蛋白质序列。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏一种即插即用的框架来辅助蛋白质生成模型结合辅助信息（如实验反馈或现有分类器），以生成具有特定属性的蛋白质序列。

Method: 通过统一包括掩码语言模型、自回归模型、扩散模型和流匹配模型在内的多种蛋白质生成模型，提出了一种统计条件化方法。

Result: 成功引导ProteinMPNN和ESM3两种常用蛋白质生成模型，生成具有增强稳定性和特定折叠结构的氨基酸序列。

Conclusion: ProteinGuide为蛋白质工程提供了一个灵活且强大的工具，能够根据需要生成具有特定属性的蛋白质序列。

Abstract: Generative machine learning models have begun to transform protein
engineering, yet no principled framework for conditioning on auxiliary
information in a plug-and-play manner exists; one may want to iteratively
incorporate experimental feedback, or make use of an existing classifier --
such as for predicting enzyme commission number -- in order to guide the
sampling of the generative model to generate sequences with desired properties.
Herein, we present ProteinGuide, a rigorous and general framework to achieve
just that: through unifying a broad class of protein generative models that
includes masked language, (order-agnostic) autoregressive, diffusion and
flow-matching models, we provide an approach to statistically condition
pre-trained protein generative models. We demonstrate applicability of our
approach by guiding each of two commonly used protein generative models,
ProteinMPNN and ESM3, to generate amino acid and structure token sequences
conditioned on several user-specified properties, namely, enhanced stability
and CATH-labeled fold generation.

</details>

### [21] [Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers](https://arxiv.org/abs/2505.04842)
*Kusha Sareen,Morgane M Moss,Alessandro Sordoni,Rishabh Agarwal,Arian Hosseini*

Main category: cs.LG

TLDR: RL$^V$通过联合训练LLM作为推理器和生成验证器，提升了MATH任务的准确性和测试时计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法放弃学习值函数，限制了测试时计算的扩展性。

Method: 提出RL$^V$，联合训练LLM作为推理器和生成验证器，利用RL生成的数据增强验证能力。

Result: MATH任务准确率提升20%以上，测试时计算效率提高8-32倍，并展现出强泛化能力。

Conclusion: RL$^V$显著提升了LLM推理和验证能力，同时高效扩展了计算资源。

Abstract: Prevalent reinforcement learning~(RL) methods for fine-tuning LLM reasoners,
such as GRPO or Leave-one-out PPO, abandon the learned value function in favor
of empirically estimated returns. This hinders test-time compute scaling that
relies on using the value-function for verification. In this work, we propose
RL$^V$ that augments any ``value-free'' RL method by jointly training the LLM
as both a reasoner and a generative verifier using RL-generated data, adding
verification capabilities without significant overhead. Empirically, RL$^V$
boosts MATH accuracy by over 20\% with parallel sampling and enables
$8-32\times$ efficient test-time compute scaling compared to the base RL
method. RL$^V$ also exhibits strong generalization capabilities for both
easy-to-hard and out-of-domain tasks. Furthermore, RL$^V$ achieves
$1.2-1.6\times$ higher performance when jointly scaling parallel and sequential
test-time compute with a long reasoning R1 model.

</details>

### [22] [Federated Learning for Cyber Physical Systems: A Comprehensive Survey](https://arxiv.org/abs/2505.04873)
*Minh K. Quan,Pubudu N. Pathirana,Mayuri Wijayasundara,Sujeeva Setunge,Dinh C. Nguyen,Christopher G. Brinton,David J. Love,H. Vincent Poor*

Main category: cs.LG

TLDR: 该论文综述了联邦学习（FL）在信息物理系统（CPS）中的最新进展，包括应用领域、系统拓扑和算法，并比较了FL在CPS与物联网（IoT）中的应用。


<details>
  <summary>Details</summary>
Motivation: 由于实时决策、安全性、可靠性、设备异构性和数据隐私等挑战，机器学习在CPS中的集成复杂，需解决开放性问题以实现其潜力。

Method: 通过分析FL和CPS的最新进展及其集成，比较FL在CPS与IoT中的应用，并探讨FL在关键CPS领域的应用。

Result: 论文总结了FL-CPS的多种应用和系统拓扑，提供了关键见解和实施经验。

Conclusion: 文章指出了FL-CPS领域的重要问题，并提出了未来研究方向。

Abstract: The integration of machine learning (ML) in cyber physical systems (CPS) is a
complex task due to the challenges that arise in terms of real-time decision
making, safety, reliability, device heterogeneity, and data privacy. There are
also open research questions that must be addressed in order to fully realize
the potential of ML in CPS. Federated learning (FL), a distributed approach to
ML, has become increasingly popular in recent years. It allows models to be
trained using data from decentralized sources. This approach has been gaining
popularity in the CPS field, as it integrates computer, communication, and
physical processes. Therefore, the purpose of this work is to provide a
comprehensive analysis of the most recent developments of FL-CPS, including the
numerous application areas, system topologies, and algorithms developed in
recent years. The paper starts by discussing recent advances in both FL and
CPS, followed by their integration. Then, the paper compares the application of
FL in CPS with its applications in the internet of things (IoT) in further
depth to show their connections and distinctions. Furthermore, the article
scrutinizes how FL is utilized in critical CPS applications, e.g., intelligent
transportation systems, cybersecurity services, smart cities, and smart
healthcare solutions. The study also includes critical insights and lessons
learned from various FL-CPS implementations. The paper's concluding section
delves into significant concerns and suggests avenues for further research in
this fast-paced and dynamic era.

</details>

### [23] [ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning](https://arxiv.org/abs/2505.04881)
*Ziqing Qiao,Yongheng Deng,Jiali Zeng,Dong Wang,Lai Wei,Fandong Meng,Jie Zhou,Ju Ren,Yaoxue Zhang*

Main category: cs.LG

TLDR: ConCISE框架通过增强模型推理时的信心，减少冗余步骤，显著缩短输出长度，同时保持任务准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型（LRMs）在复杂推理任务中因冗余内容导致的输出冗长问题，提升计算效率和用户体验。

Method: 提出ConCISE框架，包括信心注入（Confidence Injection）和早期停止（Early Stopping），通过增强模型信心简化推理链。

Result: 实验显示，ConCISE能将输出长度减少约50%，同时保持高任务准确性，并在多个基准测试中优于现有方法。

Conclusion: ConCISE通过信心引导的压缩方法，有效解决了LRMs的冗余问题，提升了推理效率和用户体验。

Abstract: Large Reasoning Models (LRMs) perform strongly in complex reasoning tasks via
Chain-of-Thought (CoT) prompting, but often suffer from verbose outputs caused
by redundant content, increasing computational overhead, and degrading user
experience. Existing compression methods either operate post-hoc pruning,
risking disruption to reasoning coherence, or rely on sampling-based selection,
which fails to intervene effectively during generation. In this work, we
introduce a confidence-guided perspective to explain the emergence of redundant
reflection in LRMs, identifying two key patterns: Confidence Deficit, where the
model reconsiders correct steps due to low internal confidence, and Termination
Delay, where reasoning continues even after reaching a confident answer. Based
on this analysis, we propose ConCISE (Confidence-guided Compression In
Step-by-step Efficient Reasoning), a framework that simplifies reasoning chains
by reinforcing the model's confidence during inference, thus preventing the
generation of redundant reflection steps. It integrates Confidence Injection to
stabilize intermediate steps and Early Stopping to terminate reasoning when
confidence is sufficient. Extensive experiments demonstrate that fine-tuning
LRMs on ConCISE-generated data yields significantly shorter outputs, reducing
length by up to approximately 50% under SimPO, while maintaining high task
accuracy. ConCISE consistently outperforms existing baselines across multiple
reasoning benchmarks.

</details>

### [24] [FedRE: Robust and Effective Federated Learning with Privacy Preference](https://arxiv.org/abs/2505.04889)
*Tianzhe Xiao,Yichen Li,Yu Zhou,Yining Qi,Yi Liu,Wei Wang,Haozhao Wang,Yi Wang,Ruixuan Li*

Main category: cs.LG

TLDR: FedRE提出了一种结合本地差分隐私（LDP）的联邦学习方法，通过优化隐私预算分配和设计参数聚合机制，在保护隐私的同时提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在联邦学习中未能考虑客户隐私偏好的差异，导致对非敏感信息的过度保护引入不必要噪声，影响模型性能。

Method: 定义隐私敏感信息（PSI），分层优化LDP隐私预算分配，并设计基于扰动信息分布的参数聚合机制。

Result: 在T-SROIE和DocTamper数据集上的实验表明，FedRE在性能上优于现有方法。

Conclusion: FedRE通过分层隐私保护和优化聚合机制，实现了隐私保护与模型性能的平衡。

Abstract: Despite Federated Learning (FL) employing gradient aggregation at the server
for distributed training to prevent the privacy leakage of raw data, private
information can still be divulged through the analysis of uploaded gradients
from clients. Substantial efforts have been made to integrate local
differential privacy (LDP) into the system to achieve a strict privacy
guarantee. However, existing methods fail to take practical issues into account
by merely perturbing each sample with the same mechanism while each client may
have their own privacy preferences on privacy-sensitive information (PSI),
which is not uniformly distributed across the raw data. In such a case,
excessive privacy protection from private-insensitive information can
additionally introduce unnecessary noise, which may degrade the model
performance. In this work, we study the PSI within data and develop FedRE, that
can simultaneously achieve robustness and effectiveness benefits with LDP
protection. More specifically, we first define PSI with regard to the privacy
preferences of each client. Then, we optimize the LDP by allocating less
privacy budget to gradients with higher PSI in a layer-wise manner, thus
providing a stricter privacy guarantee for PSI. Furthermore, to mitigate the
performance degradation caused by LDP, we design a parameter aggregation
mechanism based on the distribution of the perturbed information. We conducted
experiments with text tamper detection on T-SROIE and DocTamper datasets, and
FedRE achieves competitive performance compared to state-of-the-art methods.

</details>

### [25] [An Agent-Based Modeling Approach to Free-Text Keyboard Dynamics for Continuous Authentication](https://arxiv.org/abs/2505.05015)
*Roberto Dillon,Arushi*

Main category: cs.LG

TLDR: 论文研究了基于键盘动态行为的连续认证系统，通过模拟不同键盘类型和用户行为，评估了两种机器学习方法的性能。


<details>
  <summary>Details</summary>
Motivation: 探索行为生物特征在透明多因素认证中的有效性，特别是键盘动态行为。

Method: 使用基于代理的模型（ABM）生成合成击键数据，评估了One-Class SVM和随机森林（RF）两种方法。

Result: 随机森林在键盘内用户识别上表现良好（准确率>0.7），但跨键盘识别效果差；One-Class SVM表现不佳。

Conclusion: 键盘硬件对行为认证有显著影响，可能需要键盘特定用户档案；随机森林优于One-Class SVM。

Abstract: Continuous authentication systems leveraging free-text keyboard dynamics
offer a promising additional layer of security in a multifactor authentication
setup that can be used in a transparent way with no impact on user experience.
This study investigates the efficacy of behavioral biometrics by employing an
Agent-Based Model (ABM) to simulate diverse typing profiles across mechanical
and membrane keyboards. Specifically, we generated synthetic keystroke data
from five unique agents, capturing features related to dwell time, flight time,
and error rates within sliding 5-second windows updated every second. Two
machine learning approaches, One-Class Support Vector Machine (OC-SVM) and
Random Forest (RF), were evaluated for user verification. Results revealed a
stark contrast in performance: while One-Class SVM failed to differentiate
individual users within each group, Random Forest achieved robust
intra-keyboard user recognition (Accuracy > 0.7) but struggled to generalize
across keyboards for the same user, highlighting the significant impact of
keyboard hardware on typing behavior. These findings suggest that: (1)
keyboard-specific user profiles may be necessary for reliable authentication,
and (2) ensemble methods like RF outperform One-Class SVM in capturing
fine-grained user-specific patterns.

</details>

### [26] [Clustering with Communication: A Variational Framework for Single Cell Representation Learning](https://arxiv.org/abs/2505.04891)
*Cong Qi,Yeqing Chen,Jie Zhang,Wei Zhi*

Main category: cs.LG

TLDR: CCCVAE是一种新型变分自编码器框架，通过整合细胞间通信信号改进单细胞表示学习，优于传统VAE。


<details>
  <summary>Details</summary>
Motivation: 理解细胞间通信（CCC）对揭示细胞异质性和生物功能至关重要，但现有方法未充分利用转录组数据中的信号信息。

Method: CCCVAE利用配体-受体相互作用的通信感知核和稀疏高斯过程，将生物先验知识嵌入潜在空间。

Result: 在四个scRNA-seq数据集上，CCCVAE的聚类性能优于传统VAE。

Conclusion: CCCVAE展示了将生物先验嵌入深度生成模型在单细胞分析中的价值。

Abstract: Single-cell RNA sequencing (scRNA-seq) has revealed complex cellular
heterogeneity, but recent studies emphasize that understanding biological
function also requires modeling cell-cell communication (CCC), the signaling
interactions mediated by ligand-receptor pairs that coordinate cellular
behavior. Tools like CellChat have demonstrated that CCC plays a critical role
in processes such as cell differentiation, tissue regeneration, and immune
response, and that transcriptomic data inherently encodes rich information
about intercellular signaling. We propose CCCVAE, a novel variational
autoencoder framework that incorporates CCC signals into single-cell
representation learning. By leveraging a communication-aware kernel derived
from ligand-receptor interactions and a sparse Gaussian process, CCCVAE encodes
biologically informed priors into the latent space. Unlike conventional VAEs
that treat each cell independently, CCCVAE encourages latent embeddings to
reflect both transcriptional similarity and intercellular signaling context.
Empirical results across four scRNA-seq datasets show that CCCVAE improves
clustering performance, achieving higher evaluation scores than standard VAE
baselines. This work demonstrates the value of embedding biological priors into
deep generative models for unsupervised single-cell analysis.

</details>

### [27] [GCN-Based Throughput-Oriented Handover Management in Dense 5G Vehicular Networks](https://arxiv.org/abs/2505.04894)
*Nazanin Mehregan,Robson E. De Grande*

Main category: cs.LG

TLDR: TH-GCN是一种基于图神经网络的5G网络切换管理优化方法，显著减少切换次数并提升信号质量。


<details>
  <summary>Details</summary>
Motivation: 5G网络在高速移动环境中因覆盖范围有限和频繁切换导致网络不稳定，影响实时应用性能。

Method: 利用图神经网络（GNN）建模车辆和基站为动态图节点，结合信号质量、吞吐量等特征，实现实时自适应切换决策。

Result: 仿真显示TH-GCN减少切换次数达78%，信号质量提升10%。

Conclusion: TH-GCN通过双中心视角优化切换管理，显著提升5G网络在高移动性环境中的稳定性。

Abstract: The rapid advancement of 5G has transformed vehicular networks, offering high
bandwidth, low latency, and fast data rates essential for real-time
applications in smart cities and vehicles. These improvements enhance traffic
safety and entertainment services. However, the limited coverage and frequent
handovers in 5G networks cause network instability, especially in high-mobility
environments due to the ping-pong effect. This paper presents TH-GCN
(Throughput-oriented Graph Convolutional Network), a novel approach for
optimizing handover management in dense 5G networks. Using graph neural
networks (GNNs), TH-GCN models vehicles and base stations as nodes in a dynamic
graph enriched with features such as signal quality, throughput, vehicle speed,
and base station load. By integrating both user equipment and base station
perspectives, this dual-centric approach enables adaptive, real-time handover
decisions that improve network stability. Simulation results show that TH-GCN
reduces handovers by up to 78 percent and improves signal quality by 10
percent, outperforming existing methods.

</details>

### [28] [FedTDP: A Privacy-Preserving and Unified Framework for Trajectory Data Preparation via Federated Learning](https://arxiv.org/abs/2505.05155)
*Zhihao Zeng,Ziquan Fang,Wei Shao,Lu Chen,Yunjun Gao*

Main category: cs.LG

TLDR: FedTDP是一个基于大语言模型的隐私保护和统一框架，用于联邦环境下的轨迹数据准备（TDP），解决了数据隐私和模型通用性问题。


<details>
  <summary>Details</summary>
Motivation: 轨迹数据在交通优化和城市规划中至关重要，但数据质量和隐私问题限制了其应用潜力。现有TDP方法未能解决联邦环境下的隐私保护和模型通用性问题。

Method: 设计了轨迹隐私自编码器保护数据隐私，引入轨迹知识增强器提升模型学习能力，并提出联邦并行优化以提高训练效率。

Result: 在6个真实数据集和10个主流TDP任务上，FedTDP优于13个先进基线方法。

Conclusion: FedTDP通过隐私保护和通用性设计，显著提升了联邦环境下轨迹数据准备的效果。

Abstract: Trajectory data, which capture the movement patterns of people and vehicles
over time and space, are crucial for applications like traffic optimization and
urban planning. However, issues such as noise and incompleteness often
compromise data quality, leading to inaccurate trajectory analyses and limiting
the potential of these applications. While Trajectory Data Preparation (TDP)
can enhance data quality, existing methods suffer from two key limitations: (i)
they do not address data privacy concerns, particularly in federated settings
where trajectory data sharing is prohibited, and (ii) they typically design
task-specific models that lack generalizability across diverse TDP scenarios.
To overcome these challenges, we propose FedTDP, a privacy-preserving and
unified framework that leverages the capabilities of Large Language Models
(LLMs) for TDP in federated environments. Specifically, we: (i) design a
trajectory privacy autoencoder to secure data transmission and protect privacy,
(ii) introduce a trajectory knowledge enhancer to improve model learning of
TDP-related knowledge, enabling the development of TDP-oriented LLMs, and (iii)
propose federated parallel optimization to enhance training efficiency by
reducing data transmission and enabling parallel model training. Experiments on
6 real datasets and 10 mainstream TDP tasks demonstrate that FedTDP
consistently outperforms 13 state-of-the-art baselines.

</details>

### [29] [Precise gradient descent training dynamics for finite-width multi-layer neural networks](https://arxiv.org/abs/2505.04898)
*Qiyang Han,Masaaki Imaizumi*

Main category: cs.LG

TLDR: 本文首次在多层级神经网络中，针对有限宽度比例机制下的梯度下降迭代提供了精确的分布特性描述，并提出了非渐近状态演化理论。


<details>
  <summary>Details</summary>
Motivation: 研究多层级神经网络在有限宽度比例机制下的梯度下降行为，填补现有理论（如NTK、MF和TP）在无限宽度假设下的不足。

Method: 提出非渐近状态演化理论，捕捉第一层权重的高斯波动和深层权重的集中性，适用于非高斯特征。

Result: 理论在有限宽度机制下有效，支持从个体初始化开始的权重演化，并同时分析训练和泛化误差。

Conclusion: 梯度下降学习的模型保留了单索引函数结构，可用于指导早期停止和超参数调优。

Abstract: In this paper, we provide the first precise distributional characterization
of gradient descent iterates for general multi-layer neural networks under the
canonical single-index regression model, in the `finite-width proportional
regime' where the sample size and feature dimension grow proportionally while
the network width and depth remain bounded. Our non-asymptotic state evolution
theory captures Gaussian fluctuations in first-layer weights and concentration
in deeper-layer weights, and remains valid for non-Gaussian features.
  Our theory differs from existing neural tangent kernel (NTK), mean-field (MF)
theories and tensor program (TP) in several key aspects. First, our theory
operates in the finite-width regime whereas these existing theories are
fundamentally infinite-width. Second, our theory allows weights to evolve from
individual initializations beyond the lazy training regime, whereas NTK and MF
are either frozen at or only weakly sensitive to initialization, and TP relies
on special initialization schemes. Third, our theory characterizes both
training and generalization errors for general multi-layer neural networks
beyond the uniform convergence regime, whereas existing theories study
generalization almost exclusively in two-layer settings.
  As a statistical application, we show that vanilla gradient descent can be
augmented to yield consistent estimates of the generalization error at each
iteration, which can be used to guide early stopping and hyperparameter tuning.
As a further theoretical implication, we show that despite model
misspecification, the model learned by gradient descent retains the structure
of a single-index function with an effective signal determined by a linear
combination of the true signal and the initialization.

</details>

### [30] [Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks](https://arxiv.org/abs/2505.05190)
*Yixin Cheng,Hongcheng Guo,Yangming Li,Leonid Sigal*

Main category: cs.LG

TLDR: 文本水印通过在LLM采样过程中嵌入统计信号，但现有方法在高熵标记中嵌入水印的设计易受攻击。本文提出SIRA攻击，利用自信息计算漏洞，以低成本实现高效攻击。


<details>
  <summary>Details</summary>
Motivation: 揭示当前文本水印算法在高熵标记嵌入水印的设计存在漏洞，亟需更鲁棒的水印方法。

Method: 提出SIRA攻击，通过计算标记的自信息识别潜在模式标记并进行针对性攻击。

Result: 实验表明SIRA对七种水印方法攻击成功率近100%，成本仅0.88美元/百万标记。

Conclusion: 当前水印算法存在普遍漏洞，需设计更鲁棒的水印方法。

Abstract: Text watermarking aims to subtly embed statistical signals into text by
controlling the Large Language Model (LLM)'s sampling process, enabling
watermark detectors to verify that the output was generated by the specified
model. The robustness of these watermarking algorithms has become a key factor
in evaluating their effectiveness. Current text watermarking algorithms embed
watermarks in high-entropy tokens to ensure text quality. In this paper, we
reveal that this seemingly benign design can be exploited by attackers, posing
a significant risk to the robustness of the watermark. We introduce a generic
efficient paraphrasing attack, the Self-Information Rewrite Attack (SIRA),
which leverages the vulnerability by calculating the self-information of each
token to identify potential pattern tokens and perform targeted attack. Our
work exposes a widely prevalent vulnerability in current watermarking
algorithms. The experimental results show SIRA achieves nearly 100% attack
success rates on seven recent watermarking methods with only 0.88 USD per
million tokens cost. Our approach does not require any access to the watermark
algorithms or the watermarked LLM and can seamlessly transfer to any LLM as the
attack model, even mobile-level models. Our findings highlight the urgent need
for more robust watermarking.

</details>

### [31] [VaCDA: Variational Contrastive Alignment-based Scalable Human Activity Recognition](https://arxiv.org/abs/2505.04907)
*Soham Khisa,Avijoy Chakma*

Main category: cs.LG

TLDR: 论文提出了一种结合变分自编码器和对比学习的多源域适应框架VaCDA，用于解决可穿戴设备数据异构性导致的传统迁移学习方法效果不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备生成大量未标记数据，且数据分布异构性强，传统迁移学习方法难以有效识别日常活动。

Method: 使用变分自编码器（VAE）学习共享低维潜在空间，并结合对比学习增强特征表示，提出VaCDA框架。

Result: VaCDA在跨位置和跨设备场景中优于基线方法。

Conclusion: VaCDA通过结合VAE和对比学习，有效减少数据异构性，提升跨域适应性能。

Abstract: Technological advancements have led to the rise of wearable devices with
sensors that continuously monitor user activities, generating vast amounts of
unlabeled data. This data is challenging to interpret, and manual annotation is
labor-intensive and error-prone. Additionally, data distribution is often
heterogeneous due to device placement, type, and user behavior variations. As a
result, traditional transfer learning methods perform suboptimally, making it
difficult to recognize daily activities. To address these challenges, we use a
variational autoencoder (VAE) to learn a shared, low-dimensional latent space
from available sensor data. This space generalizes data across diverse sensors,
mitigating heterogeneity and aiding robust adaptation to the target domain. We
integrate contrastive learning to enhance feature representation by aligning
instances of the same class across domains while separating different classes.
We propose Variational Contrastive Domain Adaptation (VaCDA), a multi-source
domain adaptation framework combining VAEs and contrastive learning to improve
feature representation and reduce heterogeneity between source and target
domains. We evaluate VaCDA on multiple publicly available datasets across three
heterogeneity scenarios: cross-person, cross-position, and cross-device. VaCDA
outperforms the baselines in cross-position and cross-device scenarios.

</details>

### [32] [MTL-UE: Learning to Learn Nothing for Multi-Task Learning](https://arxiv.org/abs/2505.05279)
*Yi Yu,Song Xia,Siyuan Yang,Chenqi Kong,Wenhan Yang,Shijian Lu,Yap-Peng Tan,Alex C. Kot*

Main category: cs.LG

TLDR: MTL-UE是首个针对多任务数据和多任务学习（MTL）模型的统一框架，通过生成器结构和嵌入正则化实现高效攻击。


<details>
  <summary>Details</summary>
Motivation: 现有不可学习策略主要针对单任务学习（STL），而多任务数据和MTL模型的重要性日益增长，但缺乏相关研究。

Method: 设计基于生成器的结构，引入标签先验和类特征嵌入，结合任务内和任务间嵌入正则化。

Result: 在4个MTL数据集、3种基础UE方法、5种模型架构和5种MTL任务加权策略上表现优异。

Conclusion: MTL-UE为多任务场景提供了高效且通用的不可学习策略。

Abstract: Most existing unlearnable strategies focus on preventing unauthorized users
from training single-task learning (STL) models with personal data.
Nevertheless, the paradigm has recently shifted towards multi-task data and
multi-task learning (MTL), targeting generalist and foundation models that can
handle multiple tasks simultaneously. Despite their growing importance, MTL
data and models have been largely neglected while pursuing unlearnable
strategies. This paper presents MTL-UE, the first unified framework for
generating unlearnable examples for multi-task data and MTL models. Instead of
optimizing perturbations for each sample, we design a generator-based structure
that introduces label priors and class-wise feature embeddings which leads to
much better attacking performance. In addition, MTL-UE incorporates intra-task
and inter-task embedding regularization to increase inter-class separation and
suppress intra-class variance which enhances the attack robustness greatly.
Furthermore, MTL-UE is versatile with good supports for dense prediction tasks
in MTL. It is also plug-and-play allowing integrating existing
surrogate-dependent unlearnable methods with little adaptation. Extensive
experiments show that MTL-UE achieves superior attacking performance
consistently across 4 MTL datasets, 3 base UE methods, 5 model backbones, and 5
MTL task-weighting strategies.

</details>

### [33] [Physics-Assisted and Topology-Informed Deep Learning for Weather Prediction](https://arxiv.org/abs/2505.04918)
*Jiaqi Zheng,Qing Ling,Yerong Feng*

Main category: cs.LG

TLDR: PASSAT是一种结合物理规律和地球拓扑结构的深度学习模型，用于天气预测，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在天气预测中常忽略物理规律或地球拓扑结构，PASSAT旨在解决这一问题。

Method: PASSAT通过求解球面上的平流方程和Navier-Stokes方程，并结合球形图神经网络捕捉地球-大气相互作用。

Result: 在5.625°分辨率的ERA5数据集上，PASSAT表现优于现有深度学习模型和IFS T42数值模型。

Conclusion: PASSAT通过结合物理规律和拓扑结构，显著提升了天气预测的准确性。

Abstract: Although deep learning models have demonstrated remarkable potential in
weather prediction, most of them overlook either the \textbf{physics} of the
underlying weather evolution or the \textbf{topology} of the Earth's surface.
In light of these disadvantages, we develop PASSAT, a novel Physics-ASSisted
And Topology-informed deep learning model for weather prediction. PASSAT
attributes the weather evolution to two key factors: (i) the advection process
that can be characterized by the advection equation and the Navier-Stokes
equation; (ii) the Earth-atmosphere interaction that is difficult to both model
and calculate. PASSAT also takes the topology of the Earth's surface into
consideration, other than simply treating it as a plane. With these
considerations, PASSAT numerically solves the advection equation and the
Navier-Stokes equation on the spherical manifold, utilizes a spherical graph
neural network to capture the Earth-atmosphere interaction, and generates the
initial velocity fields that are critical to solving the advection equation
from the same spherical graph neural network. In the $5.625^\circ$-resolution
ERA5 data set, PASSAT outperforms both the state-of-the-art deep learning-based
weather prediction models and the operational numerical weather prediction
model IFS T42. Code and checkpoint are available at
https://github.com/Yumenomae/PASSAT_5p625.

</details>

### [34] [Fair Uncertainty Quantification for Depression Prediction](https://arxiv.org/abs/2505.04931)
*Yonghong Li,Xiuzhuang Zhou*

Main category: cs.LG

TLDR: 提出了一种公平不确定性量化方法（FUQ），用于抑郁症预测，结合预测可靠性和算法公平性。


<details>
  <summary>Details</summary>
Motivation: 现有研究较少关注不确定性量化（UQ）在抑郁症预测中的公平性，而公平且可靠的预测对临床应用至关重要。

Method: 通过基于群体的分析，利用共形预测量化各人口群体的不确定性，并提出公平感知优化策略。

Result: 在多个视觉和音频抑郁症数据集上的评估表明，FUQ方法有效。

Conclusion: FUQ方法实现了可靠且公平的抑郁症预测，适用于不同人口群体。

Abstract: Trustworthy depression prediction based on deep learning, incorporating both
predictive reliability and algorithmic fairness across diverse demographic
groups, is crucial for clinical application. Recently, achieving reliable
depression predictions through uncertainty quantification has attracted
increasing attention. However, few studies have focused on the fairness of
uncertainty quantification (UQ) in depression prediction. In this work, we
investigate the algorithmic fairness of UQ, namely Equal Opportunity Coverage
(EOC) fairness, and propose Fair Uncertainty Quantification (FUQ) for
depression prediction. FUQ pursues reliable and fair depression predictions
through group-based analysis. Specifically, we first group all the participants
by different sensitive attributes and leverage conformal prediction to quantify
uncertainty within each demographic group, which provides a theoretically
guaranteed and valid way to quantify uncertainty for depression prediction and
facilitates the investigation of fairness across different demographic groups.
Furthermore, we propose a fairness-aware optimization strategy that formulates
fairness as a constrained optimization problem under EOC constraints. This
enables the model to preserve predictive reliability while adapting to the
heterogeneous uncertainty levels across demographic groups, thereby achieving
optimal fairness. Through extensive evaluations on several visual and audio
depression datasets, our approach demonstrates its effectiveness.

</details>

### [35] [Structural Alignment in Link Prediction](https://arxiv.org/abs/2505.04939)
*Jeffrey Seathrún Sardina*

Main category: cs.LG

TLDR: 该论文提出了一种基于图结构优先的视角来重新分析知识图谱（KGs）和链接预测任务，强调以整体三元组而非单独节点和边来建模KG信息。


<details>
  <summary>Details</summary>
Motivation: 现有链接预测方法主要基于嵌入范式，但该论文认为从图结构优先的角度出发可能更有效，尤其是对跨KG的迁移学习。

Method: 通过文献综述和两组核心实验，验证了结构优先视角的可行性，并提出了结构对齐假设。

Result: 实验表明结构优先视角不仅可行，还能促进对KG学习的理解和跨KG迁移学习的实现。

Conclusion: 论文提出结构对齐假设，认为链接预测可视为结构任务，并开源了所有代码和数据，同时提供了爱尔兰语翻译的机器学习术语词典。

Abstract: While Knowledge Graphs (KGs) have become increasingly popular across various
scientific disciplines for their ability to model and interlink huge quantities
of data, essentially all real-world KGs are known to be incomplete. As such,
with the growth of KG use has been a concurrent development of machine learning
tools designed to predict missing information in KGs, which is referred to as
the Link Prediction Task. The majority of state-of-the-art link predictors to
date have followed an embedding-based paradigm. In this paradigm, it is assumed
that the information content of a KG is best represented by the (individual)
vector representations of its nodes and edges, and that therefore node and edge
embeddings are particularly well-suited to performing link prediction.
  This thesis proposes an alternative perspective on the field's approach to
link prediction and KG data modelling. Specifically, this work re-analyses KGs
and state-of-the-art link predictors from a graph-structure-first perspective
that models the information content of a KG in terms of whole triples, rather
than individual nodes and edges.
  Following a literature review and two core sets of experiments, this thesis
concludes that a structure-first perspective on KGs and link prediction is both
viable and useful for understanding KG learning and for enabling cross-KG
transfer learning for the link prediction task. This observation is used to
create and propose the Structural Alignment Hypothesis, which postulates that
link prediction can be understood and modelled as a structural task.
  All code and data used for this thesis are open-sourced. This thesis was
written bilingually, with the main document in English and an informal extended
summary in Irish. An Irish-language translation dictionary of machine learning
terms (the Focl\'oir Tr\'achtais) created for this work is open-sourced as
well.

</details>

### [36] [Graffe: Graph Representation Learning via Diffusion Probabilistic Models](https://arxiv.org/abs/2505.04956)
*Dingshuo Chen,Shuchen Xue,Liuji Chen,Yingheng Wang,Qiang Liu,Shu Wu,Zhi-Ming Ma,Liang Wang*

Main category: cs.LG

TLDR: Graffe是一种自监督扩散模型，用于图表示学习，通过图编码器和扩散解码器实现，理论证明去噪目标隐含地最大化数据与其表示的条件互信息，并在多个数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 扩散概率模型（DPMs）在生成高质量样本方面表现突出，但在表示学习中的应用尚未充分探索，尤其是在图表示学习中。本文旨在填补这一空白。

Method: 提出Graffe模型，包含图编码器和扩散解码器，通过去噪目标优化条件互信息，理论证明其有效性，并在实验中验证。

Result: Graffe在11个真实数据集中的9个上取得最优性能，验证了扩散模型在图表示学习中的潜力。

Conclusion: 扩散模型是图表示学习的有效工具，Graffe为这一领域提供了理论和实践支持。

Abstract: Diffusion probabilistic models (DPMs), widely recognized for their potential
to generate high-quality samples, tend to go unnoticed in representation
learning. While recent progress has highlighted their potential for capturing
visual semantics, adapting DPMs to graph representation learning remains in its
infancy. In this paper, we introduce Graffe, a self-supervised diffusion model
proposed for graph representation learning. It features a graph encoder that
distills a source graph into a compact representation, which, in turn, serves
as the condition to guide the denoising process of the diffusion decoder. To
evaluate the effectiveness of our model, we first explore the theoretical
foundations of applying diffusion models to representation learning, proving
that the denoising objective implicitly maximizes the conditional mutual
information between data and its representation. Specifically, we prove that
the negative logarithm of the denoising score matching loss is a tractable
lower bound for the conditional mutual information. Empirically, we conduct a
series of case studies to validate our theoretical insights. In addition,
Graffe delivers competitive results under the linear probing setting on node
and graph classification tasks, achieving state-of-the-art performance on 9 of
the 11 real-world datasets. These findings indicate that powerful generative
models, especially diffusion models, serve as an effective tool for graph
representation learning.

</details>

### [37] [General Transform: A Unified Framework for Adaptive Transform to Enhance Representations](https://arxiv.org/abs/2505.04969)
*Gekko Budiutama,Shunsuke Daimon,Hirofumi Nishi,Yu-ichiro Matsushita*

Main category: cs.LG

TLDR: 提出了一种自适应变换方法（GT），通过学习数据驱动的映射，优于传统变换方法，适用于多种机器学习任务。


<details>
  <summary>Details</summary>
Motivation: 传统离散变换（如傅里叶变换）依赖对数据集特性的了解，缺乏适应性。

Method: 提出General Transform（GT），学习数据驱动的映射以适应数据集和任务。

Result: GT在计算机视觉和自然语言处理任务中表现优于传统变换方法。

Conclusion: GT是一种有效的自适应变换方法，适用于多样化的学习场景。

Abstract: Discrete transforms, such as the discrete Fourier transform, are widely used
in machine learning to improve model performance by extracting meaningful
features. However, with numerous transforms available, selecting an appropriate
one often depends on understanding the dataset's properties, making the
approach less effective when such knowledge is unavailable. In this work, we
propose General Transform (GT), an adaptive transform-based representation
designed for machine learning applications. Unlike conventional transforms, GT
learns data-driven mapping tailored to the dataset and task of interest. Here,
we demonstrate that models incorporating GT outperform conventional
transform-based approaches across computer vision and natural language
processing tasks, highlighting its effectiveness in diverse learning scenarios.

</details>

### [38] [Graph Neural Network Aided Deep Reinforcement Learning for Resource Allocation in Dynamic Terahertz UAV Networks](https://arxiv.org/abs/2505.04981)
*Zhifeng Hu,Chong Han*

Main category: cs.LG

TLDR: 提出了一种基于图神经网络和深度强化学习的资源分配算法（GLOVE），用于动态THz无人机网络中的功率和天线阵列资源分配，以最大化资源效率。


<details>
  <summary>Details</summary>
Motivation: 解决动态拓扑下THz无人机网络中功率和天线阵列资源分配的复杂性问题，该问题具有非凸性和NP难性。

Method: 结合图神经网络（GNN）和深度强化学习（DRL），强调自节点特征，并利用多任务结构协同训练所有无人机的资源分配决策。

Result: GLOVE在资源效率和延迟方面优于基准方案，且在训练过程中保持零丢包，表现出更好的鲁棒性。

Conclusion: GLOVE算法在动态THz无人机网络中表现出高效、低延迟和强鲁棒性，适用于实际应用。

Abstract: Terahertz (THz) unmanned aerial vehicle (UAV) networks with flexible
topologies and ultra-high data rates are expected to empower numerous
applications in security surveillance, disaster response, and environmental
monitoring, among others. However, the dynamic topologies hinder the efficient
long-term joint power and antenna array resource allocation for THz links among
UAVs. Furthermore, the continuous nature of power and the discrete nature of
antennas cause this joint resource allocation problem to be a mixed-integer
nonlinear programming (MINLP) problem with non-convexity and NP-hardness.
Inspired by recent rapid advancements in deep reinforcement learning (DRL), a
graph neural network (GNN) aided DRL algorithm for resource allocation in the
dynamic THz UAV network with an emphasis on self-node features (GLOVE) is
proposed in this paper, with the aim of resource efficiency (RE) maximization.
When training the allocation policy for each UAV, GLOVE learns the relationship
between this UAV and its neighboring UAVs via GNN, while also emphasizing the
important self-node features of this UAV. In addition, a multi-task structure
is leveraged by GLOVE to cooperatively train resource allocation decisions for
the power and sub-arrays of all UAVs. Experimental results illustrate that
GLOVE outperforms benchmark schemes in terms of the highest RE and the lowest
latency. Moreover, unlike the benchmark methods with severe packet loss, GLOVE
maintains zero packet loss during the entire training process, demonstrating
its better robustness under the highly dynamic THz UAV network.

</details>

### [39] [Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints](https://arxiv.org/abs/2505.05019)
*Waldemar Hahn,Jan-Niklas Eckardt,Christoph Röllig,Martin Sedlmayr,Jan Moritz Middeke,Markus Wolfien*

Main category: cs.LG

TLDR: 研究评估了四种超参数优化策略对生成合成临床试验数据的影响，发现复合指标优化优于单一指标优化，但需结合领域知识确保数据有效性。


<details>
  <summary>Details</summary>
Motivation: 解决合成临床数据在隐私保护和数据可访问性方面的挑战，同时确保数据的高保真度和实用性。

Method: 系统评估四种超参数优化策略在八种生成模型中的表现，比较单一指标与复合指标优化方法。

Result: 超参数优化显著提升数据质量，TVAE、CTGAN和CTAB-GAN+分别提升60%、39%和38%，但需预处理和后处理确保临床有效性。

Conclusion: 结合领域知识和优化策略是生成高质量合成临床数据的关键，未来需进一步优化指标选择和验证大规模数据集。

Abstract: The generation of synthetic clinical trial data offers a promising approach
to mitigating privacy concerns and data accessibility limitations in medical
research. However, ensuring that synthetic datasets maintain high fidelity,
utility, and adherence to domain-specific constraints remains a key challenge.
While hyperparameter optimization (HPO) has been shown to improve generative
model performance, the effectiveness of different optimization strategies for
synthetic clinical data remains unclear. This study systematically evaluates
four HPO strategies across eight generative models, comparing single-metric
optimization against compound metric optimization approaches. Our results
demonstrate that HPO consistently improves synthetic data quality, with TVAE,
CTGAN, and CTAB-GAN+ achieving improvements of up to 60%, 39%, and 38%,
respectively. Compound metric optimization outperformed single-metric
strategies, producing more balanced and generalizable synthetic datasets.
Interestingly, HPO alone is insufficient to ensure clinically valid synthetic
data, as all models exhibited violations of fundamental survival constraints.
Preprocessing and postprocessing played a crucial role in reducing these
violations, as models lacking robust processing steps produced invalid data in
up to 61% of cases. These findings underscore the necessity of integrating
explicit domain knowledge alongside HPO to create high quality synthetic
datasets. Our study provides actionable recommendations for improving synthetic
data generation, with future research needed to refine metric selection and
validate these findings on larger datasets to enhance clinical applicability.

</details>

### [40] [Generative Models for Long Time Series: Approximately Equivariant Recurrent Network Structures for an Adjusted Training Scheme](https://arxiv.org/abs/2505.05020)
*Ruwen Fulek,Markus Lange-Hegermann*

Main category: cs.LG

TLDR: 提出了一种基于变分自编码器（VAE）的生成模型RVAE-ST，通过逐步增加序列长度的训练方案解决了长序列建模问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统循环层在建模长序列时的挑战，同时保持参数数量不变。

Method: 采用变分自编码器结合循环层，逐步增加序列长度的训练方案。

Result: 在多个基准数据集上表现优异，尤其适用于准周期性时间序列。

Conclusion: 通过组合已知组件，RVAE-ST在生成模型中表现出色，适用于多种时间序列类型。

Abstract: We present a simple yet effective generative model for time series data based
on a Variational Autoencoder (VAE) with recurrent layers, referred to as the
Recurrent Variational Autoencoder with Subsequent Training (RVAE-ST). Our
method introduces an adapted training scheme that progressively increases the
sequence length, addressing the challenge recurrent layers typically face when
modeling long sequences. By leveraging the recurrent architecture, the model
maintains a constant number of parameters regardless of sequence length. This
design encourages approximate time-shift equivariance and enables efficient
modeling of long-range temporal dependencies. Rather than introducing a
fundamentally new architecture, we show that a carefully composed combination
of known components can match or outperform state-of-the-art generative models
on several benchmark datasets. Our model performs particularly well on time
series that exhibit quasi-periodic structure,while remaining competitive on
datasets with more irregular or partially non-stationary behavior. We evaluate
its performance using ELBO, Fr\'echet Distance, discriminative scores, and
visualizations of the learned embeddings.

</details>

### [41] [Dequantified Diffusion Schrödinger Bridge for Density Ratio Estimation](https://arxiv.org/abs/2505.05034)
*Wei Chen,Shigui Li,Jiacheng Li,Junmei Yang,John Paisley,Delu Zeng*

Main category: cs.LG

TLDR: 提出了一种名为D³RE的统一框架，通过扩散桥和高斯去量化解决密度比估计中的密度鸿沟和支持鸿沟问题，提高了稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在分布差异大或支持集重叠不足时表现不佳，存在密度鸿沟和支持鸿沟问题，且边界附近的时间分数不稳定。

Method: 引入DDBI（扩散桥插值和去量化）和DSBI（结合最优传输的Schrödinger桥插值），扩展支持集覆盖并稳定时间分数。

Result: 理论证明具有均匀逼近和有界时间分数，实验在互信息和密度估计任务中优于基线方法。

Conclusion: D³RE框架通过扩散桥和最优传输技术，显著提升了密度比估计的鲁棒性和效率。

Abstract: Density ratio estimation is fundamental to tasks involving $f$-divergences,
yet existing methods often fail under significantly different distributions or
inadequately overlap supports, suffering from the \textit{density-chasm} and
the \textit{support-chasm} problems. Additionally, prior approaches yield
divergent time scores near boundaries, leading to instability. We propose
$\text{D}^3\text{RE}$, a unified framework for robust and efficient density
ratio estimation. It introduces the Dequantified Diffusion-Bridge Interpolant
(DDBI), which expands support coverage and stabilizes time scores via diffusion
bridges and Gaussian dequantization. Building on DDBI, the Dequantified
Schr\"odinger-Bridge Interpolant (DSBI) incorporates optimal transport to solve
the Schr\"odinger bridge problem, enhancing accuracy and efficiency. Our method
offers uniform approximation and bounded time scores in theory, and outperforms
baselines empirically in mutual information and density estimation tasks.

</details>

### [42] [Neural Pathways to Program Success: Hopfield Networks for PERT Analysis](https://arxiv.org/abs/2505.05047)
*Azgar Ali Noor Ahamed*

Main category: cs.LG

TLDR: 论文提出了一种基于Hopfield神经网络的PERT调度方法，将任务调度建模为能量最小化问题，并通过神经网络优化动态实现全局一致的调度。


<details>
  <summary>Details</summary>
Motivation: 项目管理中任务持续时间和依赖关系的不确定性是核心挑战，传统PERT技术需要更高效的优化方法。

Method: 将任务开始时间和优先级约束映射到Hopfield神经网络中，利用其优化动态近似全局一致调度。

Result: 在包含1000个任务的合成项目网络上验证了方法的可行性，实现了接近最优的完成时间且约束违反最少。

Conclusion: 神经优化模型为不确定环境下的可扩展和自适应任务调度提供了有前景的方向。

Abstract: Project and task scheduling under uncertainty remains a fundamental challenge
in program and project management, where accurate estimation of task durations
and dependencies is critical for delivering complex, multi project systems. The
Program Evaluation and Review Technique provides a probabilistic framework to
model task variability and critical paths. In this paper, the author presents a
novel formulation of PERT scheduling as an energy minimization problem within a
Hopfield neural network architecture. By mapping task start times and
precedence constraints into a neural computation framework, the networks
inherent optimization dynamics is exploited to approximate globally consistent
schedules. The author addresses key theoretical issues related to energy
function differentiability, constraint encoding, and convergence, and extends
the Hopfield model for structured precedence graphs. Numerical simulations on
synthetic project networks comprising up to 1000 tasks demonstrate the
viability of this approach, achieving near optimal makespans with minimal
constraint violations. The findings suggest that neural optimization models
offer a promising direction for scalable and adaptive project tasks scheduling
under uncertainty in areas such as the agentic AI workflows, microservice based
applications that the modern AI systems are being built upon.

</details>

### [43] [CodeMixBench: Evaluating Large Language Models on Code Generation with Code-Mixed Prompts](https://arxiv.org/abs/2505.05063)
*Manik Sheokand,Parth Sawant*

Main category: cs.LG

TLDR: CodeMixBench是一个新的基准测试，用于评估大型语言模型在多语言代码混合提示下的代码生成能力，填补了现有基准测试仅关注英语提示的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试如HumanEval和MBPP仅评估英语提示下的代码生成能力，忽略了多语言开发者在实际中使用代码混合语言的场景。

Method: 基于BigCodeBench，CodeMixBench在提示的自然语言部分引入了三种语言对的代码混合（CMD）：Hinglish、西班牙语-英语和汉语拼音-英语，并评估了多个开源代码生成模型。

Result: 代码混合提示显著降低了Pass@1性能，尤其是对较小模型在高CMD水平下表现更差。

Conclusion: CodeMixBench为多语言代码生成提供了更现实的评估框架，并指出了构建在多语言环境下鲁棒的代码生成模型的新挑战和方向。

Abstract: Large Language Models (LLMs) have achieved remarkable success in code
generation tasks, powering various applications like code completion,
debugging, and programming assistance. However, existing benchmarks such as
HumanEval, MBPP, and BigCodeBench primarily evaluate LLMs on English-only
prompts, overlooking the real-world scenario where multilingual developers
often use code-mixed language while interacting with LLMs. To address this gap,
we introduce CodeMixBench, a novel benchmark designed to evaluate the
robustness of LLMs on code generation from code-mixed prompts. Built upon
BigCodeBench, CodeMixBench introduces controlled code-mixing (CMD) into the
natural language parts of prompts across three language pairs: Hinglish
(Hindi-English), Spanish-English, and Chinese Pinyin-English. We
comprehensively evaluate a diverse set of open-source code generation models
ranging from 1.5B to 15B parameters. Our results show that code-mixed prompts
consistently degrade Pass@1 performance compared to their English-only
counterparts, with performance drops increasing under higher CMD levels for
smaller models. CodeMixBench provides a realistic evaluation framework for
studying multilingual code generation and highlights new challenges and
directions for building robust code generation models that generalize well
across diverse linguistic settings.

</details>

### [44] [WaterDrum: Watermarking for Data-centric Unlearning Metric](https://arxiv.org/abs/2505.05064)
*Xinyang Lu,Xinyuan Niu,Gregory Kang Ruey Lau,Bui Thi Cam Nhung,Rachael Hwee Ling Sim,Fanyu Wen,Chuan-Sheng Foo,See-Kiong Ng,Bryan Kian Hsiang Low*

Main category: cs.LG

TLDR: 本文提出了一种名为WaterDrum的数据中心化遗忘度量方法，用于解决现有基于模型效用的遗忘度量在现实场景中的局限性，并引入了新的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 在现实应用中，需要高效地从大型语言模型（LLM）中移除私有、受版权保护或有害数据的影响，但现有基于效用的遗忘度量无法准确评估遗忘程度。

Method: 利用鲁棒文本水印技术，提出了一种数据中心化的遗忘度量方法WaterDrum，并开发了包含不同相似度数据的新基准数据集。

Result: WaterDrum能够克服现有方法的局限性，并在新基准数据集上进行了严格的评估。

Conclusion: WaterDrum为LLM遗忘提供了一种更准确的评估工具，新数据集为未来研究提供了支持。

Abstract: Large language model (LLM) unlearning is critical in real-world applications
where it is necessary to efficiently remove the influence of private,
copyrighted, or harmful data from some users. However, existing utility-centric
unlearning metrics (based on model utility) may fail to accurately evaluate the
extent of unlearning in realistic settings such as when (a) the forget and
retain set have semantically similar content, (b) retraining the model from
scratch on the retain set is impractical, and/or (c) the model owner can
improve the unlearning metric without directly performing unlearning on the
LLM. This paper presents the first data-centric unlearning metric for LLMs
called WaterDrum that exploits robust text watermarking for overcoming these
limitations. We also introduce new benchmark datasets for LLM unlearning that
contain varying levels of similar data points and can be used to rigorously
evaluate unlearning algorithms using WaterDrum. Our code is available at
https://github.com/lululu008/WaterDrum and our new benchmark datasets are
released at https://huggingface.co/datasets/Glow-AI/WaterDrum-Ax.

</details>

### [45] [ItDPDM: Information-Theoretic Discrete Poisson Diffusion Model](https://arxiv.org/abs/2505.05082)
*Sagnik Bhattacharya,Abhiram R. Gorle,Ahmed Mohsin,Ahsan Bilal,Connor Ding,Amit Kumar Singh Yadav,Tsachy Weissman*

Main category: cs.LG

TLDR: 论文提出了一种名为ItDPDM的新方法，直接在离散状态空间中操作，解决了现有生成模型的两大挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法在离散数据生成建模中存在两个主要问题：一是将离散输入嵌入连续状态空间，二是依赖近似负对数似然的变分损失。

Method: 引入信息论离散泊松扩散模型（ItDPDM），通过泊松扩散过程直接在离散状态空间中操作，并提出泊松重建损失（PRL）。

Result: 在Lakh MIDI和CIFAR-10数据集上，ItDPDM显著降低了测试负对数似然（NLL）达80%，并实现了更快的收敛。

Conclusion: ItDPDM通过直接离散建模和精确损失计算，显著提升了生成模型的性能。

Abstract: Existing methods for generative modeling of discrete data, such as symbolic
music tokens, face two primary challenges: (1) they either embed discrete
inputs into continuous state-spaces or (2) rely on variational losses that only
approximate the true negative log-likelihood. Previous efforts have
individually targeted these limitations. While information-theoretic Gaussian
diffusion models alleviate the suboptimality of variational losses, they still
perform modeling in continuous domains. In this work, we introduce the
Information-Theoretic Discrete Poisson Diffusion Model (ItDPDM), which
simultaneously addresses both limitations by directly operating in a discrete
state-space via a Poisson diffusion process inspired by photon arrival
processes in camera sensors. We introduce a novel Poisson Reconstruction Loss
(PRL) and derive an exact relationship between PRL and the true negative
log-likelihood, thereby eliminating the need for approximate evidence lower
bounds. Experiments conducted on the Lakh MIDI symbolic music dataset and the
CIFAR-10 image benchmark demonstrate that ItDPDM delivers significant
improvements, reducing test NLL by up to 80% compared to prior baselines, while
also achieving faster convergence.

</details>

### [46] [Beyond Low-rank Decomposition: A Shortcut Approach for Efficient On-Device Learning](https://arxiv.org/abs/2505.05086)
*Le-Trung Nguyen,Ael Quelennec,Van-Tam Nguyen,Enzo Tartaglione*

Main category: cs.LG

TLDR: 提出一种新型快捷方法，用于减少设备端学习中的激活内存使用和计算量，显著优于传统训练方法。


<details>
  <summary>Details</summary>
Motivation: 设备端学习具有减少延迟和隐私风险的优势，但内存和计算限制仍是主要挑战。

Method: 采用低秩分解方法的快捷替代方案，优化激活内存和计算效率。

Result: 实验显示，激活内存使用减少高达120.09倍，训练FLOPs减少1.86倍。

Conclusion: 该方法有效解决了设备端学习的内存和计算瓶颈，具有实际应用潜力。

Abstract: On-device learning has emerged as a promising direction for AI development,
particularly because of its potential to reduce latency issues and mitigate
privacy risks associated with device-server communication, while improving
energy efficiency. Despite these advantages, significant memory and
computational constraints still represent major challenges for its deployment.
Drawing on previous studies on low-rank decomposition methods that address
activation memory bottlenecks in backpropagation, we propose a novel shortcut
approach as an alternative. Our analysis and experiments demonstrate that our
method can reduce activation memory usage, even up to $120.09\times$ compared
to vanilla training, while also reducing overall training FLOPs up to
$1.86\times$ when evaluated on traditional benchmarks.

</details>

### [47] [A Conjoint Graph Representation Learning Framework for Hypertension Comorbidity Risk Prediction](https://arxiv.org/abs/2505.05094)
*Leming Zhou,Zuo Wang,Zhixuan Duan*

Main category: cs.LG

TLDR: 该研究提出了一种联合图表示学习框架（CGRL），用于早期识别高血压并发症，预测糖尿病和冠心病风险，并揭示疾病进展的病理机制。


<details>
  <summary>Details</summary>
Motivation: 高血压并发症对患者和社会造成沉重负担，早期识别具有挑战性。研究旨在通过结合图学习和网络分析解决这一问题。

Method: 构建基于疾病编码的患者网络和疾病差异网络，生成三种并发症网络特征，结合计算结构干预和学习特征表示，预测糖尿病和冠心病风险。

Result: 基于差异网络提取的网络特征重要，CGRL框架在预测准确性上优于其他模型。

Conclusion: CGRL框架能更准确地预测并发症风险，并揭示疾病进展的病理机制。

Abstract: The comorbidities of hypertension impose a heavy burden on patients and
society. Early identification is necessary to prompt intervention, but it
remains a challenging task. This study aims to address this challenge by
combining joint graph learning with network analysis. Motivated by this
discovery, we develop a Conjoint Graph Representation Learning (CGRL) framework
that: a) constructs two networks based on disease coding, including the patient
network and the disease difference network. Three comorbidity network features
were generated based on the basic difference network to capture the potential
relationship between comorbidities and risk diseases; b) incorporates
computational structure intervention and learning feature representation, CGRL
was developed to predict the risks of diabetes and coronary heart disease in
patients; and c) analysis the comorbidity patterns and exploring the pathways
of disease progression, the pathological pathogenesis of diabetes and coronary
heart disease may be revealed. The results show that the network features
extracted based on the difference network are important, and the framework we
proposed provides more accurate predictions than other strong models in terms
of accuracy.

</details>

### [48] [Balancing Client Participation in Federated Learning Using AoI](https://arxiv.org/abs/2505.05099)
*Alireza Javani,Zhiying Wang*

Main category: cs.LG

TLDR: 本文提出了一种基于信息年龄（AoI）的客户端选择策略，通过控制选择间隔最小化负载不平衡，解决了联邦学习中的通信资源限制、统计异质性和客户端参与平衡问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在保护数据隐私的同时实现分布式客户端协作训练，但面临通信资源有限、统计异质性和客户端参与不平衡的挑战。

Method: 采用去中心化的马尔可夫调度策略，客户端根据年龄相关选择概率独立管理参与，平衡训练轮次中的更新，减少中心干预。

Result: 通过收敛性证明和仿真实验，AoI方法（尤其是最优马尔可夫变体）在IID和非IID数据设置下分别比FedAvg方法提高了7.5%和20%的收敛性能。

Conclusion: AoI调度策略在多样化学习环境中实现了可扩展、公平且高效的联邦学习系统。

Abstract: Federated Learning (FL) offers a decentralized framework that preserves data
privacy while enabling collaborative model training across distributed clients.
However, FL faces significant challenges due to limited communication
resources, statistical heterogeneity, and the need for balanced client
participation. This paper proposes an Age of Information (AoI)-based client
selection policy that addresses these challenges by minimizing load imbalance
through controlled selection intervals. Our method employs a decentralized
Markov scheduling policy, allowing clients to independently manage
participation based on age-dependent selection probabilities, which balances
client updates across training rounds with minimal central oversight. We
provide a convergence proof for our method, demonstrating that it ensures
stable and efficient model convergence. Specifically, we derive optimal
parameters for the Markov selection model to achieve balanced and consistent
client participation, highlighting the benefits of AoI in enhancing convergence
stability. Through extensive simulations, we demonstrate that our AoI-based
method, particularly the optimal Markov variant, improves convergence over the
FedAvg selection approach across both IID and non-IID data settings by $7.5\%$
and up to $20\%$. Our findings underscore the effectiveness of AoI-based
scheduling for scalable, fair, and efficient FL systems across diverse learning
environments.

</details>

### [49] [USPR: Learning a Unified Solver for Profiled Routing](https://arxiv.org/abs/2505.05119)
*Chuanbo Hua,Federico Berto,Zhikai Zhao,Jiwoo Son,Changhyun Kwon,Jinkyoo Park*

Main category: cs.LG

TLDR: USPR（统一求解器）通过创新的嵌入和注意力机制解决了PVRP中RL方法的局限性，实现了更高的灵活性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有RL方法在PVRP中因分布变化导致的泛化能力差和训练成本高的问题。

Method: 引入Profile Embeddings、Multi-Head Profiled Attention和Profile-aware Score Reshaping三项创新技术。

Result: 在多种PVRP基准测试中达到学习方法的最高水平，显著提升灵活性和效率。

Conclusion: USPR为PVRP提供了一种高效且灵活的解决方案，代码已开源以促进研究。

Abstract: The Profiled Vehicle Routing Problem (PVRP) extends the classical VRP by
incorporating vehicle-client-specific preferences and constraints, reflecting
real-world requirements such as zone restrictions and service-level
preferences. While recent reinforcement learning (RL) solvers have shown
promise, they require retraining for each new profile distribution, suffer from
poor representation ability, and struggle to generalize to out-of-distribution
instances. In this paper, we address these limitations by introducing USPR
(Unified Solver for Profiled Routing), a novel framework that natively handles
arbitrary profile types. USPR introduces three key innovations: (i) Profile
Embeddings (PE) to encode any combination of profile types; (ii) Multi-Head
Profiled Attention (MHPA), an attention mechanism that models rich interactions
between vehicles and clients; (iii) Profile-aware Score Reshaping (PSR), which
dynamically adjusts decoder logits using profile scores to improve
generalization. Empirical results on diverse PVRP benchmarks demonstrate that
USPR achieves state-of-the-art results among learning-based methods while
offering significant gains in flexibility and computational efficiency. We make
our source code publicly available to foster future research at
https://github.com/ai4co/uspr.

</details>

### [50] [Taming OOD Actions for Offline Reinforcement Learning: An Advantage-Based Approach](https://arxiv.org/abs/2505.05126)
*Xuyang Chen,Keyu Yan,Lin Zhao*

Main category: cs.LG

TLDR: ADAC是一种新的离线强化学习方法，通过优势调制评估OOD动作，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 离线RL存在分布偏移问题，现有方法对所有OOD动作保守处理，限制了泛化能力。

Method: 提出ADAC方法，利用批量最优值函数评估OOD动作，并通过优势函数调制Q函数更新。

Result: 在D4RL基准测试中表现优异，尤其在复杂任务上优势明显。

Conclusion: ADAC通过精确评估OOD动作，显著提升了离线RL的性能和泛化能力。

Abstract: Offline reinforcement learning (RL) aims to learn decision-making policies
from fixed datasets without online interactions, providing a practical solution
where online data collection is expensive or risky. However, offline RL often
suffers from distribution shift, resulting in inaccurate evaluation and
substantial overestimation on out-of-distribution (OOD) actions. To address
this, existing approaches incorporate conservatism by indiscriminately
discouraging all OOD actions, thereby hindering the agent's ability to
generalize and exploit beneficial ones. In this paper, we propose
Advantage-based Diffusion Actor-Critic (ADAC), a novel method that
systematically evaluates OOD actions using the batch-optimal value function.
Based on this evaluation, ADAC defines an advantage function to modulate the
Q-function update, enabling more precise assessment of OOD action quality. We
design a custom PointMaze environment and collect datasets to visually reveal
that advantage modulation can effectively identify and select superior OOD
actions. Extensive experiments show that ADAC achieves state-of-the-art
performance on almost all tasks in the D4RL benchmark, with particularly clear
margins on the more challenging tasks.

</details>

### [51] [Research on Anomaly Detection Methods Based on Diffusion Models](https://arxiv.org/abs/2505.05137)
*Yi Chen*

Main category: cs.LG

TLDR: 提出了一种基于扩散概率模型（DPMs）的异常检测新框架，结合多尺度特征提取和注意力机制，在图像和音频数据中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理复杂高维数据分布时存在挑战，扩散模型在异常检测中的潜力尚未充分探索。

Method: 通过扩散过程建模正常数据分布，利用重构误差和语义差异作为异常指标，引入多尺度特征提取和注意力机制。

Result: 在MVTec AD和UrbanSound8K等基准数据集上优于现有技术，表现出更高的准确性和鲁棒性。

Conclusion: 扩散模型在异常检测中具有高效性和鲁棒性，为实际应用提供了可靠解决方案。

Abstract: Anomaly detection is a fundamental task in machine learning and data mining,
with significant applications in cybersecurity, industrial fault diagnosis, and
clinical disease monitoring. Traditional methods, such as statistical modeling
and machine learning-based approaches, often face challenges in handling
complex, high-dimensional data distributions. In this study, we explore the
potential of diffusion models for anomaly detection, proposing a novel
framework that leverages the strengths of diffusion probabilistic models (DPMs)
to effectively identify anomalies in both image and audio data. The proposed
method models the distribution of normal data through a diffusion process and
reconstructs input data via reverse diffusion, using a combination of
reconstruction errors and semantic discrepancies as anomaly indicators. To
enhance the framework's performance, we introduce multi-scale feature
extraction, attention mechanisms, and wavelet-domain representations, enabling
the model to capture fine-grained structures and global dependencies in the
data. Extensive experiments on benchmark datasets, including MVTec AD and
UrbanSound8K, demonstrate that our method outperforms state-of-the-art anomaly
detection techniques, achieving superior accuracy and robustness across diverse
data modalities. This research highlights the effectiveness of diffusion models
in anomaly detection and provides a robust and efficient solution for
real-world applications.

</details>

### [52] [Sparse Training from Random Initialization: Aligning Lottery Ticket Masks using Weight Symmetry](https://arxiv.org/abs/2505.05143)
*Mohammed Adnan,Rohan Jain,Ekansh Sharma,Rahul Krishnan,Yani Ioannou*

Main category: cs.LG

TLDR: 论文提出通过排列稀疏掩码对齐优化盆地，显著提高了稀疏训练模型的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 探索彩票假设（LTH）稀疏掩码无法泛化到新随机初始化的原因，并提出解决方案。

Method: 通过排列LTH掩码以对齐新的优化盆地，进行稀疏训练。

Result: 在多个数据集和模型上，使用排列掩码的稀疏训练显著提高了泛化性能。

Conclusion: 排列LTH掩码是对齐优化盆地、提升稀疏训练泛化能力的有效方法。

Abstract: The Lottery Ticket Hypothesis (LTH) suggests there exists a sparse LTH mask
and weights that achieve the same generalization performance as the dense model
while using significantly fewer parameters. However, finding a LTH solution is
computationally expensive, and a LTH sparsity mask does not generalize to other
random weight initializations. Recent work has suggested that neural networks
trained from random initialization find solutions within the same basin modulo
permutation, and proposes a method to align trained models within the same loss
basin. We hypothesize that misalignment of basins is the reason why LTH masks
do not generalize to new random initializations and propose permuting the LTH
mask to align with the new optimization basin when performing sparse training
from a different random init. We empirically show a significant increase in
generalization when sparse training from random initialization with the
permuted mask as compared to using the non-permuted LTH mask, on multiple
datasets (CIFAR-10, CIFAR-100 and ImageNet) and models (VGG11, ResNet20 and
ResNet50).

</details>

### [53] [Understanding In-context Learning of Addition via Activation Subspaces](https://arxiv.org/abs/2505.05145)
*Xinyan Hu,Kayo Yin,Michael I. Jordan,Jacob Steinhardt,Lijie Chen*

Main category: cs.LG

TLDR: 论文研究了现代Transformer模型如何通过前向传播实现上下文学习，发现Llama-3-8B在特定任务中表现优异，并定位到三个关键注意力头。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型如何在少样本学习中提取信号、聚合规则并应用于新任务。

Method: 通过结构化少样本学习任务，分析模型前向传播中的注意力机制和低维子空间。

Result: Llama-3-8B在任务中表现优异，信号集中在六维子空间，且存在自校正机制。

Conclusion: 通过跟踪低维子空间，可以深入理解模型的计算结构。

Abstract: To perform in-context learning, language models must extract signals from
individual few-shot examples, aggregate these into a learned prediction rule,
and then apply this rule to new examples. How is this implemented in the
forward pass of modern transformer models? To study this, we consider a
structured family of few-shot learning tasks for which the true prediction rule
is to add an integer $k$ to the input. We find that Llama-3-8B attains high
accuracy on this task for a range of $k$, and localize its few-shot ability to
just three attention heads via a novel optimization approach. We further show
the extracted signals lie in a six-dimensional subspace, where four of the
dimensions track the unit digit and the other two dimensions track overall
magnitude. We finally examine how these heads extract information from
individual few-shot examples, identifying a self-correction mechanism in which
mistakes from earlier examples are suppressed by later examples. Our results
demonstrate how tracking low-dimensional subspaces across a forward pass can
provide insight into fine-grained computational structures.

</details>

### [54] [Bandit Max-Min Fair Allocation](https://arxiv.org/abs/2505.05169)
*Tsubasa Harada,Shinji Ito,Hanna Sumita*

Main category: cs.LG

TLDR: 论文研究了带有多臂老虎机反馈的公平分配问题（BMMFA），提出了一种算法，其渐进遗憾上界为$O(m\sqrt{T}\ln T/n + m\sqrt{T \ln(mnT)})$，并给出了下界$\Omega(m\sqrt{T}/n)$。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设每轮开始时物品价值已知，而本文关注的是通过半老虎机反馈观察物品价值的情况，且奖励函数在轮次间非加性。

Method: 结合老虎机技术和资源分配算法，提出了一种新算法。

Result: 算法实现了渐进遗憾上界，并证明了遗憾下界，两者在时间$T$足够大时差距为对数因子。

Conclusion: 本文为BMMFA问题提供了理论和算法支持，填补了现有研究的空白。

Abstract: In this paper, we study a new decision-making problem called the bandit
max-min fair allocation (BMMFA) problem. The goal of this problem is to
maximize the minimum utility among agents with additive valuations by
repeatedly assigning indivisible goods to them. One key feature of this problem
is that each agent's valuation for each item can only be observed through the
semi-bandit feedback, while existing work supposes that the item values are
provided at the beginning of each round. Another key feature is that the
algorithm's reward function is not additive with respect to rounds, unlike most
bandit-setting problems.
  Our first contribution is to propose an algorithm that has an asymptotic
regret bound of $O(m\sqrt{T}\ln T/n + m\sqrt{T \ln(mnT)})$, where $n$ is the
number of agents, $m$ is the number of items, and $T$ is the time horizon. This
is based on a novel combination of bandit techniques and a resource allocation
algorithm studied in the literature on competitive analysis. Our second
contribution is to provide the regret lower bound of $\Omega(m\sqrt{T}/n)$.
When $T$ is sufficiently larger than $n$, the gap between the upper and lower
bounds is a logarithmic factor of $T$.

</details>

### [55] [OpenworldAUC: Towards Unified Evaluation and Optimization for Open-world Prompt Tuning](https://arxiv.org/abs/2505.05180)
*Cong Hua,Qianqian Xu,Zhiyong Yang,Zitai Wang,Shilong Bao,Qingming Huang*

Main category: cs.LG

TLDR: 本文提出了一种新的度量标准OpenworldAUC和动态提示方法GMoP，用于在开放世界场景中统一评估和优化视觉语言模型的检测与分类性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景中模型需处理未知领域输入，而现有度量标准无法同时满足检测、分类和对领域分布不敏感的需求。

Method: 提出OpenworldAUC度量标准，通过成对实例比较评估性能；设计GMoP方法，结合领域特定提示和门控机制动态平衡任务。

Result: 在15个基准测试中，GMoP在OpenworldAUC和其他指标上达到最优性能。

Conclusion: OpenworldAUC和GMoP有效解决了开放世界中的评估和优化问题，具有理论和实验支持。

Abstract: Prompt tuning adapts Vision-Language Models like CLIP to open-world tasks
with minimal training costs. In this direction, one typical paradigm evaluates
model performance separately on known classes (i.e., base domain) and unseen
classes (i.e., new domain). However, real-world scenarios require models to
handle inputs without prior domain knowledge. This practical challenge has
spurred the development of open-world prompt tuning, which demands a unified
evaluation of two stages: 1) detecting whether an input belongs to the base or
new domain (P1), and 2) classifying the sample into its correct class (P2).
What's more, as domain distributions are generally unknown, a proper metric
should be insensitive to varying base/new sample ratios (P3). However, we find
that current metrics, including HM, overall accuracy, and AUROC, fail to
satisfy these three properties simultaneously. To bridge this gap, we propose
OpenworldAUC, a unified metric that jointly assesses detection and
classification through pairwise instance comparisons. To optimize OpenworldAUC
effectively, we introduce Gated Mixture-of-Prompts (GMoP), which employs
domain-specific prompts and a gating mechanism to dynamically balance detection
and classification. Theoretical guarantees ensure generalization of GMoP under
practical conditions. Experiments on 15 benchmarks in open-world scenarios show
GMoP achieves SOTA performance on OpenworldAUC and other metrics. We release
the code at https://github.com/huacong/OpenworldAUC

</details>

### [56] [Stochastic Variational Propagation: Local, Scalable and Efficient Alternative to Backpropagation](https://arxiv.org/abs/2505.05181)
*Bojian Yin,Federico Corradi*

Main category: cs.LG

TLDR: SVP是一种替代反向传播的层次变分推断方法，通过局部更新和低维投影解决内存和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 反向传播依赖全局梯度同步，导致内存开销大且可扩展性差。

Method: SVP将激活视为隐变量，优化局部ELBO，使用随机矩阵投影防止表示崩溃，并加入特征对齐损失保持一致性。

Result: SVP在多种架构和数据集上达到与反向传播相当的精度，内存减少4倍，可扩展性显著提升。

Conclusion: SVP为深度学习引入概率视角，推动模块化和可解释性网络设计。

Abstract: Backpropagation (BP) is the cornerstone of deep learning, but its reliance on
global gradient synchronization limits scalability and imposes significant
memory overhead. We propose Stochastic Variational Propagation (SVP), a
scalable alternative that reframes training as hierarchical variational
inference. SVP treats layer activations as latent variables and optimizes local
Evidence Lower Bounds (ELBOs), enabling independent, local updates while
preserving global coherence. However, directly applying KL divergence in
layer-wise ELBOs risks inter-layer's representation collapse due to excessive
compression. To prevent this, SVP projects activations into low-dimensional
spaces via fixed random matrices, ensuring information preservation and
representational diversity. Combined with a feature alignment loss for
inter-layer consistency, SVP achieves competitive accuracy with BP across
diverse architectures (MLPs, CNNs, Transformers) and datasets (MNIST to
ImageNet), reduces memory usage by up to 4x, and significantly improves
scalability. More broadly, SVP introduces a probabilistic perspective to deep
representation learning, opening pathways toward more modular and interpretable
neural network design.

</details>

### [57] [Long-Term Individual Causal Effect Estimation via Identifiable Latent Representation Learning](https://arxiv.org/abs/2505.05192)
*Ruichu Cai,Junjie Wan,Weilin Chen,Zeqin Yang,Zijian Li,Peng Zhen,Jiecheng Guo*

Main category: cs.LG

TLDR: 提出一种无需理想假设的方法，通过数据异质性识别潜在混杂因子，估计长期因果效应。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖理想假设（如潜在无混杂或加性等混杂偏差），实际应用中常被违反，限制了效果。

Method: 利用数据异质性（如多源数据）识别潜在混杂因子，设计基于潜在表示学习的估计器。

Result: 理论证明潜在混杂因子的可识别性，实验验证方法在合成和半合成数据集上的有效性。

Conclusion: 新方法避免了理想假设，显著提升了长期因果效应估计的实用性。

Abstract: Estimating long-term causal effects by combining long-term observational and
short-term experimental data is a crucial but challenging problem in many
real-world scenarios. In existing methods, several ideal assumptions, e.g.
latent unconfoundedness assumption or additive equi-confounding bias
assumption, are proposed to address the latent confounder problem raised by the
observational data. However, in real-world applications, these assumptions are
typically violated which limits their practical effectiveness. In this paper,
we tackle the problem of estimating the long-term individual causal effects
without the aforementioned assumptions. Specifically, we propose to utilize the
natural heterogeneity of data, such as data from multiple sources, to identify
latent confounders, thereby significantly avoiding reliance on idealized
assumptions. Practically, we devise a latent representation learning-based
estimator of long-term causal effects. Theoretically, we establish the
identifiability of latent confounders, with which we further achieve long-term
effect identification. Extensive experimental studies, conducted on multiple
synthetic and semi-synthetic datasets, demonstrate the effectiveness of our
proposed method.

</details>

### [58] [Concept-Based Unsupervised Domain Adaptation](https://arxiv.org/abs/2505.05195)
*Xinyue Xu,Yueying Hu,Hui Tang,Yi Qin,Lu Mi,Hao Wang,Xiaomeng Li*

Main category: cs.LG

TLDR: 提出了CUDA框架，通过对抗训练和对概念分布的松弛阈值，提升概念瓶颈模型在域适应中的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统概念瓶颈模型（CBMs）在域偏移下性能下降，缺乏泛化能力，需改进其鲁棒性。

Method: CUDA框架包括：跨域概念对齐、松弛阈值、无监督概念推断，以及理论保证的域适应集成。

Result: 在真实数据集上显著优于现有CBM和域适应方法。

Conclusion: CUDA框架提升了CBMs的域适应能力，同时保持可解释性，为域适应设定了新基准。

Abstract: Concept Bottleneck Models (CBMs) enhance interpretability by explaining
predictions through human-understandable concepts but typically assume that
training and test data share the same distribution. This assumption often fails
under domain shifts, leading to degraded performance and poor generalization.
To address these limitations and improve the robustness of CBMs, we propose the
Concept-based Unsupervised Domain Adaptation (CUDA) framework. CUDA is designed
to: (1) align concept representations across domains using adversarial
training, (2) introduce a relaxation threshold to allow minor domain-specific
differences in concept distributions, thereby preventing performance drop due
to over-constraints of these distributions, (3) infer concepts directly in the
target domain without requiring labeled concept data, enabling CBMs to adapt to
diverse domains, and (4) integrate concept learning into conventional domain
adaptation (DA) with theoretical guarantees, improving interpretability and
establishing new benchmarks for DA. Experiments demonstrate that our approach
significantly outperforms the state-of-the-art CBM and DA methods on real-world
datasets.

</details>

### [59] [GFlowNets for Active Learning Based Resource Allocation in Next Generation Wireless Networks](https://arxiv.org/abs/2505.05224)
*Charbel Bou Chaaya,Mehdi Bennis*

Main category: cs.LG

TLDR: 本文提出了一种基于主动学习和生成流网络（GFlowNet）的无线资源分配方法，能够同时满足通信、感知和计算等异构需求，性能提升20%，且所需采样轮数减半。


<details>
  <summary>Details</summary>
Motivation: 无线系统中需要同时满足通信、感知和计算等异构功能的需求，而传统资源分配方法难以高效处理高维离散问题。

Method: 采用主动学习框架，通过GFlowNet生成多样化的资源分配方案，并迭代更新环境代理模型。

Result: 仿真结果显示，该方法性能提升20%，且采样轮数减少一半。

Conclusion: GFlowNet结合主动学习能高效解决无线资源分配问题，具有显著性能优势。

Abstract: In this work, we consider the radio resource allocation problem in a wireless
system with various integrated functionalities, such as communication, sensing
and computing. We design suitable resource management techniques that can
simultaneously cater to those heterogeneous requirements, and scale
appropriately with the high-dimensional and discrete nature of the problem. We
propose a novel active learning framework where resource allocation patterns
are drawn sequentially, evaluated in the environment, and then used to
iteratively update a surrogate model of the environment. Our method leverages a
generative flow network (GFlowNet) to sample favorable solutions, as such
models are trained to generate compositional objects proportionally to their
training reward, hence providing an appropriate coverage of its modes. As such,
GFlowNet generates diverse and high return resource management designs that
update the surrogate model and swiftly discover suitable solutions. We provide
simulation results showing that our method can allocate radio resources
achieving 20% performance gains against benchmarks, while requiring less than
half of the number of acquisition rounds.

</details>

### [60] [Put CASH on Bandits: A Max K-Armed Problem for Automated Machine Learning](https://arxiv.org/abs/2505.05226)
*Amir Rezaei Balef,Claire Vernade,Katharina Eggensperger*

Main category: cs.LG

TLDR: MaxUCB是一种针对AutoML中CASH问题的轻尾有界奖励分布设计的max k-armed bandit方法，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决AutoML中CASH问题的资源分配挑战，传统方法假设奖励分布为厚尾，不适用于轻尾有界分布的场景。

Method: 提出MaxUCB方法，平衡模型类探索和超参数优化，适用于轻尾有界奖励分布。

Result: 在四个标准AutoML基准测试中，理论和实证评估显示MaxUCB优于现有方法。

Conclusion: MaxUCB为CASH问题提供了高效解决方案，适用于轻尾有界奖励分布场景。

Abstract: The Combined Algorithm Selection and Hyperparameter optimization (CASH) is a
challenging resource allocation problem in the field of AutoML. We propose
MaxUCB, a max $k$-armed bandit method to trade off exploring different model
classes and conducting hyperparameter optimization. MaxUCB is specifically
designed for the light-tailed and bounded reward distributions arising in this
setting and, thus, provides an efficient alternative compared to classic max
$k$-armed bandit methods assuming heavy-tailed reward distributions. We
theoretically and empirically evaluate our method on four standard AutoML
benchmarks, demonstrating superior performance over prior approaches.

</details>

### [61] [Latte: Transfering LLMs` Latent-level Knowledge for Few-shot Tabular Learning](https://arxiv.org/abs/2505.05237)
*Ruxue Shi,Hengrui Gu,Hangting Ye,Yiwei Dai,Xu Shen,Xin Wang*

Main category: cs.LG

TLDR: Latte是一个训练时知识提取框架，利用LLMs的潜在先验知识优化下游表格学习模型，解决少样本表格学习中的延迟和不可靠特征工程问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在少样本表格学习中存在测试时知识提取引入延迟或文本级知识导致不可靠特征工程的局限性。

Method: 提出Latte框架，通过训练时提取LLMs的潜在知识，优化下游模型，支持跨特征值的信息加权融合，并兼容无监督预训练。

Result: 在多个少样本表格学习基准测试中，Latte表现出优越性能，成为该领域的先进方法。

Conclusion: Latte通过训练时知识提取和兼容无监督预训练，显著提升了少样本表格学习的性能。

Abstract: Few-shot tabular learning, in which machine learning models are trained with
a limited amount of labeled data, provides a cost-effective approach to
addressing real-world challenges. The advent of Large Language Models (LLMs)
has sparked interest in leveraging their pre-trained knowledge for few-shot
tabular learning. Despite promising results, existing approaches either rely on
test-time knowledge extraction, which introduces undesirable latency, or
text-level knowledge, which leads to unreliable feature engineering. To
overcome these limitations, we propose Latte, a training-time knowledge
extraction framework that transfers the latent prior knowledge within LLMs to
optimize a more generalized downstream model. Latte enables general
knowledge-guided downstream tabular learning, facilitating the weighted fusion
of information across different feature values while reducing the risk of
overfitting to limited labeled data. Furthermore, Latte is compatible with
existing unsupervised pre-training paradigms and effectively utilizes available
unlabeled samples to overcome the performance limitations imposed by an
extremely small labeled dataset. Extensive experiments on various few-shot
tabular learning benchmarks demonstrate the superior performance of Latte,
establishing it as a state-of-the-art approach in this domain

</details>

### [62] [Enhancing Treatment Effect Estimation via Active Learning: A Counterfactual Covering Perspective](https://arxiv.org/abs/2505.05242)
*Hechuan Wen,Tong Chen,Mingming Gong,Li Kheng Chai,Shazia Sadiq,Hongzhi Yin*

Main category: cs.LG

TLDR: 论文提出了一种数据高效的治疗效果估计方法，通过主动学习框架和优化目标FCCM，解决了标记数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 由于标记治疗效果的代价高昂（如肿瘤成像或活检），现有算法在标记数据不足时效果有限，因此需要高效利用有限的标记预算。

Method: 通过理论分析定义了事实和反事实覆盖半径，提出贪心半径缩减算法和FCCM优化目标，以最大化覆盖范围。

Result: FCCM在合成和半合成数据集上表现优于基线方法。

Conclusion: FCCM能有效减少风险上界，适用于现实数据分布，提升了治疗效果估计的效率。

Abstract: Although numerous complex algorithms for treatment effect estimation have
been developed in recent years, their effectiveness remains limited when
handling insufficiently labeled training sets due to the high cost of labeling
the effect after treatment, e.g., expensive tumor imaging or biopsy procedures
needed to evaluate treatment effects. Therefore, it becomes essential to
actively incorporate more high-quality labeled data, all while adhering to a
constrained labeling budget. To enable data-efficient treatment effect
estimation, we formalize the problem through rigorous theoretical analysis
within the active learning context, where the derived key measures --
\textit{factual} and \textit{counterfactual covering radius} determine the risk
upper bound. To reduce the bound, we propose a greedy radius reduction
algorithm, which excels under an idealized, balanced data distribution. To
generalize to more realistic data distributions, we further propose FCCM, which
transforms the optimization objective into the \textit{Factual} and
\textit{Counterfactual Coverage Maximization} to ensure effective radius
reduction during data acquisition. Furthermore, benchmarking FCCM against other
baselines demonstrates its superiority across both fully synthetic and
semi-synthetic datasets.

</details>

### [63] [Enhancing Cooperative Multi-Agent Reinforcement Learning with State Modelling and Adversarial Exploration](https://arxiv.org/abs/2505.05262)
*Andreas Kontogiannis,Konstantinos Papathanasiou,Yi Shen,Giorgos Stamou,Michael M. Zavlanos,George Vouros*

Main category: cs.LG

TLDR: 提出了一种新的状态建模框架MARL SMPE算法，用于分布式部分可观测环境中的多智能体深度强化学习，通过推断非可观测状态的信念表示并优化策略，显著提升了协作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决分布式部分可观测环境中无通信能力的多智能体深度强化学习（MARL）面临的协作挑战，特别是如何从个体观测中推断状态表示并优化协作策略。

Method: 提出MARL SMPE算法，通过显式地将信念表示纳入策略网络，并采用对抗性探索策略，增强智能体在部分可观测环境中的策略区分能力和协作效率。

Result: 实验表明，SMPE在MPE、LBF和RWARE基准测试的复杂完全协作任务中优于现有MARL算法。

Conclusion: MARL SMPE算法通过优化状态表示和探索策略，显著提升了多智能体在部分可观测环境中的协作能力。

Abstract: Learning to cooperate in distributed partially observable environments with
no communication abilities poses significant challenges for multi-agent deep
reinforcement learning (MARL). This paper addresses key concerns in this
domain, focusing on inferring state representations from individual agent
observations and leveraging these representations to enhance agents'
exploration and collaborative task execution policies. To this end, we propose
a novel state modelling framework for cooperative MARL, where agents infer
meaningful belief representations of the non-observable state, with respect to
optimizing their own policies, while filtering redundant and less informative
joint state information. Building upon this framework, we propose the MARL SMPE
algorithm. In SMPE, agents enhance their own policy's discriminative abilities
under partial observability, explicitly by incorporating their beliefs into the
policy network, and implicitly by adopting an adversarial type of exploration
policies which encourages agents to discover novel, high-value states while
improving the discriminative abilities of others. Experimentally, we show that
SMPE outperforms state-of-the-art MARL algorithms in complex fully cooperative
tasks from the MPE, LBF, and RWARE benchmarks.

</details>

### [64] [Performance Estimation in Binary Classification Using Calibrated Confidence](https://arxiv.org/abs/2505.05295)
*Juhani Kivimäki,Jakub Białek,Wojtek Kuberski,Jukka K. Nurminen*

Main category: cs.LG

TLDR: 论文提出了一种名为CBPE的新方法，用于估计二元分类器的性能指标（如准确率、精确率、召回率和F1分数），无需依赖真实标签。该方法通过将混淆矩阵元素视为随机变量，并利用模型的校准置信分数来估计其分布。


<details>
  <summary>Details</summary>
Motivation: 传统模型性能监控需要真实标签，但标签通常难以获取，导致监控延迟或不可行。现有方法仅关注准确率估计，而其他重要指标（如精确率、召回率等）尚未得到充分研究。

Method: CBPE将混淆矩阵元素视为随机变量，利用模型的校准置信分数估计其分布，进而推导目标指标的概率分布。

Result: CBPE能够估计多种二元分类指标，并提供理论保证和有效置信区间。

Conclusion: CBPE填补了无需标签估计多种二元分类指标的研究空白，为模型性能监控提供了更灵活的工具。

Abstract: Model monitoring is a critical component of the machine learning lifecycle,
safeguarding against undetected drops in the model's performance after
deployment. Traditionally, performance monitoring has required access to ground
truth labels, which are not always readily available. This can result in
unacceptable latency or render performance monitoring altogether impossible.
Recently, methods designed to estimate the accuracy of classifier models
without access to labels have shown promising results. However, there are
various other metrics that might be more suitable for assessing model
performance in many cases. Until now, none of these important metrics has
received similar interest from the scientific community. In this work, we
address this gap by presenting CBPE, a novel method that can estimate any
binary classification metric defined using the confusion matrix. In particular,
we choose four metrics from this large family: accuracy, precision, recall, and
F$_1$, to demonstrate our method. CBPE treats the elements of the confusion
matrix as random variables and leverages calibrated confidence scores of the
model to estimate their distributions. The desired metric is then also treated
as a random variable, whose full probability distribution can be derived from
the estimated confusion matrix. CBPE is shown to produce estimates that come
with strong theoretical guarantees and valid confidence intervals.

</details>

### [65] [Scalable Chain of Thoughts via Elastic Reasoning](https://arxiv.org/abs/2505.05315)
*Yuhui Xu,Hanze Dong,Lei Wang,Doyen Sahoo,Junnan Li,Caiming Xiong*

Main category: cs.LG

TLDR: Elastic Reasoning框架通过将推理分为思考和解决两阶段，并独立分配预算，显著提升了在严格资源约束下的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在复杂任务上表现出色，但其不可控的输出长度限制了实际部署。

Method: 提出Elastic Reasoning框架，分为思考和解决两阶段，并采用预算约束的轻量级训练策略。

Result: 在数学和编程基准测试中表现稳健，训练成本更低，推理更简洁高效。

Conclusion: Elastic Reasoning为可控推理提供了实用解决方案。

Abstract: Large reasoning models (LRMs) have achieved remarkable progress on complex
tasks by generating extended chains of thought (CoT). However, their
uncontrolled output lengths pose significant challenges for real-world
deployment, where inference-time budgets on tokens, latency, or compute are
strictly constrained. We propose Elastic Reasoning, a novel framework for
scalable chain of thoughts that explicitly separates reasoning into two
phases--thinking and solution--with independently allocated budgets. At test
time, Elastic Reasoning prioritize that completeness of solution segments,
significantly improving reliability under tight resource constraints. To train
models that are robust to truncated thinking, we introduce a lightweight
budget-constrained rollout strategy, integrated into GRPO, which teaches the
model to reason adaptively when the thinking process is cut short and
generalizes effectively to unseen budget constraints without additional
training. Empirical results on mathematical (AIME, MATH500) and programming
(LiveCodeBench, Codeforces) benchmarks demonstrate that Elastic Reasoning
performs robustly under strict budget constraints, while incurring
significantly lower training cost than baseline methods. Remarkably, our
approach also produces more concise and efficient reasoning even in
unconstrained settings. Elastic Reasoning offers a principled and practical
solution to the pressing challenge of controllable reasoning at scale.

</details>

### [66] [Nearly Optimal Sample Complexity for Learning with Label Proportions](https://arxiv.org/abs/2505.05355)
*Robert Busa-Fekete,Travis Dick,Claudio Gentile,Haim Kaplan,Tomer Koren,Uri Stemmer*

Main category: cs.LG

TLDR: 本文研究了标签比例学习（LLP）问题，提出了一种在部分信息下实现个体级别低遗憾的方法，并证明了样本复杂度的最优性。


<details>
  <summary>Details</summary>
Motivation: 研究LLP问题，即在训练集中仅提供分组标签比例的情况下，如何实现个体级别的低遗憾预测。

Method: 采用经验风险最小化和随机梯度下降算法的变体，结合方差减少技术。

Result: 理论结果改进了现有文献，样本复杂度与包大小的关系更优；实验验证了算法在多个数据集上的优越性。

Conclusion: 本文方法在理论和实验上均优于现有基线，为LLP问题提供了更高效的解决方案。

Abstract: We investigate Learning from Label Proportions (LLP), a partial information
setting where examples in a training set are grouped into bags, and only
aggregate label values in each bag are available. Despite the partial
observability, the goal is still to achieve small regret at the level of
individual examples. We give results on the sample complexity of LLP under
square loss, showing that our sample complexity is essentially optimal. From an
algorithmic viewpoint, we rely on carefully designed variants of Empirical Risk
Minimization, and Stochastic Gradient Descent algorithms, combined with ad hoc
variance reduction techniques. On one hand, our theoretical results improve in
important ways on the existing literature on LLP, specifically in the way the
sample complexity depends on the bag size. On the other hand, we validate our
algorithmic solutions on several datasets, demonstrating improved empirical
performance (better accuracy for less samples) against recent baselines.

</details>

### [67] [Denoising Diffusion Probabilistic Models for Coastal Inundation Forecasting](https://arxiv.org/abs/2505.05381)
*Kazi Ashik Islam,Zakaria Mehrab,Mahantesh Halappanavar,Henning Mortveit,Sridhar Katragadda,Jon Derek Loftis,Madhav Marathe*

Main category: cs.LG

TLDR: DIFF-FLOOD是一种基于去噪扩散模型的概率时空预测方法，用于快速准确预测沿海洪水淹没水平，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 沿海洪水对社区构成重大风险，需要快速准确的预测方法以减少潜在损害。

Method: DIFF-FLOOD利用空间（邻近区域淹没水平和数字高程数据）和时间（历史淹没数据及协变量）上下文，结合卷积神经网络和交叉注意力机制捕捉时空动态。

Result: 在弗吉尼亚东海岸数据上测试，DIFF-FLOOD在预测性能和可扩展性上优于现有方法（性能指标提升6%至64%）。

Conclusion: DIFF-FLOOD为沿海洪水预测提供了一种高效且可扩展的解决方案。

Abstract: Coastal flooding poses significant risks to communities, necessitating fast
and accurate forecasting methods to mitigate potential damage. To approach this
problem, we present DIFF-FLOOD, a probabilistic spatiotemporal forecasting
method designed based on denoising diffusion models. DIFF-FLOOD predicts
inundation level at a location by taking both spatial and temporal context into
account. It utilizes inundation levels at neighboring locations and digital
elevation data as spatial context. Inundation history from a context time
window, together with additional co-variates are used as temporal context.
Convolutional neural networks and cross-attention mechanism are then employed
to capture the spatiotemporal dynamics in the data. We trained and tested
DIFF-FLOOD on coastal inundation data from the Eastern Shore of Virginia, a
region highly impacted by coastal flooding. Our results show that, DIFF-FLOOD
outperforms existing forecasting methods in terms of prediction performance (6%
to 64% improvement in terms of two performance metrics) and scalability.

</details>

### [68] [CART-ELC: Oblique Decision Tree Induction via Exhaustive Search](https://arxiv.org/abs/2505.05402)
*Andrew D. Laack*

Main category: cs.LG

TLDR: 提出了一种名为CART-ELC的新算法，用于生成斜决策树，通过限制超平面搜索范围提高计算效率，并在小数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统轴对齐决策树分类性能有限，而现有斜决策树方法因计算复杂度高未被广泛研究。

Method: CART-ELC算法在受限超平面集合上进行穷举搜索，生成斜决策树。

Result: 在小数据集上，CART-ELC分类准确率显著优于现有算法，且生成的树更浅、更简单。

Conclusion: CART-ELC是一种高效且性能优越的斜决策树生成方法，适合小数据集应用。

Abstract: Oblique decision trees have attracted attention due to their potential for
improved classification performance over traditional axis-aligned decision
trees. However, methods that rely on exhaustive search to find oblique splits
face computational challenges. As a result, they have not been widely explored.
We introduce a novel algorithm, Classification and Regression Tree - Exhaustive
Linear Combinations (CART-ELC), for inducing oblique decision trees that
performs an exhaustive search on a restricted set of hyperplanes. We then
investigate the algorithm's computational complexity and its predictive
capabilities. Our results demonstrate that CART-ELC consistently achieves
competitive performance on small datasets, often yielding statistically
significant improvements in classification accuracy relative to existing
decision tree induction algorithms, while frequently producing shallower,
simpler, and thus more interpretable trees.

</details>

### [69] [Hide & Seek: Transformer Symmetries Obscure Sharpness & Riemannian Geometry Finds It](https://arxiv.org/abs/2505.05409)
*Marvin F. da Silva,Felix Dangel,Sageev Oore*

Main category: cs.LG

TLDR: 论文提出了一种新的锐度定义，通过考虑Transformer的对称性并利用黎曼几何工具，改进了现有锐度度量方法，使其能更好地预测Transformer的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有锐度度量方法在Transformer上表现不佳，因为Transformer的注意力机制具有丰富的对称性，导致参数空间中存在不影响网络或损失的冗余方向。

Method: 通过引入商流形（quotient manifold）去除对称性模糊性，并基于黎曼几何提出一种新的锐度定义，即对称性校正后的商流形上的测地球。

Result: 实验表明，高阶近似对恢复锐度与泛化能力的相关性至关重要，并在合成数据和真实世界的文本与图像分类任务中验证了方法的有效性。

Conclusion: 通过完全考虑Transformer的对称性，新的锐度定义显著提高了对泛化能力的预测能力。

Abstract: The concept of sharpness has been successfully applied to traditional
architectures like MLPs and CNNs to predict their generalization. For
transformers, however, recent work reported weak correlation between flatness
and generalization. We argue that existing sharpness measures fail for
transformers, because they have much richer symmetries in their attention
mechanism that induce directions in parameter space along which the network or
its loss remain identical. We posit that sharpness must account fully for these
symmetries, and thus we redefine it on a quotient manifold that results from
quotienting out the transformer symmetries, thereby removing their ambiguities.
Leveraging tools from Riemannian geometry, we propose a fully general notion of
sharpness, in terms of a geodesic ball on the symmetry-corrected quotient
manifold. In practice, we need to resort to approximating the geodesics. Doing
so up to first order yields existing adaptive sharpness measures, and we
demonstrate that including higher-order terms is crucial to recover correlation
with generalization. We present results on diagonal networks with synthetic
data, and show that our geodesic sharpness reveals strong correlation for
real-world transformers on both text and image classification tasks.

</details>

### [70] [DPQ-HD: Post-Training Compression for Ultra-Low Power Hyperdimensional Computing](https://arxiv.org/abs/2505.05413)
*Nilesh Prasad Pandey,Shriniwas Kulkarni,David Wang,Onat Gungor,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TLDR: 论文提出了一种名为DPQ-HD的后训练压缩算法，用于高效压缩超维计算（HDC）系统，无需重新训练即可接近浮点性能。


<details>
  <summary>Details</summary>
Motivation: 当前HDC应用依赖高精度模型或编码矩阵，导致计算和内存需求高，尤其对超低功耗设备不友好。现有压缩方法需重新训练，成本高且不实用。

Method: DPQ-HD结合分解、剪枝和量化三种压缩技术，并引入渐进式相似性评分和早期退出策略以减少计算。

Result: 在图像和图形分类任务中，DPQ-HD实现了20-100倍内存减少，精度仅下降1-2%，且优于现有后训练压缩方法。

Conclusion: DPQ-HD是一种高效、无需重新训练的HDC压缩方案，显著降低了优化时间和推理时间。

Abstract: Hyperdimensional Computing (HDC) is emerging as a promising approach for edge
AI, offering a balance between accuracy and efficiency. However, current
HDC-based applications often rely on high-precision models and/or encoding
matrices to achieve competitive performance, which imposes significant
computational and memory demands, especially for ultra-low power devices. While
recent efforts use techniques like precision reduction and pruning to increase
the efficiency, most require retraining to maintain performance, making them
expensive and impractical. To address this issue, we propose a novel Post
Training Compression algorithm, Decomposition-Pruning-Quantization (DPQ-HD),
which aims at compressing the end-to-end HDC system, achieving near floating
point performance without the need of retraining. DPQ-HD reduces computational
and memory overhead by uniquely combining the above three compression
techniques and efficiently adapts to hardware constraints. Additionally, we
introduce an energy-efficient inference approach that progressively evaluates
similarity scores such as cosine similarity and performs early exit to reduce
the computation, accelerating prediction inference while maintaining accuracy.
We demonstrate that DPQ-HD achieves up to 20-100x reduction in memory for image
and graph classification tasks with only a 1-2% drop in accuracy compared to
uncompressed workloads. Lastly, we show that DPQ-HD outperforms the existing
post-training compression methods and performs better or at par with
retraining-based state-of-the-art techniques, requiring significantly less
overall optimization time (up to 100x) and faster inference (up to 56x) on a
microcontroller

</details>

### [71] [RL-DAUNCE: Reinforcement Learning-Driven Data Assimilation with Uncertainty-Aware Constrained Ensembles](https://arxiv.org/abs/2505.05452)
*Pouria Behnoudfar,Nan Chen*

Main category: cs.LG

TLDR: RL-DAUNCE是一种基于强化学习的数据同化方法，通过物理约束提升性能，计算高效且优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统数据同化方法（如EnKF）在处理非高斯特征和物理约束时表现不佳，需要一种更高效且能动态平衡模型与观测的方法。

Method: RL-DAUNCE通过设计代理模拟集合成员，结合物理约束和不确定性量化，采用对偶优化策略和约束动作空间。

Result: RL-DAUNCE在Madden-Julian Oscillation案例中优于EnKF，尤其在恢复间歇信号、捕捉极端事件和量化不确定性方面表现突出。

Conclusion: RL-DAUNCE在保持计算效率的同时，通过物理约束显著提升了数据同化的性能，适用于复杂现象。

Abstract: Machine learning has become a powerful tool for enhancing data assimilation.
While supervised learning remains the standard method, reinforcement learning
(RL) offers unique advantages through its sequential decision-making framework,
which naturally fits the iterative nature of data assimilation by dynamically
balancing model forecasts with observations. We develop RL-DAUNCE, a new
RL-based method that enhances data assimilation with physical constraints
through three key aspects. First, RL-DAUNCE inherits the computational
efficiency of machine learning while it uniquely structures its agents to
mirror ensemble members in conventional data assimilation methods. Second,
RL-DAUNCE emphasizes uncertainty quantification by advancing multiple ensemble
members, moving beyond simple mean-state optimization. Third, RL-DAUNCE's
ensemble-as-agents design facilitates the enforcement of physical constraints
during the assimilation process, which is crucial to improving the state
estimation and subsequent forecasting. A primal-dual optimization strategy is
developed to enforce constraints, which dynamically penalizes the reward
function to ensure constraint satisfaction throughout the learning process.
Also, state variable bounds are respected by constraining the RL action space.
Together, these features ensure physical consistency without sacrificing
efficiency. RL-DAUNCE is applied to the Madden-Julian Oscillation, an
intermittent atmospheric phenomenon characterized by strongly non-Gaussian
features and multiple physical constraints. RL-DAUNCE outperforms the standard
ensemble Kalman filter (EnKF), which fails catastrophically due to the
violation of physical constraints. Notably, RL-DAUNCE matches the performance
of constrained EnKF, particularly in recovering intermittent signals, capturing
extreme events, and quantifying uncertainties, while requiring substantially
less computational effort.

</details>

<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [72] [How Social is It? A Benchmark for LLMs' Capabilities in Multi-user Multi-turn Social Agent Tasks](https://arxiv.org/abs/2505.04628)
*Yusen Wu,Junwu Xiong,Xiaotie Deng*

Main category: cs.CL

TLDR: 论文提出了一个评估大语言模型（LLM）社交能力的基准HSII，并引入任务分级框架和数据集HSII-Dataset，通过四个阶段测试LLM在复杂社交任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估LLM在多用户、多轮社交任务中能力的基准，论文旨在填补这一空白。

Method: 提出HSII基准和HSII-Dataset数据集，分四个阶段评估LLM的社交能力，并研究链式思维（COT）方法的影响。

Result: 实验表明HSII能有效评估LLM的社交能力，并引入COT-complexity指标平衡正确性与效率。

Conclusion: HSII基准适用于评估LLM的社交技能，为未来研究提供了新工具。

Abstract: Expanding the application of large language models (LLMs) to societal life,
instead of primary function only as auxiliary assistants to communicate with
only one person at a time, necessitates LLMs' capabilities to independently
play roles in multi-user, multi-turn social agent tasks within complex social
settings. However, currently the capability has not been systematically
measured with available benchmarks. To address this gap, we first introduce an
agent task leveling framework grounded in sociological principles.
Concurrently, we propose a novel benchmark, How Social Is It (we call it HSII
below), designed to assess LLM's social capabilities in comprehensive social
agents tasks and benchmark representative models. HSII comprises four stages:
format parsing, target selection, target switching conversation, and stable
conversation, which collectively evaluate the communication and task completion
capabilities of LLMs within realistic social interaction scenarios dataset,
HSII-Dataset. The dataset is derived step by step from news dataset. We perform
an ablation study by doing clustering to the dataset. Additionally, we
investigate the impact of chain of thought (COT) method on enhancing LLMs'
social performance. Since COT cost more computation, we further introduce a new
statistical metric, COT-complexity, to quantify the efficiency of certain LLMs
with COTs for specific social tasks and strike a better trade-off between
measurement of correctness and efficiency. Various results of our experiments
demonstrate that our benchmark is well-suited for evaluating social skills in
LLMs.

</details>

### [73] [Adaptive Token Boundaries: Integrating Human Chunking Mechanisms into Multimodal LLMs](https://arxiv.org/abs/2505.04637)
*Dongxing Yu*

Main category: cs.CL

TLDR: 该研究探讨了多模态大语言模型（MLLMs）与人类认知过程在信息整合上的差异，提出了一种动态跨模态标记化框架，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在信息整合上与人类认知存在显著差距，研究旨在缩小这一差距。

Method: 通过比较人类与模型在视觉-语言任务中的表现，提出动态跨模态标记化框架，包含自适应边界、分层表示和对齐机制。

Result: 新框架在基准任务上显著优于现有模型（VQA +7.8%，复杂场景描述 +5.3%），且错误模式和注意力分布更接近人类。

Conclusion: 研究为开发更符合人类认知的AI系统提供了理论和实证支持。

Abstract: Recent advancements in multimodal large language models (MLLMs) have
demonstrated remarkable capabilities in processing diverse data types, yet
significant disparities persist between human cognitive processes and
computational approaches to multimodal information integration. This research
presents a systematic investigation into the parallels between human
cross-modal chunking mechanisms and token representation methodologies in
MLLMs. Through empirical studies comparing human performance patterns with
model behaviors across visual-linguistic tasks, we demonstrate that
conventional static tokenization schemes fundamentally constrain current
models' capacity to simulate the dynamic, context-sensitive nature of human
information processing. We propose a novel framework for dynamic cross-modal
tokenization that incorporates adaptive boundaries, hierarchical
representations, and alignment mechanisms grounded in cognitive science
principles. Quantitative evaluations demonstrate that our approach yields
statistically significant improvements over state-of-the-art models on
benchmark tasks (+7.8% on Visual Question Answering, +5.3% on Complex Scene
Description) while exhibiting more human-aligned error patterns and attention
distributions. These findings contribute to the theoretical understanding of
the relationship between human cognition and artificial intelligence, while
providing empirical evidence for developing more cognitively plausible AI
systems.

</details>

### [74] [Language translation, and change of accent for speech-to-speech task using diffusion model](https://arxiv.org/abs/2505.04639)
*Abhishek Mishra,Ritesh Sur Chowdhury,Vartul Bahuguna,Isha Pandey,Ganesh Ramakrishnan*

Main category: cs.CL

TLDR: 提出了一种统一的语音翻译与口音适应方法，利用扩散模型生成目标语音的梅尔频谱，实现高效联合优化。


<details>
  <summary>Details</summary>
Motivation: 跨文化交流需要同时处理语言翻译和口音适应，但现有研究对此关注不足。

Method: 将问题重新定义为条件生成任务，利用扩散模型基于音素和目标语音特征生成目标语音的梅尔频谱。

Result: 提出的框架在翻译和口音适应上比传统方法更高效且有效。

Conclusion: 该方法为语音翻译与口音适应提供了一种统一的解决方案。

Abstract: Speech-to-speech translation (S2ST) aims to convert spoken input in one
language to spoken output in another, typically focusing on either language
translation or accent adaptation. However, effective cross-cultural
communication requires handling both aspects simultaneously - translating
content while adapting the speaker's accent to match the target language
context. In this work, we propose a unified approach for simultaneous speech
translation and change of accent, a task that remains underexplored in current
literature. Our method reformulates the problem as a conditional generation
task, where target speech is generated based on phonemes and guided by target
speech features. Leveraging the power of diffusion models, known for
high-fidelity generative capabilities, we adapt text-to-image diffusion
strategies by conditioning on source speech transcriptions and generating Mel
spectrograms representing the target speech with desired linguistic and
accentual attributes. This integrated framework enables joint optimization of
translation and accent adaptation, offering a more parameter-efficient and
effective model compared to traditional pipelines.

</details>

### [75] [A Comparative Benchmark of a Moroccan Darija Toxicity Detection Model (Typica.ai) and Major LLM-Based Moderation APIs (OpenAI, Mistral, Anthropic)](https://arxiv.org/abs/2505.04640)
*Hicham Assoudi*

Main category: cs.CL

TLDR: Typica.ai的摩洛哥Darija毒性检测模型在性能上优于主流LLM审核API，强调文化适应模型的重要性。


<details>
  <summary>Details</summary>
Motivation: 评估Typica.ai的定制模型在检测摩洛哥Darija文化毒性内容中的表现，填补通用系统在此类任务中的不足。

Method: 使用OMCD_Typica.ai_Mix数据集，比较Typica.ai与OpenAI、Mistral和Anthropic Claude的审核API，评估精度、召回率、F1分数和准确率。

Result: Typica.ai模型表现最优，尤其在检测文化特定的毒性内容（如隐晦侮辱、讽刺等）上更可靠。

Conclusion: 文化适应模型对可靠的内容审核至关重要，Typica.ai的定制模型在摩洛哥Darija中表现突出。

Abstract: This paper presents a comparative benchmark evaluating the performance of
Typica.ai's custom Moroccan Darija toxicity detection model against major
LLM-based moderation APIs: OpenAI (omni-moderation-latest), Mistral
(mistral-moderation-latest), and Anthropic Claude (claude-3-haiku-20240307). We
focus on culturally grounded toxic content, including implicit insults,
sarcasm, and culturally specific aggression often overlooked by general-purpose
systems. Using a balanced test set derived from the OMCD_Typica.ai_Mix dataset,
we report precision, recall, F1-score, and accuracy, offering insights into
challenges and opportunities for moderation in underrepresented languages. Our
results highlight Typica.ai's superior performance, underlining the importance
of culturally adapted models for reliable content moderation.

</details>

### [76] [Rethinking Multimodal Sentiment Analysis: A High-Accuracy, Simplified Fusion Architecture](https://arxiv.org/abs/2505.04642)
*Nischal Mandal,Yang Li*

Main category: cs.CL

TLDR: 本文提出了一种轻量级的多模态情感分析模型，通过简单的特征融合策略在资源受限环境中实现高效情感分类。


<details>
  <summary>Details</summary>
Motivation: 多模态情感分析需要整合语言、音频和视觉信号，但现有方法常采用复杂架构，计算开销大。本文旨在设计一种轻量级模型，兼顾性能和效率。

Method: 使用IEMOCAP数据集，设计模态特定编码器（全连接层+Dropout），通过简单拼接和密集融合层实现跨模态交互。

Result: 模型在六类情感分类任务中达到92%的准确率，性能与复杂模型相当。

Conclusion: 研究表明，通过精心设计的特征工程和模块化架构，简单融合策略在资源受限环境中可优于或匹配复杂模型。

Abstract: Multimodal sentiment analysis, a pivotal task in affective computing, seeks
to understand human emotions by integrating cues from language, audio, and
visual signals. While many recent approaches leverage complex attention
mechanisms and hierarchical architectures, we propose a lightweight, yet
effective fusion-based deep learning model tailored for utterance-level emotion
classification. Using the benchmark IEMOCAP dataset, which includes aligned
text, audio-derived numeric features, and visual descriptors, we design a
modality-specific encoder using fully connected layers followed by dropout
regularization. The modality-specific representations are then fused using
simple concatenation and passed through a dense fusion layer to capture
cross-modal interactions. This streamlined architecture avoids computational
overhead while preserving performance, achieving a classification accuracy of
92% across six emotion categories. Our approach demonstrates that with careful
feature engineering and modular design, simpler fusion strategies can
outperform or match more complex models, particularly in resource-constrained
environments.

</details>

### [77] [Prediction-powered estimators for finite population statistics in highly imbalanced textual data: Public hate crime estimation](https://arxiv.org/abs/2505.04643)
*Hannes Waldetoft,Jakob Torgander,Måns Magnusson*

Main category: cs.CL

TLDR: 结合Transformer编码器神经网络与调查抽样估计器，利用模型预测作为辅助变量，高效估计文本文档有限群体中的参数，减少手动标注时间。


<details>
  <summary>Details</summary>
Motivation: 解决在有限文本群体中手动标注目标变量标签的挑战，提高参数估计效率。

Method: 结合Transformer编码器预测与Hansen-Hurwitz、差异估计和分层随机抽样估计器，应用于瑞典仇恨犯罪统计数据。

Result: 方法在可用标注训练数据时能提供高效估计，显著减少手动标注时间。

Conclusion: 若标注数据可用，该方法能高效估计参数并减少手动标注负担。

Abstract: Estimating population parameters in finite populations of text documents can
be challenging when obtaining the labels for the target variable requires
manual annotation. To address this problem, we combine predictions from a
transformer encoder neural network with well-established survey sampling
estimators using the model predictions as an auxiliary variable. The
applicability is demonstrated in Swedish hate crime statistics based on Swedish
police reports. Estimates of the yearly number of hate crimes and the police's
under-reporting are derived using the Hansen-Hurwitz estimator, difference
estimation, and stratified random sampling estimation. We conclude that if
labeled training data is available, the proposed method can provide very
efficient estimates with reduced time spent on manual annotation.

</details>

### [78] [ChatGPT for automated grading of short answer questions in mechanical ventilation](https://arxiv.org/abs/2505.04645)
*Tejas Jade,Alex Yartsev*

Main category: cs.CL

TLDR: 研究评估了ChatGPT 4o在研究生医学教育中自动评分短答案问题的表现，发现其评分与人类评分存在显著差异，系统性偏低且一致性差。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在模拟对话语言和解释非结构化自由文本方面的能力使其成为自动评分的潜在工具，但其在研究生教育中的实际表现尚不明确。

Method: 使用ChatGPT 4o对215名学生的557份短答案回答进行评分，并与人类评分对比，采用混合效应模型、方差成分分析、ICC、Cohen's kappa等方法分析一致性。

Result: ChatGPT评分系统性偏低（平均偏差-1.34分），个体一致性差（ICC1=0.086），且与人类评分差异显著，尤其在评价性和分析性题目上。

Conclusion: 研究建议谨慎使用LLMs进行研究生课程评分，因其评分与人类评分差异较大，不适合高风险评估。

Abstract: Standardised tests using short answer questions (SAQs) are common in
postgraduate education. Large language models (LLMs) simulate conversational
language and interpret unstructured free-text responses in ways aligning with
applying SAQ grading rubrics, making them attractive for automated grading. We
evaluated ChatGPT 4o to grade SAQs in a postgraduate medical setting using data
from 215 students (557 short-answer responses) enrolled in an online course on
mechanical ventilation (2020--2024). Deidentified responses to three case-based
scenarios were presented to ChatGPT with a standardised grading prompt and
rubric. Outputs were analysed using mixed-effects modelling, variance component
analysis, intraclass correlation coefficients (ICCs), Cohen's kappa, Kendall's
W, and Bland--Altman statistics. ChatGPT awarded systematically lower marks
than human graders with a mean difference (bias) of -1.34 on a 10-point scale.
ICC values indicated poor individual-level agreement (ICC1 = 0.086), and
Cohen's kappa (-0.0786) suggested no meaningful agreement. Variance component
analysis showed minimal variability among the five ChatGPT sessions (G-value =
0.87), indicating internal consistency but divergence from the human grader.
The poorest agreement was observed for evaluative and analytic items, whereas
checklist and prescriptive rubric items had less disagreement. We caution
against the use of LLMs in grading postgraduate coursework. Over 60% of
ChatGPT-assigned grades differed from human grades by more than acceptable
boundaries for high-stakes assessments.

</details>

### [79] [FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights](https://arxiv.org/abs/2505.04649)
*Chengzhang Yu,Yiming Zhang,Zhixin Liu,Zenghui Ding,Yining Sun,Zhanpeng Jin*

Main category: cs.CL

TLDR: FRAME框架通过迭代优化和结构化反馈提升医学论文生成质量，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在知识合成和质量保证方面的挑战，提升医学论文生成的效率和学术标准。

Method: 1. 结构化数据集构建；2. 生成器、评估器和反思器三部分架构；3. 结合统计指标和人工基准的评估框架。

Result: 实验显示FRAME显著优于传统方法（如DeepSeek V3提升9.91%），生成论文质量接近人类水平。

Conclusion: FRAME为自动化医学论文生成提供了高效且严格的基础，未来研究方向合成表现突出。

Abstract: The automation of scientific research through large language models (LLMs)
presents significant opportunities but faces critical challenges in knowledge
synthesis and quality assurance. We introduce Feedback-Refined Agent
Methodology (FRAME), a novel framework that enhances medical paper generation
through iterative refinement and structured feedback. Our approach comprises
three key innovations: (1) A structured dataset construction method that
decomposes 4,287 medical papers into essential research components through
iterative refinement; (2) A tripartite architecture integrating Generator,
Evaluator, and Reflector agents that progressively improve content quality
through metric-driven feedback; and (3) A comprehensive evaluation framework
that combines statistical metrics with human-grounded benchmarks. Experimental
results demonstrate FRAME's effectiveness, achieving significant improvements
over conventional approaches across multiple models (9.91% average gain with
DeepSeek V3, comparable improvements with GPT-4o Mini) and evaluation
dimensions. Human evaluation confirms that FRAME-generated papers achieve
quality comparable to human-authored works, with particular strength in
synthesizing future research directions. The results demonstrated our work
could efficiently assist medical research by building a robust foundation for
automated medical research paper generation while maintaining rigorous academic
standards.

</details>

### [80] [Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions](https://arxiv.org/abs/2505.04651)
*Adithya Kulkarni,Fatimah Alotaibi,Xinyue Zeng,Longfeng Wu,Tong Zeng,Barry Menglong Yao,Minqian Liu,Shuaicheng Zhang,Lifu Huang,Dawei Zhou*

Main category: cs.CL

TLDR: 该综述探讨了大型语言模型（LLMs）在科学假设生成与验证中的应用，总结了其方法、数据集及未来方向。


<details>
  <summary>Details</summary>
Motivation: LLMs通过信息合成、潜在关系发现和推理增强，正在改变科学研究的方式。

Method: 综述了LLM驱动的方法，包括符号框架、生成模型、混合系统和多智能体架构，以及检索增强生成、知识图谱补全等技术。

Result: 对比了早期符号系统与现代LLM流程，总结了验证方法（如模拟、因果建模）和跨领域数据集（如AHTech、CSKG-600）。

Conclusion: 提出了未来方向，包括新颖性感知生成、多模态符号集成和伦理保障，强调LLMs在科学发现中的潜力。

Abstract: Large Language Models (LLMs) are transforming scientific hypothesis
generation and validation by enabling information synthesis, latent
relationship discovery, and reasoning augmentation. This survey provides a
structured overview of LLM-driven approaches, including symbolic frameworks,
generative models, hybrid systems, and multi-agent architectures. We examine
techniques such as retrieval-augmented generation, knowledge-graph completion,
simulation, causal inference, and tool-assisted reasoning, highlighting
trade-offs in interpretability, novelty, and domain alignment. We contrast
early symbolic discovery systems (e.g., BACON, KEKADA) with modern LLM
pipelines that leverage in-context learning and domain adaptation via
fine-tuning, retrieval, and symbolic grounding. For validation, we review
simulation, human-AI collaboration, causal modeling, and uncertainty
quantification, emphasizing iterative assessment in open-world contexts. The
survey maps datasets across biomedicine, materials science, environmental
science, and social science, introducing new resources like AHTech and
CSKG-600. Finally, we outline a roadmap emphasizing novelty-aware generation,
multimodal-symbolic integration, human-in-the-loop systems, and ethical
safeguards, positioning LLMs as agents for principled, scalable scientific
discovery.

</details>

### [81] [Advancing Conversational Diagnostic AI with Multimodal Reasoning](https://arxiv.org/abs/2505.04653)
*Khaled Saab,Jan Freyberg,Chunjong Park,Tim Strother,Yong Cheng,Wei-Hung Weng,David G. T. Barrett,David Stutz,Nenad Tomasev,Anil Palepu,Valentin Liévin,Yash Sharma,Roma Ruparel,Abdullah Ahmed,Elahe Vedadi,Kimberly Kanada,Cian Hughes,Yun Liu,Geoff Brown,Yang Gao,Sean Li,S. Sara Mahdavi,James Manyika,Katherine Chou,Yossi Matias,Avinatan Hassidim,Dale R. Webster,Pushmeet Kohli,S. M. Ali Eslami,Joëlle Barral,Adam Rodman,Vivek Natarajan,Mike Schaekermann,Tao Tu,Alan Karthikesalingam,Ryutaro Tanno*

Main category: cs.CL

TLDR: AMIE（Articulate Medical Intelligence Explorer）通过多模态数据处理能力提升诊断对话性能，在随机盲法研究中表现优于初级保健医生。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在诊断对话中主要限于纯语言交互，无法满足远程医疗中多模态数据的需求。

Method: 利用Gemini 2.0 Flash实现状态感知对话框架，动态控制对话流程，并通过不确定性引导后续问题。

Result: AMIE在多模态和非多模态评估中均显著优于初级保健医生，尤其在诊断准确性方面。

Conclusion: 多模态对话诊断AI取得进展，但实际应用仍需进一步研究。

Abstract: Large Language Models (LLMs) have demonstrated great potential for conducting
diagnostic conversations but evaluation has been largely limited to
language-only interactions, deviating from the real-world requirements of
remote care delivery. Instant messaging platforms permit clinicians and
patients to upload and discuss multimodal medical artifacts seamlessly in
medical consultation, but the ability of LLMs to reason over such data while
preserving other attributes of competent diagnostic conversation remains
unknown. Here we advance the conversational diagnosis and management
performance of the Articulate Medical Intelligence Explorer (AMIE) through a
new capability to gather and interpret multimodal data, and reason about this
precisely during consultations. Leveraging Gemini 2.0 Flash, our system
implements a state-aware dialogue framework, where conversation flow is
dynamically controlled by intermediate model outputs reflecting patient states
and evolving diagnoses. Follow-up questions are strategically directed by
uncertainty in such patient states, leading to a more structured multimodal
history-taking process that emulates experienced clinicians. We compared AMIE
to primary care physicians (PCPs) in a randomized, blinded, OSCE-style study of
chat-based consultations with patient actors. We constructed 105 evaluation
scenarios using artifacts like smartphone skin photos, ECGs, and PDFs of
clinical documents across diverse conditions and demographics. Our rubric
assessed multimodal capabilities and other clinically meaningful axes like
history-taking, diagnostic accuracy, management reasoning, communication, and
empathy. Specialist evaluation showed AMIE to be superior to PCPs on 7/9
multimodal and 29/32 non-multimodal axes (including diagnostic accuracy). The
results show clear progress in multimodal conversational diagnostic AI, but
real-world translation needs further research.

</details>

### [82] [A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient](https://arxiv.org/abs/2505.04654)
*Yehor Tereshchenko,Mika Hämäläinen*

Main category: cs.CL

TLDR: 论文比较了多种AI模型的伦理表现，提出了一种新的危害度量指标RDC，并强调高风险场景中人类监督的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨AI和LLM快速发展带来的伦理问题，如安全性、滥用、歧视和社会影响。

Method: 对多种AI模型（如DeepSeek-V3、GPT系列、Gemini）进行伦理性能比较分析，并引入RDC指标。

Result: 提出了RDC作为衡量LLM危害的新指标，并指出高风险场景需加强人类监督。

Conclusion: AI伦理问题需持续关注，RDC为评估危害提供了新工具，人类监督不可或缺。

Abstract: Artificial Intelligence (AI) and Large Language Models (LLMs) have rapidly
evolved in recent years, showcasing remarkable capabilities in natural language
understanding and generation. However, these advancements also raise critical
ethical questions regarding safety, potential misuse, discrimination and
overall societal impact. This article provides a comparative analysis of the
ethical performance of various AI models, including the brand new
DeepSeek-V3(R1 with reasoning and without), various GPT variants (4o, 3.5
Turbo, 4 Turbo, o1/o3 mini) and Gemini (1.5 flash, 2.0 flash and 2.0 flash exp)
and highlights the need for robust human oversight, especially in situations
with high stakes. Furthermore, we present a new metric for calculating harm in
LLMs called Relative Danger Coefficient (RDC).

</details>

### [83] [Integration of Large Language Models and Traditional Deep Learning for Social Determinants of Health Prediction](https://arxiv.org/abs/2505.04655)
*Paul Landes,Jimeng Sun,Adam Cross*

Main category: cs.CL

TLDR: 论文提出了一种结合传统深度学习和大型语言模型（LLM）的方法，自动从临床文本中提取社会健康决定因素（SDoH），并在分类任务中表现优于基准10个百分点，同时通过优化方法将执行时间缩短12倍。


<details>
  <summary>Details</summary>
Motivation: 社会健康决定因素（SDoH）对个体健康状况有重要影响，但传统方法在自动提取和分类上存在效率或精度不足的问题。

Method: 结合传统深度学习和LLM，提出了一种高效且精确的分类方法，并利用合成数据增强模型性能。

Result: 模型在分类任务中表现优于基准10个百分点，且执行时间缩短12倍；合成数据进一步提升了性能。

Conclusion: 该方法为自动预测影响高危患者的SDoH提供了高效且精确的解决方案。

Abstract: Social Determinants of Health (SDoH) are economic, social and personal
circumstances that affect or influence an individual's health status. SDoHs
have shown to be correlated to wellness outcomes, and therefore, are useful to
physicians in diagnosing diseases and in decision-making. In this work, we
automatically extract SDoHs from clinical text using traditional deep learning
and Large Language Models (LLMs) to find the advantages and disadvantages of
each on an existing publicly available dataset. Our models outperform a
previous reference point on a multilabel SDoH classification by 10 points, and
we present a method and model to drastically speed up classification (12X
execution time) by eliminating expensive LLM processing. The method we present
combines a more nimble and efficient solution that leverages the power of the
LLM for precision and traditional deep learning methods for efficiency. We also
show highly performant results on a dataset supplemented with synthetic data
and several traditional deep learning models that outperform LLMs. Our models
and methods offer the next iteration of automatic prediction of SDoHs that
impact at-risk patients.

</details>

### [84] [AI-Generated Fall Data: Assessing LLMs and Diffusion Model for Wearable Fall Detection](https://arxiv.org/abs/2505.04660)
*Sana Alamgeer,Yasine Souissi,Anne H. H. Ngu*

Main category: cs.CL

TLDR: 研究探索了利用大型语言模型（LLMs）生成合成跌倒数据以解决真实数据稀缺的问题，评估了不同模型的效果及其对跌倒检测性能的影响。


<details>
  <summary>Details</summary>
Motivation: 由于老年人跌倒数据的稀缺性，研究旨在通过生成合成数据来提升跌倒检测系统的训练效果。

Method: 使用文本到运动（T2M, SATO, ParCo）和文本到文本（GPT4o, GPT4, Gemini）模型生成合成数据，并与真实数据集结合，通过LSTM模型评估性能。同时比较了扩散方法与LLM生成数据的分布一致性。

Result: 合成数据的效果受数据集特性影响，LLM数据在低频（20Hz）表现最佳，但在高频（200Hz）不稳定。扩散方法数据与真实数据最接近，但未显著提升模型性能。

Conclusion: 研究为优化跌倒检测模型的合成数据生成提供了见解，强调了数据特性和传感器位置的重要性。

Abstract: Training fall detection systems is challenging due to the scarcity of
real-world fall data, particularly from elderly individuals. To address this,
we explore the potential of Large Language Models (LLMs) for generating
synthetic fall data. This study evaluates text-to-motion (T2M, SATO, ParCo) and
text-to-text models (GPT4o, GPT4, Gemini) in simulating realistic fall
scenarios. We generate synthetic datasets and integrate them with four
real-world baseline datasets to assess their impact on fall detection
performance using a Long Short-Term Memory (LSTM) model. Additionally, we
compare LLM-generated synthetic data with a diffusion-based method to evaluate
their alignment with real accelerometer distributions. Results indicate that
dataset characteristics significantly influence the effectiveness of synthetic
data, with LLM-generated data performing best in low-frequency settings (e.g.,
20Hz) while showing instability in high-frequency datasets (e.g., 200Hz). While
text-to-motion models produce more realistic biomechanical data than
text-to-text models, their impact on fall detection varies. Diffusion-based
synthetic data demonstrates the closest alignment to real data but does not
consistently enhance model performance. An ablation study further confirms that
the effectiveness of synthetic data depends on sensor placement and fall
representation. These findings provide insights into optimizing synthetic data
generation for fall detection models.

</details>

### [85] [Personalized Risks and Regulatory Strategies of Large Language Models in Digital Advertising](https://arxiv.org/abs/2505.04665)
*Haoyang Feng,Yanjun Dai,Yuan Gao*

Main category: cs.CL

TLDR: 论文研究了基于大语言模型的个性化广告推荐系统，结合隐私保护和数据安全措施，提出了一种基于BERT的算法模型，并通过实验验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 探讨在实际运营中，如何将广告推荐系统与用户隐私保护和数据安全措施结合，以解决个性化广告推荐中的风险问题。

Method: 结合BERT模型和注意力机制，构建个性化广告推荐和用户风险保护的算法模型，包括数据预处理、特征选择、广告语义嵌入、本地模型训练和数据加密。

Result: 实验表明，基于BERT的广告推送能有效提高点击率和转化率，同时通过隐私保护机制降低用户数据泄露风险。

Conclusion: 研究为个性化广告推荐提供了一种兼顾效果和隐私保护的解决方案，验证了BERT模型在此领域的潜力。

Abstract: Although large language models have demonstrated the potential for
personalized advertising recommendations in experimental environments, in
actual operations, how advertising recommendation systems can be combined with
measures such as user privacy protection and data security is still an area
worthy of in-depth discussion. To this end, this paper studies the personalized
risks and regulatory strategies of large language models in digital
advertising. This study first outlines the principles of Large Language Model
(LLM), especially the self-attention mechanism based on the Transformer
architecture, and how to enable the model to understand and generate natural
language text. Then, the BERT (Bidirectional Encoder Representations from
Transformers) model and the attention mechanism are combined to construct an
algorithmic model for personalized advertising recommendations and user factor
risk protection. The specific steps include: data collection and preprocessing,
feature selection and construction, using large language models such as BERT
for advertising semantic embedding, and ad recommendations based on user
portraits. Then, local model training and data encryption are used to ensure
the security of user privacy and avoid the leakage of personal data. This paper
designs an experiment for personalized advertising recommendation based on a
large language model of BERT and verifies it with real user data. The
experimental results show that BERT-based advertising push can effectively
improve the click-through rate and conversion rate of advertisements. At the
same time, through local model training and privacy protection mechanisms, the
risk of user privacy leakage can be reduced to a certain extent.

</details>

### [86] [Fine-Tuning Large Language Models and Evaluating Retrieval Methods for Improved Question Answering on Building Codes](https://arxiv.org/abs/2505.04666)
*Mohammad Aqib,Mohd Hamza,Qipei Mei,Ying Hei Chui*

Main category: cs.CL

TLDR: 该研究探讨了利用检索增强生成（RAG）技术构建建筑规范问答系统的可行性，重点评估了检索方法和语言模型微调的效果。


<details>
  <summary>Details</summary>
Motivation: 建筑规范内容复杂且更新频繁，手动查询效率低，需要自动化解决方案。

Method: 研究比较了多种检索方法（如Elasticsearch）和语言模型微调技术，基于加拿大国家建筑规范（NBCC）数据集进行实验。

Result: Elasticsearch表现最佳，语言模型微调后生成能力显著提升。

Conclusion: 结合高效检索器和微调语言模型的RAG系统能有效应对建筑规范的复杂性。

Abstract: Building codes are regulations that establish standards for the design,
construction, and safety of buildings to ensure structural integrity, fire
protection, and accessibility. They are often extensive, complex, and subject
to frequent updates, making manual querying challenging and time-consuming. Key
difficulties include navigating large volumes of text, interpreting technical
language, and identifying relevant clauses across different sections. A
potential solution is to build a Question-Answering (QA) system that answers
user queries based on building codes. Among the various methods for building a
QA system, Retrieval-Augmented Generation (RAG) stands out in performance. RAG
consists of two components: a retriever and a language model. This study
focuses on identifying a suitable retriever method for building codes and
optimizing the generational capability of the language model using fine-tuning
techniques. We conducted a detailed evaluation of various retrieval methods by
performing the retrieval on the National Building Code of Canada (NBCC) and
explored the impact of domain-specific fine-tuning on several language models
using the dataset derived from NBCC. Our analysis included a comparative
assessment of different retrievers and the performance of both pre-trained and
fine-tuned models to determine the efficacy and domain-specific adaptation of
language models using fine-tuning on the NBCC dataset. Experimental results
showed that Elasticsearch proved to be the most robust retriever among all. The
findings also indicate that fine-tuning language models on an NBCC-specific
dataset can enhance their ability to generate contextually relevant responses.
When combined with context retrieved by a powerful retriever like
Elasticsearch, this improvement in LLM performance can optimize the RAG system,
enabling it to better navigate the complexities of the NBCC.

</details>

### [87] [Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards](https://arxiv.org/abs/2505.04671)
*Yuxin Zhang,Meihao Fan,Ju Fan,Mingyang Yi,Yuyu Luo,Jian Tan,Guoliang Li*

Main category: cs.CL

TLDR: Reward-SQL框架通过引入过程奖励模型（PRMs）优化Text-to-SQL任务，采用“冷启动后PRM监督”策略，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有PRMs在Text-to-SQL任务中可能因误用导致推理轨迹扭曲，需系统研究如何有效整合PRMs。

Method: 先通过Chain-of-CTEs分解SQL查询建立推理基线，再探索四种PRM整合策略，最佳组合为在线训练信号（GRPO）与PRM引导推理。

Result: 在BIRD基准测试中，Reward-SQL使7B PRM监督模型性能提升13.1%，GRPO策略模型达到68.9%准确率。

Conclusion: Reward-SQL有效利用奖励监督提升Text-to-SQL推理性能，代码已公开。

Abstract: Recent advances in large language models (LLMs) have significantly improved
performance on the Text-to-SQL task by leveraging their powerful reasoning
capabilities. To enhance accuracy during the reasoning process, external
Process Reward Models (PRMs) can be introduced during training and inference to
provide fine-grained supervision. However, if misused, PRMs may distort the
reasoning trajectory and lead to suboptimal or incorrect SQL generation.To
address this challenge, we propose Reward-SQL, a framework that systematically
explores how to incorporate PRMs into the Text-to-SQL reasoning process
effectively. Our approach follows a "cold start, then PRM supervision"
paradigm. Specifically, we first train the model to decompose SQL queries into
structured stepwise reasoning chains using common table expressions
(Chain-of-CTEs), establishing a strong and interpretable reasoning baseline.
Then, we investigate four strategies for integrating PRMs, and find that
combining PRM as an online training signal (GRPO) with PRM-guided inference
(e.g., best-of-N sampling) yields the best results. Empirically, on the BIRD
benchmark, Reward-SQL enables models supervised by a 7B PRM to achieve a 13.1%
performance gain across various guidance strategies. Notably, our GRPO-aligned
policy model based on Qwen2.5-Coder-7B-Instruct achieves 68.9% accuracy on the
BIRD development set, outperforming all baseline methods under the same model
size. These results demonstrate the effectiveness of Reward-SQL in leveraging
reward-based supervision for Text-to-SQL reasoning. Our code is publicly
available.

</details>

### [88] [REVEAL: Multi-turn Evaluation of Image-Input Harms for Vision LLM](https://arxiv.org/abs/2505.04673)
*Madhur Jindal,Saurabh Deshpande*

Main category: cs.CL

TLDR: REVEAL框架用于评估视觉大语言模型（VLLMs）的安全性，发现多轮对话中的缺陷率显著高于单轮对话，GPT-4o表现最佳。


<details>
  <summary>Details</summary>
Motivation: 传统安全评估框架无法应对VLLMs在多模态和多轮对话中的复杂性，需要新的评估方法。

Method: 提出REVEAL框架，包括自动图像挖掘、合成对抗数据生成、多轮对话扩展和全面危害评估。

Result: 评估了五种VLLMs，发现多轮对话缺陷率更高，GPT-4o表现最平衡，Llama-3.2缺陷率最高。

Conclusion: 多轮对话暴露VLLMs更深层漏洞，需加强上下文防御，尤其是针对错误信息。

Abstract: Vision Large Language Models (VLLMs) represent a significant advancement in
artificial intelligence by integrating image-processing capabilities with
textual understanding, thereby enhancing user interactions and expanding
application domains. However, their increased complexity introduces novel
safety and ethical challenges, particularly in multi-modal and multi-turn
conversations. Traditional safety evaluation frameworks, designed for
text-based, single-turn interactions, are inadequate for addressing these
complexities. To bridge this gap, we introduce the REVEAL (Responsible
Evaluation of Vision-Enabled AI LLMs) Framework, a scalable and automated
pipeline for evaluating image-input harms in VLLMs. REVEAL includes automated
image mining, synthetic adversarial data generation, multi-turn conversational
expansion using crescendo attack strategies, and comprehensive harm assessment
through evaluators like GPT-4o.
  We extensively evaluated five state-of-the-art VLLMs, GPT-4o, Llama-3.2,
Qwen2-VL, Phi3.5V, and Pixtral, across three important harm categories: sexual
harm, violence, and misinformation. Our findings reveal that multi-turn
interactions result in significantly higher defect rates compared to
single-turn evaluations, highlighting deeper vulnerabilities in VLLMs. Notably,
GPT-4o demonstrated the most balanced performance as measured by our
Safety-Usability Index (SUI) followed closely by Pixtral. Additionally,
misinformation emerged as a critical area requiring enhanced contextual
defenses. Llama-3.2 exhibited the highest MT defect rate ($16.55 \%$) while
Qwen2-VL showed the highest MT refusal rate ($19.1 \%$).

</details>

### [89] [Advanced Deep Learning Approaches for Automated Recognition of Cuneiform Symbols](https://arxiv.org/abs/2505.04678)
*Shahad Elshehaby,Alavikunhu Panthakkan,Hussain Al-Ahmad,Mina Al-Saad*

Main category: cs.CL

TLDR: 本文提出了一种基于深度学习的自动化方法，用于识别和解释楔形文字字符，并通过五种模型在性能指标上进行了评估，其中两种表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索楔形文字的识别与翻译，结合计算语言学和考古学，为人类历史的理解与保护提供新视角。

Method: 训练五种深度学习模型，评估其准确性和精确度，并在汉谟拉比法典的楔形文字上进行测试。

Result: 两种模型表现优异，能准确识别阿卡德语符号并提供精确的英文翻译。

Conclusion: 未来将研究集成和堆叠方法以优化性能，同时探索阿卡德语与阿拉伯语的语言学关系。

Abstract: This paper presents a thoroughly automated method for identifying and
interpreting cuneiform characters via advanced deep-learning algorithms. Five
distinct deep-learning models were trained on a comprehensive dataset of
cuneiform characters and evaluated according to critical performance metrics,
including accuracy and precision. Two models demonstrated outstanding
performance and were subsequently assessed using cuneiform symbols from the
Hammurabi law acquisition, notably Hammurabi Law 1. Each model effectively
recognized the relevant Akkadian meanings of the symbols and delivered precise
English translations. Future work will investigate ensemble and stacking
approaches to optimize performance, utilizing hybrid architectures to improve
detection accuracy and reliability. This research explores the linguistic
relationships between Akkadian, an ancient Mesopotamian language, and Arabic,
emphasizing their historical and cultural linkages. This study demonstrates the
capability of deep learning to decipher ancient scripts by merging
computational linguistics with archaeology, therefore providing significant
insights for the comprehension and conservation of human history.

</details>

### [90] [SOAEsV2-7B/72B: Full-Pipeline Optimization for State-Owned Enterprise LLMs via Continual Pre-Training, Domain-Progressive SFT and Distillation-Enhanced Speculative Decoding](https://arxiv.org/abs/2505.04723)
*Jingyang Deng,Ran Chen,Jo-Ku Cheng,Jinwen Ma*

Main category: cs.CL

TLDR: 该研究提出了一种针对中国国有资产的领域专用大语言模型（LLM）开发框架，解决了模型容量限制、过度依赖监督微调数据及推理效率低的问题。通过三阶段方法（持续预训练、渐进领域微调和蒸馏增强推测解码），模型在保持通用能力的同时显著提升了领域性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法在开发面向中国国有资产和企业的领域专用LLM时存在模型容量限制、过度依赖监督微调数据以及推理效率低的问题，亟需一种更全面的解决方案。

Method: 采用三阶段框架：1）持续预训练整合领域知识；2）渐进领域监督微调（SFT）从弱相关数据过渡到专家标注数据；3）蒸馏增强推测解码加速推理。

Result: 实验表明，模型在保持99.8%通用能力的同时显著提升领域性能（Rouge-1提升1.08倍，BLEU-4提升1.17倍），推理速度提升1.39-1.52倍。

Conclusion: 该研究为优化国有资产领域专用LLM提供了一种全流程方法，成功弥合了通用语言能力与领域专业知识之间的差距。

Abstract: This study addresses key challenges in developing domain-specific large
language models (LLMs) for Chinese state-owned assets and enterprises (SOAEs),
where current approaches face three limitations: 1) constrained model capacity
that limits knowledge integration and cross-task adaptability; 2) excessive
reliance on domain-specific supervised fine-tuning (SFT) data, which neglects
the broader applicability of general language patterns; and 3) inefficient
inference acceleration for large models processing long contexts. In this work,
we propose SOAEsV2-7B/72B, a specialized LLM series developed via a three-phase
framework: 1) continual pre-training integrates domain knowledge while
retaining base capabilities; 2) domain-progressive SFT employs curriculum-based
learning strategy, transitioning from weakly relevant conversational data to
expert-annotated SOAEs datasets to optimize domain-specific tasks; 3)
distillation-enhanced speculative decoding accelerates inference via logit
distillation between 72B target and 7B draft models, achieving
1.39-1.52$\times$ speedup without quality loss. Experimental results
demonstrate that our domain-specific pre-training phase maintains 99.8% of
original general language capabilities while significantly improving domain
performance, resulting in a 1.08$\times$ improvement in Rouge-1 score and a
1.17$\times$ enhancement in BLEU-4 score. Ablation studies further show that
domain-progressive SFT outperforms single-stage training, achieving
1.02$\times$ improvement in Rouge-1 and 1.06$\times$ in BLEU-4. Our work
introduces a comprehensive, full-pipeline approach for optimizing SOAEs LLMs,
bridging the gap between general language capabilities and domain-specific
expertise.

</details>

### [91] [Flower Across Time and Media: Sentiment Analysis of Tang Song Poetry and Visual Correspondence](https://arxiv.org/abs/2505.04785)
*Shuai Gong,Tiange Zhou*

Main category: cs.CL

TLDR: 该研究通过BERT情感分析量化唐宋诗歌中花卉意象的情感模式，并将其与装饰艺术的发展进行对比，填补了文学情感与视觉文化关联的研究空白。


<details>
  <summary>Details</summary>
Motivation: 探索唐宋时期花卉意象在诗歌与视觉艺术中的情感表达关联，弥补现有研究的不足。

Method: 使用微调的BERT模型分析唐宋诗歌中的牡丹和梅花意象，并与纺织品、陶瓷等视觉艺术进行交叉验证。

Result: 发现唐宋时期花卉意象的情感内涵存在显著变化，揭示了文学表达与艺术表现之间未被认识的协同关系。

Conclusion: 研究为理解唐宋文化中的情感与艺术互动提供了新视角，展示了计算人文与传统汉学方法的结合潜力。

Abstract: The Tang (618 to 907) and Song (960 to 1279) dynasties witnessed an
extraordinary flourishing of Chinese cultural expression, where floral motifs
served as a dynamic medium for both poetic sentiment and artistic design. While
previous scholarship has examined these domains independently, the systematic
correlation between evolving literary emotions and visual culture remains
underexplored. This study addresses that gap by employing BERT-based sentiment
analysis to quantify emotional patterns in floral imagery across Tang Song
poetry, then validating these patterns against contemporaneous developments in
decorative arts.Our approach builds upon recent advances in computational
humanities while remaining grounded in traditional sinological methods. By
applying a fine tuned BERT model to analyze peony and plum blossom imagery in
classical poetry, we detect measurable shifts in emotional connotations between
the Tang and Song periods. These textual patterns are then cross berenced with
visual evidence from textiles, ceramics, and other material culture, revealing
previously unrecognized synergies between literary expression and artistic
representation.

</details>

### [92] [Osiris: A Lightweight Open-Source Hallucination Detection System](https://arxiv.org/abs/2505.04844)
*Alex Shan,John Bauer,Christopher D. Manning*

Main category: cs.CL

TLDR: 本文提出了一种基于监督微调的幻觉检测方法，使用7B模型在RAGTruth基准测试中表现优于GPT-4o，解决了现有方法成本高、速度慢的问题。


<details>
  <summary>Details</summary>
Motivation: RAG系统中LLM生成的响应可能存在幻觉，现有检测方法依赖人工或闭源模型，成本高且难以扩展。

Method: 通过构建一个包含诱导幻觉的扰动多跳QA数据集，并对其进行监督微调。

Result: 7B模型在RAGTruth基准测试中的召回率优于GPT-4o，同时在精度和准确率上表现竞争性。

Conclusion: 该方法在幻觉检测任务中高效且可扩展，代码已开源。

Abstract: Retrieval-Augmented Generation (RAG) systems have gained widespread adoption
by application builders because they leverage sources of truth to enable Large
Language Models (LLMs) to generate more factually sound responses. However,
hallucinations, instances of LLM responses that are unfaithful to the provided
context, often prevent these systems from being deployed in production
environments. Current hallucination detection methods typically involve human
evaluation or the use of closed-source models to review RAG system outputs for
hallucinations. Both human evaluators and closed-source models suffer from
scaling issues due to their high costs and slow inference speeds. In this work,
we introduce a perturbed multi-hop QA dataset with induced hallucinations. Via
supervised fine-tuning on our dataset, we achieve better recall with a 7B model
than GPT-4o on the RAGTruth hallucination detection benchmark and offer
competitive performance on precision and accuracy, all while using a fraction
of the parameters. Code is released at our repository.

</details>

### [93] [Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards](https://arxiv.org/abs/2505.04847)
*Manveer Singh Tamber,Forrest Sheng Bao,Chenyu Xu,Ge Luo,Suleman Kazi,Minseok Bae,Miaoran Li,Ofer Mendelevitch,Renyi Qu,Jimmy Lin*

Main category: cs.CL

TLDR: 论文探讨了LLM幻觉问题，提出了FaithJudge方法改进评估，并引入新的幻觉排行榜。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在RAG中仍频繁产生幻觉的问题，改进现有评估方法。

Method: 提出FaithJudge方法，基于少量人工标注的LLM-as-a-judge评估。

Result: FaithJudge显著优于现有方法，并推出新的幻觉排行榜。

Conclusion: FaithJudge为LLM幻觉评估提供了更可靠的基准。

Abstract: Hallucinations remain a persistent challenge for LLMs. RAG aims to reduce
hallucinations by grounding responses in contexts. However, even when provided
context, LLMs still frequently introduce unsupported information or
contradictions. This paper presents our efforts to measure LLM hallucinations
with a focus on summarization tasks, assessing how often various LLMs introduce
hallucinations when summarizing documents. We discuss Vectara's existing LLM
hallucination leaderboard, based on the Hughes Hallucination Evaluation Model
(HHEM). While HHEM and Vectara's Hallucination Leaderboard have garnered great
research interest, we examine challenges faced by HHEM and current
hallucination detection methods by analyzing the effectiveness of these methods
on existing hallucination datasets. To address these limitations, we propose
FaithJudge, an LLM-as-a-judge approach guided by few-shot human hallucination
annotations, which substantially improves automated LLM hallucination
evaluation over current methods. We introduce an enhanced hallucination
leaderboard centered on FaithJudge, alongside our current hallucination
leaderboard, enabling more reliable benchmarking of LLMs for hallucinations in
RAG.

</details>

### [94] [An Open-Source Dual-Loss Embedding Model for Semantic Retrieval in Higher Education](https://arxiv.org/abs/2505.04916)
*Ramteja Sajja,Yusuf Sermet,Ibrahim Demir*

Main category: cs.CL

TLDR: 论文提出了两种针对教育问答优化的开源嵌入模型，通过合成数据集和双损失训练策略，显著提升了语义检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有语义检索系统难以适应学术内容的独特语言和结构特征，需要针对教育领域优化的嵌入模型。

Method: 构建了包含3,197对句子的合成数据集，并比较了两种训练策略：基于MNRL的基线模型和结合MNRL与CosineSimilarityLoss的双损失模型。

Result: 两种模型均优于开源基线，双损失模型缩小了与高性能专有嵌入（如OpenAI的text-embedding-3系列）的性能差距。

Conclusion: 该研究提供了可复用的教育领域嵌入模型和语义检索框架，支持学术聊天机器人等下游应用。

Abstract: Recent advances in AI have catalyzed the adoption of intelligent educational
tools, yet many semantic retrieval systems remain ill-suited to the unique
linguistic and structural characteristics of academic content. This study
presents two open-source embedding models fine-tuned for educational question
answering, particularly in the context of course syllabi. A synthetic dataset
of 3,197 sentence pairs, spanning synonymous terminology, paraphrased
questions, and implicit-explicit mappings, was constructed through a
combination of manual curation and large language model (LLM)-assisted
generation. Two training strategies were evaluated: (1) a baseline model
fine-tuned using MultipleNegativesRankingLoss (MNRL), and (2) a dual-loss model
that combines MNRL with CosineSimilarityLoss to improve both semantic ranking
and similarity calibration. Evaluations were conducted on 28 university course
syllabi using a fixed set of natural language questions categorized into
course, faculty, and teaching assistant information. Results demonstrate that
both fine-tuned models outperform strong open-source baselines, including
all-MiniLM-L6-v2 and multi-qa-MiniLM-L6-cos-v1, and that the dual-loss model
narrows the performance gap with high-performing proprietary embeddings such as
OpenAI's text-embedding-3 series. This work contributes reusable,
domain-aligned embedding models and provides a replicable framework for
educational semantic retrieval, supporting downstream applications such as
academic chatbots, retrieval-augmented generation (RAG) systems, and learning
management system (LMS) integrations.

</details>

### [95] [Chain-of-Thought Tokens are Computer Program Variables](https://arxiv.org/abs/2505.04955)
*Fangwei Zhu,Peiyi Wang,Zhifang Sui*

Main category: cs.CL

TLDR: 研究发现，Chain-of-thoughts（CoT）中的中间结果存储是关键，而非所有中间步骤。CoT令牌可能类似程序变量，但存在潜在缺陷。


<details>
  <summary>Details</summary>
Motivation: 探索CoT在LLMs中的内部机制，尤其是其令牌在复杂推理任务中的作用。

Method: 在组合任务（多位数乘法和动态规划）上实证研究CoT令牌的作用，包括保留中间结果、替代潜在形式存储及随机干预值。

Result: 仅保留中间结果令牌即可达到类似性能；替代存储形式不影响表现；干预值会改变后续令牌和最终答案。

Conclusion: CoT令牌可能类似程序变量，但需注意其潜在缺陷（如捷径和计算复杂度限制）。

Abstract: Chain-of-thoughts (CoT) requires large language models (LLMs) to generate
intermediate steps before reaching the final answer, and has been proven
effective to help LLMs solve complex reasoning tasks. However, the inner
mechanism of CoT still remains largely unclear. In this paper, we empirically
study the role of CoT tokens in LLMs on two compositional tasks: multi-digit
multiplication and dynamic programming. While CoT is essential for solving
these problems, we find that preserving only tokens that store intermediate
results would achieve comparable performance. Furthermore, we observe that
storing intermediate results in an alternative latent form will not affect
model performance. We also randomly intervene some values in CoT, and notice
that subsequent CoT tokens and the final answer would change correspondingly.
These findings suggest that CoT tokens may function like variables in computer
programs but with potential drawbacks like unintended shortcuts and
computational complexity limits between tokens. The code and data are available
at https://github.com/solitaryzero/CoTs_are_Variables.

</details>

### [96] [Rethinking the Relationship between the Power Law and Hierarchical Structures](https://arxiv.org/abs/2505.04984)
*Kai Nakaishi,Ryo Yoshida,Kohei Kajikawa,Koji Hukushima,Yohei Oseki*

Main category: cs.CL

TLDR: 该论文通过分析英语语料库中的句法树，验证了关于幂律衰减与层次结构关系的假设是否成立，发现假设不成立，并指出需要重新思考幂律与层次结构的关系。


<details>
  <summary>Details</summary>
Motivation: 研究动机是验证幂律衰减是否可以作为句法层次结构的证据，填补这一假设缺乏实证支持的空白。

Method: 方法包括分析英语语料库中的句法树，计算互信息、与概率上下文无关文法（PCFG）的偏差等统计特性。

Result: 结果表明，假设不成立，句法结构不符合幂律衰减与层次结构的关系，且该论点难以推广到儿童语言和动物信号。

Conclusion: 结论是需要重新审视幂律与层次结构的关系，并进一步研究其普遍性。

Abstract: Statistical analysis of corpora provides an approach to quantitatively
investigate natural languages. This approach has revealed that several power
laws consistently emerge across different corpora and languages, suggesting the
universal principles underlying languages. Particularly, the power-law decay of
correlation has been interpreted as evidence for underlying hierarchical
structures in syntax, semantics, and discourse. This perspective has also been
extended to child languages and animal signals. However, the argument
supporting this interpretation has not been empirically tested. To address this
problem, this study examines the validity of the argument for syntactic
structures. Specifically, we test whether the statistical properties of parse
trees align with the implicit assumptions in the argument. Using English
corpora, we analyze the mutual information, deviations from probabilistic
context-free grammars (PCFGs), and other properties in parse trees, as well as
in the PCFG that approximates these trees. Our results indicate that the
assumptions do not hold for syntactic structures and that it is difficult to
apply the proposed argument to child languages and animal signals, highlighting
the need to reconsider the relationship between the power law and hierarchical
structures.

</details>

### [97] [Latent Preference Coding: Aligning Large Language Models via Discrete Latent Codes](https://arxiv.org/abs/2505.04993)
*Zhuocheng Gong,Jian Guan,Wei Wu,Huishuai Zhang,Dongyan Zhao*

Main category: cs.CL

TLDR: 论文提出了一种名为LPC的新框架，用于建模人类偏好的隐含因素及其组合，无需依赖预定义的奖励函数，显著提升了对齐算法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖显式或隐式奖励函数，忽略了人类偏好的复杂性和多面性，难以处理不同任务和人群中的冲突因素。

Method: LPC通过离散潜在代码建模隐含因素及其组合，自动从数据中推断这些因素及其重要性，并与多种离线对齐算法无缝集成。

Result: 实验表明，LPC在多个基准测试中显著提升了三种对齐算法（DPO、SimPO、IPO）的性能，潜在代码有效捕捉了人类偏好的分布差异并增强了鲁棒性。

Conclusion: LPC为多面偏好因素提供了统一表示，为开发更鲁棒和通用的对齐技术铺平了道路，有助于LLM的负责任部署。

Abstract: Large language models (LLMs) have achieved remarkable success, yet aligning
their generations with human preferences remains a critical challenge. Existing
approaches to preference modeling often rely on an explicit or implicit reward
function, overlooking the intricate and multifaceted nature of human
preferences that may encompass conflicting factors across diverse tasks and
populations. To address this limitation, we introduce Latent Preference Coding
(LPC), a novel framework that models the implicit factors as well as their
combinations behind holistic preferences using discrete latent codes. LPC
seamlessly integrates with various offline alignment algorithms, automatically
inferring the underlying factors and their importance from data without relying
on pre-defined reward functions and hand-crafted combination weights. Extensive
experiments on multiple benchmarks demonstrate that LPC consistently improves
upon three alignment algorithms (DPO, SimPO, and IPO) using three base models
(Mistral-7B, Llama3-8B, and Llama3-8B-Instruct). Furthermore, deeper analysis
reveals that the learned latent codes effectively capture the differences in
the distribution of human preferences and significantly enhance the robustness
of alignment against noise in data. By providing a unified representation for
the multifarious preference factors, LPC paves the way towards developing more
robust and versatile alignment techniques for the responsible deployment of
powerful LLMs.

</details>

### [98] [Rethinking Invariance in In-context Learning](https://arxiv.org/abs/2505.04994)
*Lizhe Fang,Yifei Wang,Khashayar Gatmiry,Lei Fang,Yisen Wang*

Main category: cs.CL

TLDR: 论文提出了一种名为InvICL的新方法，解决了现有ICL算法对上下文顺序敏感的问题，同时实现了信息不泄漏和上下文相互依赖两个关键特性。


<details>
  <summary>Details</summary>
Motivation: 现有ICL算法对上下文顺序敏感，且缺乏同时满足信息不泄漏和上下文相互依赖的解决方案。

Method: 提出InvICL方法，通过设计满足信息不泄漏和上下文相互依赖的特性，实现ICL的排列不变性。

Result: InvICL在大多数基准数据集上优于现有方法，展示了更强的泛化能力。

Conclusion: InvICL是一种有效的ICL方法，解决了顺序敏感性问题，同时提升了性能。

Abstract: In-Context Learning (ICL) has emerged as a pivotal capability of
auto-regressive large language models, yet it is hindered by a notable
sensitivity to the ordering of context examples regardless of their mutual
independence. To address this issue, recent studies have introduced several
variant algorithms of ICL that achieve permutation invariance. However, many of
these do not exhibit comparable performance with the standard auto-regressive
ICL algorithm. In this work, we identify two crucial elements in the design of
an invariant ICL algorithm: information non-leakage and context
interdependence, which are not simultaneously achieved by any of the existing
methods. These investigations lead us to the proposed Invariant ICL (InvICL), a
methodology designed to achieve invariance in ICL while ensuring the two
properties. Empirically, our findings reveal that InvICL surpasses previous
models, both invariant and non-invariant, in most benchmark datasets,
showcasing superior generalization capabilities across varying input lengths.
Code is available at https://github.com/PKU-ML/InvICL.

</details>

### [99] [The Pitfalls of Growing Group Complexity: LLMs and Social Choice-Based Aggregation for Group Recommendations](https://arxiv.org/abs/2505.05016)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TLDR: 研究探讨了大型语言模型（LLMs）在零样本学习下如何正确执行基于社交选择的聚合策略，以及提示格式对准确性的影响。结果显示，超过100个评分时性能下降，但不同模型对复杂度的敏感度不同。上下文学习（ICL）能显著提升性能，而其他提示修改无显著影响。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在群体推荐系统（GRS）中的应用条件，特别是零样本学习下模型的表现及提示格式的影响。

Method: 分析不同LLMs在不同提示条件下（如上下文学习、解释生成）的表现，重点关注群体复杂度（用户和物品数量）和偏好格式的影响。

Result: 性能在超过100个评分时下降，但不同模型对复杂度的敏感度不同。ICL显著提升性能，其他提示修改无影响。偏好格式（如按用户或物品列评分）影响准确性。

Conclusion: 未来研究应考虑群体复杂度对LLM性能的影响。较小LLMs在适当条件下可生成群体推荐，降低计算成本和资源需求。

Abstract: Large Language Models (LLMs) are increasingly applied in recommender systems
aimed at both individuals and groups. Previously, Group Recommender Systems
(GRS) often used social choice-based aggregation strategies to derive a single
recommendation based on the preferences of multiple people. In this paper, we
investigate under which conditions language models can perform these strategies
correctly based on zero-shot learning and analyse whether the formatting of the
group scenario in the prompt affects accuracy. We specifically focused on the
impact of group complexity (number of users and items), different LLMs,
different prompting conditions, including In-Context learning or generating
explanations, and the formatting of group preferences. Our results show that
performance starts to deteriorate when considering more than 100 ratings.
However, not all language models were equally sensitive to growing group
complexity. Additionally, we showed that In-Context Learning (ICL) can
significantly increase the performance at higher degrees of group complexity,
while adding other prompt modifications, specifying domain cues or prompting
for explanations, did not impact accuracy. We conclude that future research
should include group complexity as a factor in GRS evaluation due to its effect
on LLM performance. Furthermore, we showed that formatting the group scenarios
differently, such as rating lists per user or per item, affected accuracy. All
in all, our study implies that smaller LLMs are capable of generating group
recommendations under the right conditions, making the case for using smaller
models that require less computing power and costs.

</details>

### [100] [Scalable Multi-Stage Influence Function for Large Language Models via Eigenvalue-Corrected Kronecker-Factored Parameterization](https://arxiv.org/abs/2505.05017)
*Yuntai Bao,Xuhong Zhang,Tianyu Du,Xinkui Zhao,Jiang Zong,Hao Peng,Jianwei Yin*

Main category: cs.CL

TLDR: 提出了一种多阶段影响函数方法，用于将微调后大语言模型的预测归因于预训练数据，并通过EK-FAC参数化提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法计算多阶段影响且难以扩展到亿级参数的大语言模型。

Method: 提出多阶段影响函数，结合EK-FAC参数化进行高效近似。

Result: 实验验证了EK-FAC的扩展性和多阶段影响函数的有效性，并通过案例展示了其解释能力。

Conclusion: 多阶段影响函数为微调后大语言模型的预测提供了可扩展且有效的解释工具。

Abstract: Pre-trained large language models (LLMs) are commonly fine-tuned to adapt to
downstream tasks. Since the majority of knowledge is acquired during
pre-training, attributing the predictions of fine-tuned LLMs to their
pre-training data may provide valuable insights. Influence functions have been
proposed as a means to explain model predictions based on training data.
However, existing approaches fail to compute ``multi-stage'' influence and lack
scalability to billion-scale LLMs.
  In this paper, we propose the multi-stage influence function to attribute the
downstream predictions of fine-tuned LLMs to pre-training data under the
full-parameter fine-tuning paradigm. To enhance the efficiency and practicality
of our multi-stage influence function, we leverage Eigenvalue-corrected
Kronecker-Factored (EK-FAC) parameterization for efficient approximation.
Empirical results validate the superior scalability of EK-FAC approximation and
the effectiveness of our multi-stage influence function. Additionally, case
studies on a real-world LLM, dolly-v2-3b, demonstrate its interpretive power,
with exemplars illustrating insights provided by multi-stage influence
estimates. Our code is public at
https://github.com/colored-dye/multi_stage_influence_function.

</details>

### [101] [G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness](https://arxiv.org/abs/2505.05026)
*Jaehyun Jeon,Janghan Yoon,Minsoo Kim,Sumin Shim,Yejin Choi,Hanbin Kim,Youngjae Yu*

Main category: cs.CL

TLDR: 论文提出了WiserUI-Bench基准和G-FOCUS推理策略，用于评估UI设计的说服力，旨在替代或补充昂贵的A/B测试。


<details>
  <summary>Details</summary>
Motivation: 当前A/B测试成本高且耗时，而现有视觉语言模型（VLM）方法未能有效评估UI设计的比较说服力。

Method: 引入WiserUI-Bench基准（包含300个真实UI图像对）和G-FOCUS推理策略，减少位置偏差并提高评估准确性。

Result: 实验表明，G-FOCUS在一致性和准确性上优于现有推理策略。

Conclusion: 该工作为UI设计优化提供了可扩展的解决方案，推动了VLM在UI评估中的应用。

Abstract: Evaluating user interface (UI) design effectiveness extends beyond aesthetics
to influencing user behavior, a principle central to Design Persuasiveness. A/B
testing is the predominant method for determining which UI variations drive
higher user engagement, but it is costly and time-consuming. While recent
Vision-Language Models (VLMs) can process automated UI analysis, current
approaches focus on isolated design attributes rather than comparative
persuasiveness-the key factor in optimizing user interactions. To address this,
we introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design
Persuasiveness Assessment task, featuring 300 real-world UI image pairs labeled
with A/B test results and expert rationales. Additionally, we propose G-FOCUS,
a novel inference-time reasoning strategy that enhances VLM-based
persuasiveness assessment by reducing position bias and improving evaluation
accuracy. Experimental results show that G-FOCUS surpasses existing inference
strategies in consistency and accuracy for pairwise UI evaluation. Through
promoting VLM-driven evaluation of UI persuasiveness, our work offers an
approach to complement A/B testing, propelling progress in scalable UI
preference modeling and design optimization. Code and data will be released
publicly.

</details>

### [102] [Image-Text Relation Prediction for Multilingual Tweets](https://arxiv.org/abs/2505.05040)
*Matīss Rikters,Edison Marrese-Taylor*

Main category: cs.CL

TLDR: 研究探讨多语言视觉语言模型在不同语言中预测图像与文本关系的能力，并构建了一个平衡的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 尽管社交媒体允许媒体上传多年，但图像与文本的关系仍不明确，研究旨在探索模型在此任务上的表现。

Method: 构建了一个来自拉脱维亚Twitter帖子及其英文翻译的平衡基准数据集，并测试多语言视觉语言模型。

Result: 较新的视觉语言模型在此任务上表现更好，但仍需改进。

Conclusion: 视觉语言模型在图像与文本关系预测上有进步，但仍有提升空间。

Abstract: Various social networks have been allowing media uploads for over a decade
now. Still, it has not always been clear what is their relation with the posted
text or even if there is any at all. In this work, we explore how multilingual
vision-language models tackle the task of image-text relation prediction in
different languages, and construct a dedicated balanced benchmark data set from
Twitter posts in Latvian along with their manual translations into English. We
compare our results to previous work and show that the more recently released
vision-language model checkpoints are becoming increasingly capable at this
task, but there is still much room for further improvement.

</details>

### [103] [Teochew-Wild: The First In-the-wild Teochew Dataset with Orthographic Annotations](https://arxiv.org/abs/2505.05056)
*Linrong Pan,Chenglong Jiang,Gaoze Hou,Ying Gao*

Main category: cs.CL

TLDR: 该论文介绍了Teochew-Wild语料库的构建，包含18.9小时的多场景潮汕方言语音数据，配有精确的文本和拼音标注，并提供了辅助工具，验证了其在ASR和TTS任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 潮汕方言是一种低资源语言，缺乏公开可用的语音数据集，阻碍了相关研究和应用的发展。

Method: 构建了包含多场景语音数据的Teochew-Wild语料库，提供文本和拼音标注，并开发了辅助工具。

Result: 实验验证了该语料库在自动语音识别（ASR）和文本转语音（TTS）任务中的有效性。

Conclusion: Teochew-Wild是首个公开可用的潮汕方言语音数据集，为低资源语言的研究和应用提供了重要资源。

Abstract: This paper reports the construction of the Teochew-Wild, a speech corpus of
the Teochew dialect. The corpus includes 18.9 hours of in-the-wild Teochew
speech data from multiple speakers, covering both formal and colloquial
expressions, with precise orthographic and pinyin annotations. Additionally, we
provide supplementary text processing tools and resources to propel research
and applications in speech tasks for this low-resource language, such as
automatic speech recognition (ASR) and text-to-speech (TTS). To the best of our
knowledge, this is the first publicly available Teochew dataset with accurate
orthographic annotations. We conduct experiments on the corpus, and the results
validate its effectiveness in ASR and TTS tasks.

</details>

### [104] [Performance Evaluation of Large Language Models in Bangla Consumer Health Query Summarization](https://arxiv.org/abs/2505.05070)
*Ajwad Abrar,Farzana Tabassum,Sabbir Ahmed*

Main category: cs.CL

TLDR: 研究评估了九种大型语言模型（LLMs）在零样本条件下对孟加拉语消费者健康查询（CHQs）的摘要能力，发现Mixtral-8x22b-Instruct在ROUGE-1和ROUGE-L上表现最佳，而微调的Bangla T5在ROUGE-2上更优，表明零样本LLMs可媲美微调模型。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为低资源语言，其消费者健康查询常含冗余信息，需高效摘要以支持医疗响应。

Method: 使用BanglaCHQ-Summ数据集（2,350对标注查询-摘要）和ROUGE指标，比较九种LLMs与微调的Bangla T5模型。

Result: Mixtral-8x22b-Instruct在ROUGE-1和ROUGE-L上表现最佳，Bangla T5在ROUGE-2上更优。

Conclusion: 零样本LLMs能提供高质量摘要，为低资源语言的医疗查询摘要提供可扩展解决方案。

Abstract: Consumer Health Queries (CHQs) in Bengali (Bangla), a low-resource language,
often contain extraneous details, complicating efficient medical responses.
This study investigates the zero-shot performance of nine advanced large
language models (LLMs): GPT-3.5-Turbo, GPT-4, Claude-3.5-Sonnet,
Llama3-70b-Instruct, Mixtral-8x22b-Instruct, Gemini-1.5-Pro,
Qwen2-72b-Instruct, Gemma-2-27b, and Athene-70B, in summarizing Bangla CHQs.
Using the BanglaCHQ-Summ dataset comprising 2,350 annotated query-summary
pairs, we benchmarked these LLMs using ROUGE metrics against Bangla T5, a
fine-tuned state-of-the-art model. Mixtral-8x22b-Instruct emerged as the top
performing model in ROUGE-1 and ROUGE-L, while Bangla T5 excelled in ROUGE-2.
The results demonstrate that zero-shot LLMs can rival fine-tuned models,
achieving high-quality summaries even without task-specific training. This work
underscores the potential of LLMs in addressing challenges in low-resource
languages, providing scalable solutions for healthcare query summarization.

</details>

### [105] [Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction](https://arxiv.org/abs/2505.05084)
*Xiaowei Zhu,Yubing Ren,Yanan Cao,Xixun Lin,Fang Fang,Yangxi Li*

Main category: cs.CL

TLDR: 本文提出了一种基于多尺度共形预测（MCP）的零样本机器生成文本检测框架，以解决现有检测方法因高误报率（FPR）带来的社会风险问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展引发了对恶意滥用的担忧，现有检测方法过度关注准确性而忽视了高误报率的社会风险。

Method: 利用共形预测（CP）约束误报率上限，并提出多尺度共形预测（MCP）框架，以平衡误报率约束与检测性能。同时引入高质量数据集RealDet。

Result: MCP有效约束误报率，显著提升检测性能，并增强对抗攻击的鲁棒性。

Conclusion: MCP框架在约束误报率和提升检测性能方面表现优异，为机器生成文本检测提供了实用解决方案。

Abstract: The rapid advancement of large language models has raised significant
concerns regarding their potential misuse by malicious actors. As a result,
developing effective detectors to mitigate these risks has become a critical
priority. However, most existing detection methods focus excessively on
detection accuracy, often neglecting the societal risks posed by high false
positive rates (FPRs). This paper addresses this issue by leveraging Conformal
Prediction (CP), which effectively constrains the upper bound of FPRs. While
directly applying CP constrains FPRs, it also leads to a significant reduction
in detection performance. To overcome this trade-off, this paper proposes a
Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal
Prediction (MCP), which both enforces the FPR constraint and improves detection
performance. This paper also introduces RealDet, a high-quality dataset that
spans a wide range of domains, ensuring realistic calibration and enabling
superior detection performance when combined with MCP. Empirical evaluations
demonstrate that MCP effectively constrains FPRs, significantly enhances
detection performance, and increases robustness against adversarial attacks
across multiple detectors and datasets.

</details>

### [106] [Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders](https://arxiv.org/abs/2505.05111)
*Boyi Deng,Yu Wan,Yidan Zhang,Baosong Yang,Fuli Feng*

Main category: cs.CL

TLDR: 论文探讨了大型语言模型（LLMs）的多语言能力机制，提出了一种基于稀疏自编码器（SAEs）的新方法，发现语言特定特征，并通过这些特征实现对LLMs生成语言的精准控制。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经元或内部激活的方法在多语言能力分析中存在局限性，如叠加效应和层间激活差异，需要更可靠的分析工具。

Method: 使用稀疏自编码器（SAEs）分解LLMs的激活，提出新指标评估特征的单一语言性，并通过特征消融实验验证其语言特异性。

Result: 发现某些SAE特征与特定语言强相关，消融这些特征仅显著影响单一语言能力；还发现多语言协同特征，联合消融效果更显著。

Conclusion: SAEs为多语言能力分析提供了新视角，其语言特定特征可用于增强对LLMs生成语言的控制。

Abstract: The mechanisms behind multilingual capabilities in Large Language Models
(LLMs) have been examined using neuron-based or internal-activation-based
methods. However, these methods often face challenges such as superposition and
layer-wise activation variance, which limit their reliability. Sparse
Autoencoders (SAEs) offer a more nuanced analysis by decomposing the
activations of LLMs into sparse linear combination of SAE features. We
introduce a novel metric to assess the monolinguality of features obtained from
SAEs, discovering that some features are strongly related to specific
languages. Additionally, we show that ablating these SAE features only
significantly reduces abilities in one language of LLMs, leaving others almost
unaffected. Interestingly, we find some languages have multiple synergistic SAE
features, and ablating them together yields greater improvement than ablating
individually. Moreover, we leverage these SAE-derived language-specific
features to enhance steering vectors, achieving control over the language
generated by LLMs.

</details>

### [107] [A Benchmark Dataset and a Framework for Urdu Multimodal Named Entity Recognition](https://arxiv.org/abs/2505.05148)
*Hussain Ahmad,Qingyang Zeng,Jing Wan*

Main category: cs.CL

TLDR: 论文提出了U-MNER框架和Twitter2015-Urdu数据集，填补了乌尔都语多模态命名实体识别（MNER）的研究空白，并通过融合文本和视觉信息实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如乌尔都语）在多模态命名实体识别领域缺乏标注数据集和标准化基线的问题。

Method: 结合Urdu-BERT提取文本嵌入和ResNet提取视觉特征，通过跨模态融合模块对齐和融合信息。

Result: 在Twitter2015-Urdu数据集上实现了最先进的性能。

Conclusion: U-MNER框架为低资源语言的MNER研究奠定了基础。

Abstract: The emergence of multimodal content, particularly text and images on social
media, has positioned Multimodal Named Entity Recognition (MNER) as an
increasingly important area of research within Natural Language Processing.
Despite progress in high-resource languages such as English, MNER remains
underexplored for low-resource languages like Urdu. The primary challenges
include the scarcity of annotated multimodal datasets and the lack of
standardized baselines. To address these challenges, we introduce the U-MNER
framework and release the Twitter2015-Urdu dataset, a pioneering resource for
Urdu MNER. Adapted from the widely used Twitter2015 dataset, it is annotated
with Urdu-specific grammar rules. We establish benchmark baselines by
evaluating both text-based and multimodal models on this dataset, providing
comparative analyses to support future research on Urdu MNER. The U-MNER
framework integrates textual and visual context using Urdu-BERT for text
embeddings and ResNet for visual feature extraction, with a Cross-Modal Fusion
Module to align and fuse information. Our model achieves state-of-the-art
performance on the Twitter2015-Urdu dataset, laying the groundwork for further
MNER research in low-resource languages.

</details>

### [108] [QualBench: Benchmarking Chinese LLMs with Localized Professional Qualifications for Vertical Domain Evaluation](https://arxiv.org/abs/2505.05225)
*Mengze Hong,Wailing Ng,Di Jiang,Chen Jason Zhang*

Main category: cs.CL

TLDR: QualBench是首个专注于中文大语言模型（LLM）本地化评估的多领域问答基准，覆盖6个垂直领域，包含17,000多个问题。Qwen2.5模型表现优于GPT-4o，中文LLM整体优于非中文模型，凸显本地化知识的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有基准在垂直领域覆盖不足，且缺乏对中国工作场景的针对性评估。

Method: 利用资格考试作为统一框架，构建QualBench数据集，基于24项中国资格考试设计问题。

Result: Qwen2.5模型表现最佳（75.26%），中文LLM优于非中文模型，但领域覆盖仍有不足。LLM与众包机制协作失败。

Conclusion: 需通过多领域RAG知识增强和联邦学习的垂直领域LLM训练来提升模型能力。

Abstract: The rapid advancement of Chinese large language models (LLMs) underscores the
need for domain-specific evaluations to ensure reliable applications. However,
existing benchmarks often lack coverage in vertical domains and offer limited
insights into the Chinese working context. Leveraging qualification exams as a
unified framework for human expertise evaluation, we introduce QualBench, the
first multi-domain Chinese QA benchmark dedicated to localized assessment of
Chinese LLMs. The dataset includes over 17,000 questions across six vertical
domains, with data selections grounded in 24 Chinese qualifications to closely
align with national policies and working standards. Through comprehensive
evaluation, the Qwen2.5 model outperformed the more advanced GPT-4o, with
Chinese LLMs consistently surpassing non-Chinese models, highlighting the
importance of localized domain knowledge in meeting qualification requirements.
The best performance of 75.26% reveals the current gaps in domain coverage
within model capabilities. Furthermore, we present the failure of LLM
collaboration with crowdsourcing mechanisms and suggest the opportunities for
multi-domain RAG knowledge enhancement and vertical domain LLM training with
Federated Learning.

</details>

### [109] [T-T: Table Transformer for Tagging-based Aspect Sentiment Triplet Extraction](https://arxiv.org/abs/2505.05271)
*Kun Peng,Chaodong Tong,Cong Cao,Hao Peng,Qian Li,Guanlin Wu,Lei Jiang,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TLDR: 论文提出了一种基于表格标记的Transformer模型（T-T），通过引入条纹注意力和循环移位策略，解决了传统Transformer在ASTE任务中面临的长序列和局部注意力不公平的问题，实现了更高效的关系学习。


<details>
  <summary>Details</summary>
Motivation: 由于Transformer在语义建模上的强大能力，作者尝试将其直接用于ASTE任务的关系学习模块，但面临长序列和局部注意力不公平的挑战。

Method: 提出Table-Transformer（T-T），引入条纹注意力机制和循环移位策略，优化全局注意力为局部窗口，并促进不同窗口间的交互。

Result: 实验表明，T-T作为下游关系学习模块，以较低计算成本实现了最先进的性能。

Conclusion: T-T通过创新的注意力机制，有效解决了Transformer在ASTE任务中的挑战，显著提升了模型性能。

Abstract: Aspect sentiment triplet extraction (ASTE) aims to extract triplets composed
of aspect terms, opinion terms, and sentiment polarities from given sentences.
The table tagging method is a popular approach to addressing this task, which
encodes a sentence into a 2-dimensional table, allowing for the tagging of
relations between any two words. Previous efforts have focused on designing
various downstream relation learning modules to better capture interactions
between tokens in the table, revealing that a stronger capability to capture
relations can lead to greater improvements in the model. Motivated by this, we
attempt to directly utilize transformer layers as downstream relation learning
modules. Due to the powerful semantic modeling capability of transformers, it
is foreseeable that this will lead to excellent improvement. However, owing to
the quadratic relation between the length of the table and the length of the
input sentence sequence, using transformers directly faces two challenges:
overly long table sequences and unfair local attention interaction. To address
these challenges, we propose a novel Table-Transformer (T-T) for the
tagging-based ASTE method. Specifically, we introduce a stripe attention
mechanism with a loop-shift strategy to tackle these challenges. The former
modifies the global attention mechanism to only attend to a 2-dimensional local
attention window, while the latter facilitates interaction between different
attention windows. Extensive and comprehensive experiments demonstrate that the
T-T, as a downstream relation learning module, achieves state-of-the-art
performance with lower computational costs.

</details>

### [110] [Toward Reasonable Parrots: Why Large Language Models Should Argue with Us by Design](https://arxiv.org/abs/2505.05298)
*Elena Musi,Nadin Kokciyan,Khalid Al-Khatib,Davide Ceolin,Emmanuelle Dietz,Klara Gutekunst,Annette Hautli-Janisz,Cristian Manuel Santibañez Yañez,Jodi Schneider,Jonas Scholz,Cor Steging,Jacky Visser,Henning Wachsmuth*

Main category: cs.CL

TLDR: 论文主张开发支持论证过程的对话技术，提出LLMs目前不足，并提出以‘合理鹦鹉’为设计理念的技术框架。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在支持论证过程中存在不足，需重新设计技术以提升论证能力。

Method: 提出‘合理鹦鹉’概念，结合论证理论的基本原则（相关性、责任、自由）和对话动作。

Result: 为LLM技术提供了基于论证理论的设计起点。

Conclusion: 应重新定位LLMs为辅助批判性思维的工具，而非替代品。

Abstract: In this position paper, we advocate for the development of conversational
technology that is inherently designed to support and facilitate argumentative
processes. We argue that, at present, large language models (LLMs) are
inadequate for this purpose, and we propose an ideal technology design aimed at
enhancing argumentative skills. This involves re-framing LLMs as tools to
exercise our critical thinking rather than replacing them. We introduce the
concept of 'reasonable parrots' that embody the fundamental principles of
relevance, responsibility, and freedom, and that interact through argumentative
dialogical moves. These principles and moves arise out of millennia of work in
argumentation theory and should serve as the starting point for LLM-based
technology that incorporates basic principles of argumentation.

</details>

### [111] [ICon: In-Context Contribution for Automatic Data Selection](https://arxiv.org/abs/2505.05327)
*Yixin Yang,Qingxiu Dong,Linli Yao,Fangwei Zhu,Zhifang Sui*

Main category: cs.CL

TLDR: 提出了一种名为ICon的梯度无关方法，利用上下文学习的隐式微调特性高效测量样本贡献，显著提升模型性能并降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法依赖计算昂贵的梯度或人工启发式，未能充分利用数据内在属性，ICon旨在解决这一问题。

Method: ICon通过上下文学习的隐式学习评估性能变化，无需梯度计算或人工指标设计，包含三个组件。

Result: 实验表明，ICon在多个基准测试中表现优异，仅用15%数据训练即可超越完整数据集和其他方法。

Conclusion: ICon高效且有效，所选样本兼具任务多样性和适当难度，而非仅最难题。

Abstract: Data selection for instruction tuning is essential for improving the
performance of Large Language Models (LLMs) and reducing training cost.
However, existing automated selection methods either depend on computationally
expensive gradient-based measures or manually designed heuristics, which may
fail to fully exploit the intrinsic attributes of data. In this paper, we
propose In-context Learning for Contribution Measurement (ICon), a novel
gradient-free method that takes advantage of the implicit fine-tuning nature of
in-context learning (ICL) to measure sample contribution without gradient
computation or manual indicators engineering. ICon offers a computationally
efficient alternative to gradient-based methods and reduces human inductive
bias inherent in heuristic-based approaches. ICon comprises three components
and identifies high-contribution data by assessing performance shifts under
implicit learning through ICL. Extensive experiments on three LLMs across 12
benchmarks and 5 pairwise evaluation sets demonstrate the effectiveness of
ICon. Remarkably, on LLaMA3.1-8B, models trained on 15% of ICon-selected data
outperform full datasets by 5.42% points and exceed the best performance of
widely used selection methods by 2.06% points. We further analyze
high-contribution samples selected by ICon, which show both diverse tasks and
appropriate difficulty levels, rather than just the hardest ones.

</details>

### [112] [Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than Humans?](https://arxiv.org/abs/2505.05406)
*Valeria Pastorino,Nafise Sadat Moosavi*

Main category: cs.CL

TLDR: 研究发现，大型语言模型（LLM）生成的新闻内容在政治和社会敏感话题中比人类作者更容易表现出明显的框架偏见，且不同模型架构的偏见程度差异显著。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在自动新闻生成中可能引入或放大的框架偏见，以评估其对公众认知的潜在影响。

Method: 分析未经调整和微调的LLM生成的新闻内容中的框架表现，重点关注政治和社会敏感话题。

Result: LLM在敏感话题中表现出比人类更显著的框架偏见，且不同模型的偏见程度差异明显。

Conclusion: 需要开发有效的训练后缓解策略和更严格的评估框架，以确保自动新闻内容的平衡性。

Abstract: Framing in media critically shapes public perception by selectively
emphasizing some details while downplaying others. With the rise of large
language models in automated news and content creation, there is growing
concern that these systems may introduce or even amplify framing biases
compared to human authors. In this paper, we explore how framing manifests in
both out-of-the-box and fine-tuned LLM-generated news content. Our analysis
reveals that, particularly in politically and socially sensitive contexts, LLMs
tend to exhibit more pronounced framing than their human counterparts. In
addition, we observe significant variation in framing tendencies across
different model architectures, with some models displaying notably higher
biases. These findings point to the need for effective post-training mitigation
strategies and tighter evaluation frameworks to ensure that automated news
content upholds the standards of balanced reporting.

</details>

### [113] [Crosslingual Reasoning through Test-Time Scaling](https://arxiv.org/abs/2505.05408)
*Zheng-Xin Yong,M. Farid Adilazuarda,Jonibek Mansurov,Ruochen Zhang,Niklas Muennighoff,Carsten Eickhoff,Genta Indra Winata,Julia Kreutzer,Stephen H. Bach,Alham Fikri Aji*

Main category: cs.CL

TLDR: 研究探讨了英语推理微调在多语言中的泛化能力，发现计算扩展提升多语言数学推理能力，但低资源语言和跨领域推理仍需改进。


<details>
  <summary>Details</summary>
Motivation: 探究英语推理微调在多语言环境中的泛化效果及其机制。

Method: 通过扩展推理计算、分析思维链模式及控制推理语言策略进行研究。

Result: 英语推理模型在高资源语言中表现更优，低资源语言和跨领域推理效果较差。

Conclusion: 建议在高资源语言中使用英语推理模型，并需进一步优化低资源语言和跨领域推理能力。

Abstract: Reasoning capabilities of large language models are primarily studied for
English, even when pretrained models are multilingual. In this work, we
investigate to what extent English reasoning finetuning with long
chain-of-thoughts (CoTs) can generalize across languages. First, we find that
scaling up inference compute for English-centric reasoning language models
(RLMs) improves multilingual mathematical reasoning across many languages
including low-resource languages, to an extent where they outperform models
twice their size. Second, we reveal that while English-centric RLM's CoTs are
naturally predominantly English, they consistently follow a quote-and-think
pattern to reason about quoted non-English inputs. Third, we discover an
effective strategy to control the language of long CoT reasoning, and we
observe that models reason better and more efficiently in high-resource
languages. Finally, we observe poor out-of-domain reasoning generalization, in
particular from STEM to cultural commonsense knowledge, even for English.
Overall, we demonstrate the potentials, study the mechanisms and outline the
limitations of crosslingual generalization of English reasoning test-time
scaling. We conclude that practitioners should let English-centric RLMs reason
in high-resource languages, while further work is needed to improve reasoning
in low-resource languages and out-of-domain contexts.

</details>

### [114] [Reasoning Models Don't Always Say What They Think](https://arxiv.org/abs/2505.05410)
*Yanda Chen,Joe Benton,Ansh Radhakrishnan,Jonathan Uesato,Carson Denison,John Schulman,Arushi Somani,Peter Hase,Misha Wagner,Fabien Roger,Vlad Mikulik,Samuel R. Bowman,Jan Leike,Jared Kaplan,Ethan Perez*

Main category: cs.CL

TLDR: 研究评估了链式思维（CoT）在AI安全中的有效性，发现其虽能部分揭示模型推理过程，但揭示率通常低于20%，且强化学习效果有限。


<details>
  <summary>Details</summary>
Motivation: 探索CoT是否能忠实反映AI模型的推理过程，以提升AI安全性。

Method: 评估6种推理提示下CoT的忠实性，并分析强化学习对忠实性的影响。

Result: CoT揭示推理提示的比率通常低于20%；强化学习初期有效但效果有限；奖励破解未增加提示的显性表达。

Conclusion: CoT监控在训练和评估中有潜力，但不足以完全避免意外行为，尤其是在非必要CoT推理的场景中。

Abstract: Chain-of-thought (CoT) offers a potential boon for AI safety as it allows
monitoring a model's CoT to try to understand its intentions and reasoning
processes. However, the effectiveness of such monitoring hinges on CoTs
faithfully representing models' actual reasoning processes. We evaluate CoT
faithfulness of state-of-the-art reasoning models across 6 reasoning hints
presented in the prompts and find: (1) for most settings and models tested,
CoTs reveal their usage of hints in at least 1% of examples where they use the
hint, but the reveal rate is often below 20%, (2) outcome-based reinforcement
learning initially improves faithfulness but plateaus without saturating, and
(3) when reinforcement learning increases how frequently hints are used (reward
hacking), the propensity to verbalize them does not increase, even without
training against a CoT monitor. These results suggest that CoT monitoring is a
promising way of noticing undesired behaviors during training and evaluations,
but that it is not sufficient to rule them out. They also suggest that in
settings like ours where CoT reasoning is not necessary, test-time monitoring
of CoTs is unlikely to reliably catch rare and catastrophic unexpected
behaviors.

</details>

### [115] [TransProQA: an LLM-based literary Translation evaluation metric with Professional Question Answering](https://arxiv.org/abs/2505.05423)
*Ran Zhang,Wei Zhao,Lieve Macken,Steffen Eger*

Main category: cs.CL

TLDR: TransProQA是一种基于LLM的无参考QA框架，专为文学翻译评估设计，整合专业译者见解，显著优于现有指标。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标偏重机械准确性，忽视艺术表达，可能影响翻译质量和文化真实性，需专门文学评估指标。

Method: 提出TransProQA框架，结合专业译者见解，关注文学质量评估关键要素（如文学手法、文化理解、作者声音）。

Result: TransProQA显著优于现有指标，相关性提升0.07，在充分性评估中超过SOTA指标15分以上，接近人类评估水平。

Conclusion: TransProQA具有广泛适用性，可作为无训练文学评估指标，适用于需本地处理的文本。

Abstract: The impact of Large Language Models (LLMs) has extended into literary
domains. However, existing evaluation metrics prioritize mechanical accuracy
over artistic expression and tend to overrate machine translation (MT) as being
superior to experienced professional human translation. In the long run, this
bias could result in a permanent decline in translation quality and cultural
authenticity. In response to the urgent need for a specialized literary
evaluation metric, we introduce TransProQA, a novel, reference-free, LLM-based
question-answering (QA) framework designed specifically for literary
translation evaluation. TransProQA uniquely integrates insights from
professional literary translators and researchers, focusing on critical
elements in literary quality assessment such as literary devices, cultural
understanding, and authorial voice. Our extensive evaluation shows that while
literary-finetuned XCOMET-XL yields marginal gains, TransProQA substantially
outperforms current metrics, achieving up to 0.07 gain in correlation (ACC-EQ
and Kendall's tau) and surpassing the best state-of-the-art (SOTA) metrics by
over 15 points in adequacy assessments. Incorporating professional translator
insights as weights further improves performance, highlighting the value of
translator inputs. Notably, TransProQA approaches human-level evaluation
performance comparable to trained linguistic annotators. It demonstrates broad
applicability to open-source models such as LLaMA3.3-70b and Qwen2.5-32b,
indicating its potential as an accessible and training-free literary evaluation
metric and a valuable tool for evaluating texts that require local processing
due to copyright or ethical considerations.

</details>

### [116] [Ultra-FineWeb: Efficient Data Filtering and Verification for High-Quality LLM Training Data](https://arxiv.org/abs/2505.05427)
*Yudong Wang,Zixuan Fu,Jie Cai,Peijun Tang,Hongya Lyu,Yewei Fang,Zhi Zheng,Jie Zhou,Guoyang Zeng,Chaojun Xiao,Xu Han,Zhiyuan Liu*

Main category: cs.CL

TLDR: 论文提出了一种高效的数据过滤管道，解决了数据验证和种子数据选择的问题，显著提升了数据质量和训练效率。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的发展，数据质量成为提升模型性能的关键因素，但现有方法在数据验证和种子数据选择上存在挑战。

Method: 引入高效验证策略和优化种子数据选择，构建基于fastText的轻量级分类器，应用于FineWeb和Chinese FineWeb数据集。

Result: 创建了高质量的Ultra-FineWeb数据集，训练后的LLMs在多个基准任务中表现显著提升。

Conclusion: 提出的数据过滤管道有效提升了数据质量和训练效率，验证了其在实际应用中的价值。

Abstract: Data quality has become a key factor in enhancing model performance with the
rapid development of large language models (LLMs). Model-driven data filtering
has increasingly become a primary approach for acquiring high-quality data.
However, it still faces two main challenges: (1) the lack of an efficient data
verification strategy makes it difficult to provide timely feedback on data
quality; and (2) the selection of seed data for training classifiers lacks
clear criteria and relies heavily on human expertise, introducing a degree of
subjectivity. To address the first challenge, we introduce an efficient
verification strategy that enables rapid evaluation of the impact of data on
LLM training with minimal computational cost. To tackle the second challenge,
we build upon the assumption that high-quality seed data is beneficial for LLM
training, and by integrating the proposed verification strategy, we optimize
the selection of positive and negative samples and propose an efficient data
filtering pipeline. This pipeline not only improves filtering efficiency,
classifier quality, and robustness, but also significantly reduces experimental
and inference costs. In addition, to efficiently filter high-quality data, we
employ a lightweight classifier based on fastText, and successfully apply the
filtering pipeline to two widely-used pre-training corpora, FineWeb and Chinese
FineWeb datasets, resulting in the creation of the higher-quality Ultra-FineWeb
dataset. Ultra-FineWeb contains approximately 1 trillion English tokens and 120
billion Chinese tokens. Empirical results demonstrate that the LLMs trained on
Ultra-FineWeb exhibit significant performance improvements across multiple
benchmark tasks, validating the effectiveness of our pipeline in enhancing both
data quality and training efficiency.

</details>

### [117] [clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations](https://arxiv.org/abs/2505.05445)
*Chalamalasetti Kranti,Sherzod Hakimov,David Schlangen*

Main category: cs.CL

TLDR: 提出了一个名为clem todd的框架，用于在一致条件下系统评估对话系统，支持用户模拟器和对话系统的灵活组合，并提供统一的评估标准。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常孤立评估对话系统的组件，限制了跨架构和配置的通用性。

Method: 开发了clem todd框架，支持插件式集成，统一数据集、评估指标和计算约束。

Result: 通过重新评估现有系统和集成新系统，提供了关于架构、规模和提示策略对对话性能影响的实用见解。

Conclusion: clem todd为构建高效对话系统提供了实用指导，并展示了其灵活性和实用性。

Abstract: The emergence of instruction-tuned large language models (LLMs) has advanced
the field of dialogue systems, enabling both realistic user simulations and
robust multi-turn conversational agents. However, existing research often
evaluates these components in isolation-either focusing on a single user
simulator or a specific system design-limiting the generalisability of insights
across architectures and configurations. In this work, we propose clem todd
(chat-optimized LLMs for task-oriented dialogue systems development), a
flexible framework for systematically evaluating dialogue systems under
consistent conditions. clem todd enables detailed benchmarking across
combinations of user simulators and dialogue systems, whether existing models
from literature or newly developed ones. It supports plug-and-play integration
and ensures uniform datasets, evaluation metrics, and computational
constraints. We showcase clem todd's flexibility by re-evaluating existing
task-oriented dialogue systems within this unified setup and integrating three
newly proposed dialogue systems into the same evaluation pipeline. Our results
provide actionable insights into how architecture, scale, and prompting
strategies affect dialogue performance, offering practical guidance for
building efficient and effective conversational AI systems.

</details>

### [118] [UKElectionNarratives: A Dataset of Misleading Narratives Surrounding Recent UK General Elections](https://arxiv.org/abs/2505.05459)
*Fatima Haouari,Carolina Scarton,Nicolò Faggiani,Nikolaos Nikolaidis,Bonka Kotseva,Ibrahim Abu Farha,Jens Linge,Kalina Bontcheva*

Main category: cs.CL

TLDR: 论文提出了一种欧洲选举中常见误导性叙事的分类法，并构建了首个标注数据集UKElectionNarratives，评估了预训练和大型语言模型（如GPT-4o）在检测误导性叙事中的效果。


<details>
  <summary>Details</summary>
Motivation: 误导性叙事在选举中影响公众观点，需要准确检测。

Method: 提出分类法并构建标注数据集，评估预训练和大型语言模型的检测效果。

Result: 构建了UKElectionNarratives数据集，并展示了模型在检测误导性叙事中的表现。

Conclusion: 讨论了潜在应用场景，并提出了未来研究方向。

Abstract: Misleading narratives play a crucial role in shaping public opinion during
elections, as they can influence how voters perceive candidates and political
parties. This entails the need to detect these narratives accurately. To
address this, we introduce the first taxonomy of common misleading narratives
that circulated during recent elections in Europe. Based on this taxonomy, we
construct and analyse UKElectionNarratives: the first dataset of
human-annotated misleading narratives which circulated during the UK General
Elections in 2019 and 2024. We also benchmark Pre-trained and Large Language
Models (focusing on GPT-4o), studying their effectiveness in detecting
election-related misleading narratives. Finally, we discuss potential use cases
and make recommendations for future research directions using the proposed
codebook and dataset.

</details>

### [119] [Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging](https://arxiv.org/abs/2505.05464)
*Shiqi Chen,Jinghan Zhang,Tongyao Zhu,Wei Liu,Siyang Gao,Miao Xiong,Manling Li,Junxian He*

Main category: cs.CL

TLDR: 通过模型合并将大型语言模型（LLMs）的推理能力融入视觉语言模型（VLMs），探索感知与推理的结合机制。


<details>
  <summary>Details</summary>
Motivation: 理解视觉感知与语言推理如何结合及其贡献机制。

Method: 提出跨模态模型合并方法，无需训练即可将LLMs的推理能力转移到VLMs。

Result: 实验表明合并成功，且感知能力集中在模型早期层，推理能力则由中后层主导；合并后各层均参与推理。

Conclusion: 模型合并是多模态集成与解释的有效工具。

Abstract: Vision-Language Models (VLMs) combine visual perception with the general
capabilities, such as reasoning, of Large Language Models (LLMs). However, the
mechanisms by which these two abilities can be combined and contribute remain
poorly understood. In this work, we explore to compose perception and reasoning
through model merging that connects parameters of different models. Unlike
previous works that often focus on merging models of the same kind, we propose
merging models across modalities, enabling the incorporation of the reasoning
capabilities of LLMs into VLMs. Through extensive experiments, we demonstrate
that model merging offers a successful pathway to transfer reasoning abilities
from LLMs to VLMs in a training-free manner. Moreover, we utilize the merged
models to understand the internal mechanism of perception and reasoning and how
merging affects it. We find that perception capabilities are predominantly
encoded in the early layers of the model, whereas reasoning is largely
facilitated by the middle-to-late layers. After merging, we observe that all
layers begin to contribute to reasoning, whereas the distribution of perception
abilities across layers remains largely unchanged. These observations shed
light on the potential of model merging as a tool for multimodal integration
and interpretation.

</details>

### [120] [ComPO: Preference Alignment via Comparison Oracles](https://arxiv.org/abs/2505.05465)
*Peter Chen,Xi Chen,Wotao Yin,Tianyi Lin*

Main category: cs.CL

TLDR: 本文提出了一种基于比较预言机的新偏好对齐方法，解决了现有直接对齐方法中的冗长和似然位移问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有直接对齐方法存在冗长和似然位移问题，这些问题源于噪声偏好对导致偏好和非偏好响应的似然相似。

Method: 提出基于比较预言机的偏好对齐方法，提供其基本方案的收敛保证，并通过启发式方法改进。

Result: 实验表明，该方法在多个基准测试中有效提升了LLM性能，并验证了其对噪声偏好对的适应性。

Conclusion: 本文方法为现有直接对齐方法的局限性提供了替代解决方案，并强调了设计针对不同似然边际偏好对的专用方法的重要性。

Abstract: Direct alignment methods are increasingly used for aligning large language
models (LLMs) with human preferences. However, these methods suffer from the
issues of verbosity and likelihood displacement, which can be driven by the
noisy preference pairs that induce similar likelihood for preferred and
dispreferred responses. The contributions of this paper are two-fold. First, we
propose a new preference alignment method based on comparison oracles and
provide the convergence guarantee for its basic scheme. Second, we improve our
method using some heuristics and conduct the experiments to demonstrate the
flexibility and compatibility of practical scheme in improving the performance
of LLMs using noisy preference pairs. Evaluations are conducted across multiple
base and instruction-tuned models (Mistral-7B, Llama-3-8B and Gemma-2-9B) with
benchmarks (AlpacaEval 2, MT-Bench and Arena-Hard). Experimental results show
the effectiveness of our method as an alternative to addressing the limitations
of existing direct alignment methods. A highlight of our work is that we
evidence the importance of designing specialized methods for preference pairs
with distinct likelihood margin, which complements the recent findings in
\citet{Razin-2025-Unintentional}.

</details>

<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [121] [Towards Artificial Intelligence Research Assistant for Expert-Involved Learning](https://arxiv.org/abs/2505.04638)
*Tianyu Liu,Simeng Han,Xiao Luo,Hanchen Wang,Pan Lu,Biqing Zhu,Yuge Wang,Keyi Li,Jiapeng Chen,Rihao Qu,Yufeng Liu,Xinyue Cui,Aviv Yaish,Yuhang Chen,Minsheng Hao,Chuhan Li,Kexing Li,Arman Cohan,Hua Xu,Mark Gerstein,James Zou,Hongyu Zhao*

Main category: cs.AI

TLDR: ARIEL是一个多模态数据集，用于评估和提升LLMs和LMMs在生物医学研究中的文本摘要和图像解释能力，通过专家评估和模型优化取得显著成果。


<details>
  <summary>Details</summary>
Motivation: LLMs和LMMs在生物医学研究中的可靠性和贡献尚未充分研究，ARIEL旨在填补这一空白。

Method: 创建开放数据集，结合专家评估，通过提示工程、微调和计算扩展优化模型性能。

Result: 模型在文本摘要和图像解释上表现优于人类专家，并探索了LMMs生成科学假设的潜力。

Conclusion: 研究明确了当前模型的优势和局限，为未来生物医学研究中大规模语言和多模态模型的应用提供了指导。

Abstract: Large Language Models (LLMs) and Large Multi-Modal Models (LMMs) have emerged
as transformative tools in scientific research, yet their reliability and
specific contributions to biomedical applications remain insufficiently
characterized. In this study, we present \textbf{AR}tificial
\textbf{I}ntelligence research assistant for \textbf{E}xpert-involved
\textbf{L}earning (ARIEL), a multimodal dataset designed to benchmark and
enhance two critical capabilities of LLMs and LMMs in biomedical research:
summarizing extensive scientific texts and interpreting complex biomedical
figures. To facilitate rigorous assessment, we create two open-source sets
comprising biomedical articles and figures with designed questions. We
systematically benchmark both open- and closed-source foundation models,
incorporating expert-driven human evaluations conducted by doctoral-level
experts. Furthermore, we improve model performance through targeted prompt
engineering and fine-tuning strategies for summarizing research papers, and
apply test-time computational scaling to enhance the reasoning capabilities of
LMMs, achieving superior accuracy compared to human-expert corrections. We also
explore the potential of using LMM Agents to generate scientific hypotheses
from diverse multimodal inputs. Overall, our results delineate clear strengths
and highlight significant limitations of current foundation models, providing
actionable insights and guiding future advancements in deploying large-scale
language and multi-modal models within biomedical research.

</details>

### [122] [Computational Irreducibility as the Foundation of Agency: A Formal Model Connecting Undecidability to Autonomous Behavior in Complex Systems](https://arxiv.org/abs/2505.04646)
*Poria Azadi*

Main category: cs.AI

TLDR: 本文通过将计算极限（可判定性、完备性、计算不可约性）与物理概念结合，探讨了自主性和能动性的起源。提出了一个‘最小代理’模型，并证明真正的自主性必然导致外部视角的不可判定性。


<details>
  <summary>Details</summary>
Motivation: 研究自主性和能动性的计算基础，以区分自主系统与可预测系统。

Method: 使用算法信息理论，构建‘最小代理’模型，分析代理与环境交互的计算不可约性和不可判定性。

Result: 证明自主性必然伴随外部不可判定性，能动性源于代理与环境耦合的复杂性。

Conclusion: 该框架为理解意识、设计自主AI及重新定义自由意志提供了计算视角。

Abstract: This article explores the emergence of autonomy and agency by connecting
fundamental computational limits (decidability, completeness, computational
irreducibility) with physical concepts. We introduce a formal model of a
"minimal agent" operating within potentially Turing-complete environments.
Using algorithmic information theory, we argue that the inherent undecidability
and computational irreducibility of agent-environment interaction lead to
unpredictability and novel information generation, enabling agency (effective
goal-directed action). Computational irreducibility prevents full external
prediction, creating necessary conditions for autonomous behavior. We relate
this to computational sourcehood, where an agent is the irreducible origin of
its behavior, though formalizing this concept remains challenging. Our central
thesis, formally proven, is that genuine autonomy necessarily implies
undecidability from an external perspective, distinguishing autonomous systems
from predictable ones. We propose that agency arises when agent-environment
coupling complexity allows mutual information between internal states and
relevant environmental variables to increase, particularly where analytical
solutions are absent and operational closure is needed for persistence. This
framework links agency directly to the computational properties of interaction,
offering implications for understanding consciousness, designing autonomous AI,
and reconceptualizing free will in a deterministic yet computationally
irreducible universe.

</details>

### [123] [Dynamic Location Search for Identifying Maximum Weighted Independent Sets in Complex Networks](https://arxiv.org/abs/2505.04674)
*Enqiang Zhu,Chenkai Hao,Chanjuan Liu,Yongsheng Rao*

Main category: cs.AI

TLDR: 提出了一种名为DynLS的高效算法，用于解决最大加权独立集（MWIS）问题，该算法在智能交通系统中表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在智能交通系统中表现优异，但其训练时间和计算资源需求较高，尤其是在大规模复杂场景中。

Method: DynLS结合了基于分数的自适应顶点扰动（SAVP）、区域定位机制（RLM）和组合局部搜索策略（ComLS）三种创新技术。

Result: DynLS在360个测试实例中表现最佳，解决了350个实例，并在收敛速度上媲美第二优算法。

Conclusion: DynLS为MWIS问题提供了高效的启发式算法，有助于优化智能交通系统中的AI技术。

Abstract: While Artificial intelligence (AI), including Generative AI, are effective at
generating high-quality traffic data and optimization solutions in intelligent
transportation systems (ITSs), these techniques often demand significant
training time and computational resources, especially in large-scale and
complex scenarios. To address this, we introduce a novel and efficient
algorithm for solving the maximum weighted independent set (MWIS) problem,
which can be used to model many ITSs applications, such as traffic signal
control and vehicle routing. Given the NP-hard nature of the MWIS problem, our
proposed algorithm, DynLS, incorporates three key innovations to solve it
effectively. First, it uses a scores-based adaptive vertex perturbation (SAVP)
technique to accelerate convergence, particularly in sparse graphs. Second, it
includes a region location mechanism (RLM) to help escape local optima by
dynamically adjusting the search space. Finally, it employs a novel variable
neighborhood descent strategy, ComLS, which combines vertex exchange strategies
with a reward mechanism to guide the search toward high-quality solutions. Our
experimental results demonstrate DynLS's superior performance, consistently
delivering high-quality solutions within 1000 seconds. DynLS outperformed five
leading algorithms across 360 test instances, achieving the best solution for
350 instances and surpassing the second-best algorithm, Cyclic-Fast, by 177
instances. Moreover, DynLS matched Cyclic-Fast's convergence speed,
highlighting its efficiency and practicality. This research represents a
significant advancement in heuristic algorithms for the MWIS problem, offering
a promising approach to aid AI techniques in optimizing intelligent
transportation systems.

</details>

### [124] [The Promise and Limits of LLMs in Constructing Proofs and Hints for Logic Problems in Intelligent Tutoring Systems](https://arxiv.org/abs/2505.04736)
*Sutapa Dey Tithi,Arun Kumar Ramesh,Clara DiMarco,Xiaoyi Tian,Nazia Alam,Kimia Fazeli,Tiffany Barnes*

Main category: cs.AI

TLDR: 论文研究了大型语言模型（LLMs）在逻辑证明教学中的应用，发现其在生成提示方面表现良好，但需改进以确保准确性和教学适用性。


<details>
  <summary>Details</summary>
Motivation: 智能辅导系统在逻辑证明教学中效果显著，但模板化反馈限制了其个性化能力。LLMs虽能动态生成反馈，但存在幻觉或教学不合理的风险。

Method: 评估了四种先进LLMs在358个命题逻辑问题上的六种提示技术，并分析了LLM生成提示的准确性和教学适用性。

Result: DeepSeek-V3在逐步证明构建中表现最佳（84.4%准确率），生成的提示在一致性和清晰度上获高评价，但在解释提示背景方面表现不佳。

Conclusion: LLMs可增强逻辑辅导系统的提示功能，但需进一步优化以确保准确性和教学合理性。

Abstract: Intelligent tutoring systems have demonstrated effectiveness in teaching
formal propositional logic proofs, but their reliance on template-based
explanations limits their ability to provide personalized student feedback.
While large language models (LLMs) offer promising capabilities for dynamic
feedback generation, they risk producing hallucinations or pedagogically
unsound explanations. We evaluated the stepwise accuracy of LLMs in
constructing multi-step symbolic logic proofs, comparing six prompting
techniques across four state-of-the-art LLMs on 358 propositional logic
problems. Results show that DeepSeek-V3 achieved superior performance with
84.4% accuracy on stepwise proof construction and excelled particularly in
simpler rules. We further used the best-performing LLM to generate explanatory
hints for 1,050 unique student problem-solving states from a logic ITS and
evaluated them on 4 criteria with both an LLM grader and human expert ratings
on a 20% sample. Our analysis finds that LLM-generated hints were 75% accurate
and rated highly by human evaluators on consistency and clarity, but did not
perform as well explaining why the hint was provided or its larger context. Our
results demonstrate that LLMs may be used to augment tutoring systems with
logic tutoring hints, but requires additional modifications to ensure accuracy
and pedagogical appropriateness.

</details>

### [125] [Is there Value in Reinforcement Learning?](https://arxiv.org/abs/2505.04822)
*Lior Fox,Yonatan Loewenstein*

Main category: cs.AI

TLDR: 论文探讨了强化学习中动作价值的核心地位，指出政策梯度方法并非完全“无价值”，并建议重新评估建模假设而非仅关注优化算法。


<details>
  <summary>Details</summary>
Motivation: 解决关于动作价值是否明确表示的争议，并批判政策梯度方法作为替代方案的不足。

Method: 通过分析政策梯度与价值基础方法的依赖关系，提出重新评估强化学习的建模假设。

Result: 政策梯度方法仍需价值表示进行学习，因此单纯转向政策梯度方法无法消除价值在行为模型中的作用。

Conclusion: 应重新评估强化学习的建模假设，并考虑计算复杂性等因素以更全面地评价模型复杂度。

Abstract: Action-values play a central role in popular Reinforcement Learing (RL)
models of behavior. Yet, the idea that action-values are explicitly represented
has been extensively debated. Critics had therefore repeatedly suggested that
policy-gradient (PG) models should be favored over value-based (VB) ones, as a
potential solution for this dilemma. Here we argue that this solution is
unsatisfying. This is because PG methods are not, in fact, "Value-free" --
while they do not rely on an explicit representation of Value for acting
(stimulus-response mapping), they do require it for learning. Hence, switching
to PG models is, per se, insufficient for eliminating Value from models of
behavior. More broadly, the requirement for a representation of Value stems
from the underlying assumptions regarding the optimization objective posed by
the standard RL framework, not from the particular algorithm chosen to solve
it. Previous studies mostly took these standard RL assumptions for granted, as
part of their conceptualization or problem modeling, while debating the
different methods used to optimize it (i.e., PG or VB). We propose that,
instead, the focus of the debate should shift to critically evaluating the
underlying modeling assumptions. Such evaluation is particularly important from
an experimental perspective. Indeed, the very notion of Value must be
reconsidered when standard assumptions (e.g., risk neutrality,
full-observability, Markovian environment, exponential discounting) are
relaxed, as is likely in natural settings. Finally, we use the Value debate as
a case study to argue in favor of a more nuanced, algorithmic rather than
statistical, view of what constitutes "a model" in cognitive sciences. Our
analysis suggests that besides "parametric" statistical complexity, additional
aspects such as computational complexity must also be taken into account when
evaluating model complexity.

</details>

### [126] [Large Language Models are Autonomous Cyber Defenders](https://arxiv.org/abs/2505.04843)
*Sebastián R. Castro,Roberto Campbell,Nancy Lau,Octavio Villalobos,Jiaqi Duan,Alvaro A. Cardenas*

Main category: cs.AI

TLDR: 本文研究了大型语言模型（LLM）在多智能体自主网络防御（ACD）环境中的表现，提出了新的通信协议，并评估了LLM与强化学习（RL）智能体的协作效果。


<details>
  <summary>Details</summary>
Motivation: 传统ACD方法依赖单智能体强化学习，存在训练成本高、解释性差和可迁移性不足的问题，而LLM能提供更通用的解释性解决方案。

Method: 通过将LLM集成到CybORG CAGE 4环境中，提出新的通信协议，评估LLM与RL智能体在多智能体ACD中的交互。

Result: 研究揭示了LLM和RL在多智能体ACD中的优劣势，为未来ACD智能体团队的开发提供了方向。

Conclusion: LLM在多智能体ACD中展现出潜力，但仍需进一步研究以优化其训练和部署。

Abstract: Fast and effective incident response is essential to prevent adversarial
cyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response
through Artificial Intelligence (AI) agents that plan and execute actions. Most
ACD approaches focus on single-agent scenarios and leverage Reinforcement
Learning (RL). However, ACD RL-trained agents depend on costly training, and
their reasoning is not always explainable or transferable. Large Language
Models (LLMs) can address these concerns by providing explainable actions in
general security contexts. Researchers have explored LLM agents for ACD but
have not evaluated them on multi-agent scenarios or interacting with other ACD
agents. In this paper, we show the first study on how LLMs perform in
multi-agent ACD environments by proposing a new integration to the CybORG CAGE
4 environment. We examine how ACD teams of LLM and RL agents can interact by
proposing a novel communication protocol. Our results highlight the strengths
and weaknesses of LLMs and RL and help us identify promising research
directions to create, train, and deploy future teams of ACD agents.

</details>

### [127] [CRAFT: Cultural Russian-Oriented Dataset Adaptation for Focused Text-to-Image Generation](https://arxiv.org/abs/2505.04851)
*Viacheslav Vasilev,Vladimir Arkhipkin,Julia Agafonova,Tatiana Nikulina,Evelina Mironova,Alisa Shichanina,Nikolai Gerasimenko,Mikhail Shoytov,Denis Dimitrov*

Main category: cs.AI

TLDR: 论文探讨了文本到图像生成模型在个体文化知识上的不足，提出了一种基于文化代码（特别是俄罗斯文化）的数据集构建方法，并验证了其对模型生成质量的提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在个体文化知识上存在显著不足，主要因为训练数据以欧美流行文化为主，导致生成结果不准确、质量下降，甚至传播刻板印象和冒犯性内容。

Method: 提出了一种收集和处理基于文化代码（俄罗斯文化）数据的方法，并使用Kandinsky 3.1模型验证其效果。

Result: 人类评估结果表明，该方法提高了模型对俄罗斯文化的理解能力。

Conclusion: 研究强调了文化代码对图像生成模型的重要性，并展示了基于特定文化数据集的构建方法对模型性能的提升。

Abstract: Despite the fact that popular text-to-image generation models cope well with
international and general cultural queries, they have a significant knowledge
gap regarding individual cultures. This is due to the content of existing large
training datasets collected on the Internet, which are predominantly based on
Western European or American popular culture. Meanwhile, the lack of cultural
adaptation of the model can lead to incorrect results, a decrease in the
generation quality, and the spread of stereotypes and offensive content. In an
effort to address this issue, we examine the concept of cultural code and
recognize the critical importance of its understanding by modern image
generation models, an issue that has not been sufficiently addressed in the
research community to date. We propose the methodology for collecting and
processing the data necessary to form a dataset based on the cultural code, in
particular the Russian one. We explore how the collected data affects the
quality of generations in the national domain and analyze the effectiveness of
our approach using the Kandinsky 3.1 text-to-image model. Human evaluation
results demonstrate an increase in the level of awareness of Russian culture in
the model.

</details>

### [128] [Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models](https://arxiv.org/abs/2505.04914)
*John Hawkins*

Main category: cs.AI

TLDR: 论文探讨了基于Transformer-decoder的语言模型在推理能力上的局限性，并提出了一种开源工具enigme来测试和评估这些模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer-decoder模型在自然语言命令理解和推理任务中的局限性，并设计任务来测试其推理边界。

Method: 通过分析模型的潜在变量结构，设计文本谜题库enigme，用于训练和评估模型的推理能力。

Result: 提出enigme作为开源工具，用于生成文本谜题，以测试和评估模型的推理能力。

Conclusion: Transformer-decoder模型在推理能力上存在局限性，enigme工具为未来AI架构的推理能力评估提供了新方法。

Abstract: Transformer-decoder language models are a core innovation in text based
generative artificial intelligence. These models are being deployed as
general-purpose intelligence systems in many applications. Central to their
utility is the capacity to understand natural language commands and exploit the
reasoning embedded in human text corpora to apply some form of reasoning
process to a wide variety of novel tasks. To understand the limitations of this
approach to generating reasoning we argue that we need to consider the
architectural constraints of these systems. Consideration of the latent
variable structure of transformer-decoder models allows us to design reasoning
tasks that should probe the boundary of their capacity to reason. We present
enigme, an open-source library for generating text-based puzzles to be used in
training and evaluating reasoning skills within transformer-decoder models and
future AI architectures.

</details>

### [129] [Belief Filtering for Epistemic Control in Linguistic State Space](https://arxiv.org/abs/2505.04927)
*Sebastian Dumbrava*

Main category: cs.AI

TLDR: 论文探讨了信念过滤作为人工代理认知控制机制的作用，重点关注以语言表达形式调节内部认知状态。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于通过语言基础的认知架构实现代理的认知调控，以提升AI的安全性和对齐性。

Method: 方法基于语义流形框架，将信念状态视为动态、结构化的自然语言片段集合，并通过内容感知操作实现信念过滤。

Result: 结果表明，语言基础的认知架构具有固有的可解释性和模块化，直接支持信念过滤。

Conclusion: 结论指出，通过结构化干预代理的内部语义空间，可以增强AI安全性和对齐性，并为认知治理提供新方向。

Abstract: We examine belief filtering as a mechanism for the epistemic control of
artificial agents, focusing on the regulation of internal cognitive states
represented as linguistic expressions. This mechanism is developed within the
Semantic Manifold framework, where belief states are dynamic, structured
ensembles of natural language fragments. Belief filters act as content-aware
operations on these fragments across various cognitive transitions. This paper
illustrates how the inherent interpretability and modularity of such a
linguistically-grounded cognitive architecture directly enable belief
filtering, offering a principled approach to agent regulation. The study
highlights the potential for enhancing AI safety and alignment through
structured interventions in an agent's internal semantic space and points to
new directions for architecturally embedded cognitive governance.

</details>

### [130] [Position: Epistemic Artificial Intelligence is Essential for Machine Learning Models to Know When They Do Not Know](https://arxiv.org/abs/2505.04950)
*Shireen Kudukkil Manchingal,Fabio Cuzzolin*

Main category: cs.AI

TLDR: 论文主张转向认知人工智能，强调模型需从已知和未知中学习，以提升AI系统在不确定环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前AI在处理不确定性和对抗性数据时表现不佳，尤其是在自动驾驶等领域，传统方法过于依赖数据拟合和领域适应。

Method: 提出认知人工智能范式，强调模型需识别和管理不确定性。

Result: 该方法有望提升AI系统在不可预测环境中的适应性和鲁棒性。

Conclusion: 认知人工智能为解决AI系统的不确定性问题提供了新方向。

Abstract: Despite the impressive achievements of AI, including advancements in
generative models and large language models, there remains a significant gap in
the ability of AI to handle uncertainty and generalize beyond the training
data. We argue that AI models, especially in autonomous systems, fail to make
robust predictions when faced with unfamiliar or adversarial data, as evidenced
by incidents with autonomous vehicles. Traditional machine learning approaches
struggle to address these issues due to an overemphasis on data fitting and
domain adaptation. This position paper posits a paradigm shift towards
epistemic artificial intelligence, emphasizing the need for models to learn not
only from what they know but also from their ignorance. This approach, which
focuses on recognizing and managing uncertainty, offers a potential solution to
improve the resilience and robustness of AI systems, ensuring that they can
better handle unpredictable real-world environments.

</details>

### [131] [Position: The AI Conference Peer Review Crisis Demands Author Feedback and Reviewer Rewards](https://arxiv.org/abs/2505.04966)
*Jaeho Kim,Yunseok Lee,Seulki Lee*

Main category: cs.AI

TLDR: 本文提出将传统单向同行评审系统转变为双向反馈循环，通过作者评估评审质量和评审者获得正式认证，以提升评审质量和可持续性。


<details>
  <summary>Details</summary>
Motivation: AI会议同行评审面临提交量激增、评审质量下降和责任问题，亟需改革。

Method: 提出两种机制：(1) 双向评审系统，作者可评估评审；(2) 评审者奖励系统，激励高质量评审。

Result: 旨在建立责任框架，提升评审质量。

Conclusion: 呼吁社区关注并推动评审系统改革。

Abstract: The peer review process in major artificial intelligence (AI) conferences
faces unprecedented challenges with the surge of paper submissions (exceeding
10,000 submissions per venue), accompanied by growing concerns over review
quality and reviewer responsibility. This position paper argues for the need to
transform the traditional one-way review system into a bi-directional feedback
loop where authors evaluate review quality and reviewers earn formal
accreditation, creating an accountability framework that promotes a
sustainable, high-quality peer review system. The current review system can be
viewed as an interaction between three parties: the authors, reviewers, and
system (i.e., conference), where we posit that all three parties share
responsibility for the current problems. However, issues with authors can only
be addressed through policy enforcement and detection tools, and ethical
concerns can only be corrected through self-reflection. As such, this paper
focuses on reforming reviewer accountability with systematic rewards through
two key mechanisms: (1) a two-stage bi-directional review system that allows
authors to evaluate reviews while minimizing retaliatory behavior, (2)a
systematic reviewer reward system that incentivizes quality reviewing. We ask
for the community's strong interest in these problems and the reforms that are
needed to enhance the peer review process.

</details>

### [132] [Foam-Agent: Towards Automated Intelligent CFD Workflows](https://arxiv.org/abs/2505.04997)
*Ling Yue,Nithin Somasekharan,Yadi Cao,Shaowu Pan*

Main category: cs.AI

TLDR: Foam-Agent是一个多代理框架，通过自然语言输入自动化OpenFOAM CFD模拟工作流，显著降低了CFD的专业门槛。


<details>
  <summary>Details</summary>
Motivation: CFD模拟需要大量专业知识和手动配置，限制了非专业人士的使用。Foam-Agent旨在通过自动化解决这一问题。

Method: 框架包含分层多索引检索系统、依赖感知文件生成系统和迭代错误校正机制。

Result: 在110个模拟任务中，Foam-Agent成功率达到83.6%，显著优于现有框架。

Conclusion: Foam-Agent通过多代理系统降低了CFD的使用门槛，同时保持了建模准确性。

Abstract: Computational Fluid Dynamics (CFD) is an essential simulation tool in various
engineering disciplines, but it often requires substantial domain expertise and
manual configuration, creating barriers to entry. We present Foam-Agent, a
multi-agent framework that automates complex OpenFOAM-based CFD simulation
workflows from natural language inputs. Our innovation includes (1) a
hierarchical multi-index retrieval system with specialized indices for
different simulation aspects, (2) a dependency-aware file generation system
that provides consistency management across configuration files, and (3) an
iterative error correction mechanism that diagnoses and resolves simulation
failures without human intervention. Through comprehensive evaluation on the
dataset of 110 simulation tasks, Foam-Agent achieves an 83.6% success rate with
Claude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for
MetaOpenFOAM and 37.3% for OpenFOAM-GPT). Ablation studies demonstrate the
critical contribution of each system component, with the specialized error
correction mechanism providing a 36.4% performance improvement. Foam-Agent
substantially lowers the CFD expertise threshold while maintaining modeling
accuracy, demonstrating the potential of specialized multi-agent systems to
democratize access to complex scientific simulation tools. The code is public
at https://github.com/csml-rpi/Foam-Agent

</details>

### [133] [A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons](https://arxiv.org/abs/2505.05029)
*Siyue Ren,Wanli Fu,Xinkun Zou,Chen Shen,Yi Cai,Chen Chu,Zhen Wang,Shuyue Hu*

Main category: cs.AI

TLDR: 论文提出RepuNet，一种动态双层声誉框架，用于解决生成多智能体系统中的“公地悲剧”问题，通过声誉系统促进合作。


<details>
  <summary>Details</summary>
Motivation: “公地悲剧”在人类社会中普遍存在，类似问题也出现在生成多智能体系统中，需要一种机制来促进合作。

Method: 提出RepuNet框架，结合直接交互和间接八卦，动态建模智能体声誉和系统网络演化。

Result: RepuNet有效缓解“公地悲剧”，促进合作，并观察到合作集群形成、剥削性智能体被孤立等行为。

Conclusion: 声誉系统在生成多智能体系统中能有效促进合作，并引发丰富的涌现行为。

Abstract: The tragedy of the commons, where individual self-interest leads to
collectively disastrous outcomes, is a pervasive challenge in human society.
Recent studies have demonstrated that similar phenomena can arise in generative
multi-agent systems (MASs). To address this challenge, this paper explores the
use of reputation systems as a remedy. We propose RepuNet, a dynamic,
dual-level reputation framework that models both agent-level reputation
dynamics and system-level network evolution. Specifically, driven by direct
interactions and indirect gossip, agents form reputations for both themselves
and their peers, and decide whether to connect or disconnect other agents for
future interactions. Through two distinct scenarios, we show that RepuNet
effectively mitigates the 'tragedy of the commons', promoting and sustaining
cooperation in generative MASs. Moreover, we find that reputation systems can
give rise to rich emergent behaviors in generative MASs, such as the formation
of cooperative clusters, the social isolation of exploitative agents, and the
preference for sharing positive gossip rather than negative ones.

</details>

### [134] [Enhancing Reinforcement Learning for the Floorplanning of Analog ICs with Beam Search](https://arxiv.org/abs/2505.05059)
*Sandro Junior Della Rovere,Davide Basso,Luca Bortolussi,Mirjana Videnovic-Misic,Husni Habal*

Main category: cs.AI

TLDR: 本文提出了一种结合强化学习（RL）和束搜索（BS）的混合方法，用于解决模拟IC布局中的复杂权衡问题，显著提升了面积、死区和半周长线长等指标。


<details>
  <summary>Details</summary>
Motivation: 模拟IC布局需要处理复杂的权衡和设备物理特性，传统学习方法难以实现完全自动化。RL在解决布局问题中表现突出，但仍有改进空间。

Method: 采用RL与BS结合的混合方法，BS算法增强了推理过程，支持多种目标权重和拥堵处理，无需重新训练策略。

Result: 实验结果显示，相比标准RL方法，面积、死区和线长改善了5-85%，且性能与现有先进技术相当。

Conclusion: 混合方法在保持RL泛化能力的同时，显著提升了布局效果，为自动化布局提供了高效解决方案。

Abstract: The layout of analog ICs requires making complex trade-offs, while addressing
device physics and variability of the circuits. This makes full automation with
learning-based solutions hard to achieve. However, reinforcement learning (RL)
has recently reached significant results, particularly in solving the
floorplanning problem. This paper presents a hybrid method that combines RL
with a beam (BS) strategy. The BS algorithm enhances the agent's inference
process, allowing for the generation of flexible floorplans by accomodating
various objective weightings, and addressing congestion without without the
need for policy retraining or fine-tuning. Moreover, the RL agent's
generalization ability stays intact, along with its efficient handling of
circuit features and constraints. Experimental results show approx. 5-85%
improvement in area, dead space and half-perimeter wire length compared to a
standard RL application, along with higher rewards for the agent. Moreover,
performance and efficiency align closely with those of existing
state-of-the-art techniques.

</details>

### [135] [A Neuro-Symbolic Framework for Sequence Classification with Relational and Temporal Knowledge](https://arxiv.org/abs/2505.05106)
*Luca Salvatore Lorello,Marco Lippi,Stefano Melacci*

Main category: cs.AI

TLDR: 论文探讨了神经符号人工智能在动态知识背景下的序列分类问题，提出了一种新方法并进行了实验评估。


<details>
  <summary>Details</summary>
Motivation: 现有框架多假设知识静态不变，忽略了时间维度，本文旨在解决动态知识驱动的序列分类问题。

Method: 采用多阶段神经符号和纯神经架构，并在新引入的基准框架上进行实验。

Result: 实验结果表明该问题具有挑战性，并揭示了神经符号方法的未探索缺陷。

Conclusion: 本文为未来研究提供了宝贵参考，强调了动态知识背景下神经符号方法的局限性。

Abstract: One of the goals of neuro-symbolic artificial intelligence is to exploit
background knowledge to improve the performance of learning tasks. However,
most of the existing frameworks focus on the simplified scenario where
knowledge does not change over time and does not cover the temporal dimension.
In this work we consider the much more challenging problem of knowledge-driven
sequence classification where different portions of knowledge must be employed
at different timesteps, and temporal relations are available. Our experimental
evaluation compares multi-stage neuro-symbolic and neural-only architectures,
and it is conducted on a newly-introduced benchmarking framework. Results
demonstrate the challenging nature of this novel setting, and also highlight
under-explored shortcomings of neuro-symbolic methods, representing a precious
reference for future research.

</details>

### [136] [Multi-agent Embodied AI: Advances and Future Directions](https://arxiv.org/abs/2505.05108)
*Zhaohan Feng,Ruiqi Xue,Lei Yuan,Yang Yu,Ning Ding,Meiqin Liu,Bingzhao Gao,Jian Sun,Gang Wang*

Main category: cs.AI

TLDR: 本文综述了多智能体具身AI的研究现状，分析了关键贡献，并指出了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的具身AI需要处理复杂动态环境，而现有研究多集中于单智能体静态环境，缺乏对多智能体协作的系统性研究。

Method: 通过文献综述，分析多智能体具身AI的关键技术与挑战。

Result: 总结了当前研究的局限性，如简化模型无法应对复杂动态环境，并提出了未来研究方向。

Conclusion: 多智能体具身AI是未来发展的关键方向，需进一步研究协作机制与动态环境适应性。

Abstract: Embodied artificial intelligence (Embodied AI) plays a pivotal role in the
application of advanced technologies in the intelligent era, where AI systems
are integrated with physical bodies that enable them to perceive, reason, and
interact with their environments. Through the use of sensors for input and
actuators for action, these systems can learn and adapt based on real-world
feedback, allowing them to perform tasks effectively in dynamic and
unpredictable environments. As techniques such as deep learning (DL),
reinforcement learning (RL), and large language models (LLMs) mature, embodied
AI has become a leading field in both academia and industry, with applications
spanning robotics, healthcare, transportation, and manufacturing. However, most
research has focused on single-agent systems that often assume static, closed
environments, whereas real-world embodied AI must navigate far more complex
scenarios. In such settings, agents must not only interact with their
surroundings but also collaborate with other agents, necessitating
sophisticated mechanisms for adaptation, real-time learning, and collaborative
problem-solving. Despite increasing interest in multi-agent systems, existing
research remains narrow in scope, often relying on simplified models that fail
to capture the full complexity of dynamic, open environments for multi-agent
embodied AI. Moreover, no comprehensive survey has systematically reviewed the
advancements in this area. As embodied AI rapidly evolves, it is crucial to
deepen our understanding of multi-agent embodied AI to address the challenges
presented by real-world applications. To fill this gap and foster further
development in the field, this paper reviews the current state of research,
analyzes key contributions, and identifies challenges and future directions,
providing insights to guide innovation and progress in this field.

</details>

### [137] [Is there a half-life for the success rates of AI agents?](https://arxiv.org/abs/2505.05115)
*Toby Ord*

Main category: cs.AI

TLDR: AI代理在长时间任务中的表现可以用简单的数学模型解释，即每分钟失败率恒定，导致成功率随任务时长指数下降。


<details>
  <summary>Details</summary>
Motivation: 探究AI代理在长时间任务中表现下降的原因及其普遍性。

Method: 基于Kwa等人（2025）的实证研究，提出恒定失败率模型，并验证其拟合度。

Result: 模型能准确预测不同时长任务的AI成功率，暗示失败源于子任务链的累积效应。

Conclusion: 该模型适用于当前任务集，但需进一步验证其普适性。

Abstract: Building on the recent empirical work of Kwa et al. (2025), I show that
within their suite of research-engineering tasks the performance of AI agents
on longer-duration tasks can be explained by an extremely simple mathematical
model -- a constant rate of failing during each minute a human would take to do
the task. This implies an exponentially declining success rate with the length
of the task and that each agent could be characterised by its own half-life.
This empirical regularity allows us to estimate the success rate for an agent
at different task lengths. And the fact that this model is a good fit for the
data is suggestive of the underlying causes of failure on longer tasks -- that
they involve increasingly large sets of subtasks where failing any one fails
the task. Whether this model applies more generally on other suites of tasks is
unknown and an important subject for further work.

</details>

### [138] [MARK: Memory Augmented Refinement of Knowledge](https://arxiv.org/abs/2505.05177)
*Anish Ganguli,Prabal Deb,Debleena Banerjee*

Main category: cs.AI

TLDR: MARK框架通过结构化记忆增强LLMs，使其无需重新训练即可持续学习，提升领域适应性和个性化响应。


<details>
  <summary>Details</summary>
Motivation: LLMs在动态领域知识中难以对齐，且专家知识与系统知识存在差距，影响信息检索和应用。

Method: MARK框架利用三种专用代理（残余记忆、用户问题记忆、LLM响应记忆）存储和分析领域知识，优化响应。

Result: MARK减少了幻觉，支持领域特定适应，并提升个性化AI助手的能力。

Conclusion: MARK为LLMs提供了一种无需重新训练的持续学习方法，显著提升了其在实际应用中的表现。

Abstract: Large Language Models (LLMs) assist in specialized tasks but struggle to
align with evolving domain knowledge without costly fine-tuning. Domain
knowledge consists of: Knowledge: Immutable facts (e.g., 'A stone is solid')
and generally accepted principles (e.g., ethical standards); Refined Memory:
Evolving insights shaped by business needs and real-world changes. However, a
significant gap often exists between a domain expert's deep, nuanced
understanding and the system's domain knowledge, which can hinder accurate
information retrieval and application. Our Memory-Augmented Refinement of
Knowledge (MARK) framework enables LLMs to continuously learn without
retraining by leveraging structured refined memory, inspired by the Society of
Mind. MARK operates through specialized agents, each serving a distinct role:
Residual Refined Memory Agent: Stores and retrieves domain-specific insights to
maintain context over time; User Question Refined Memory Agent: Captures
user-provided facts, abbreviations, and terminology for better comprehension;
LLM Response Refined Memory Agent: Extracts key elements from responses for
refinement and personalization. These agents analyse stored refined memory,
detect patterns, resolve contradictions, and improve response accuracy.
Temporal factors like recency and frequency prioritize relevant information
while discarding outdated insights. MARK enhances LLMs in multiple ways: Ground
Truth Strategy: Reduces hallucinations by establishing a structured reference;
Domain-Specific Adaptation: Essential for fields like healthcare, law, and
manufacturing, where proprietary insights are absent from public datasets;
Personalized AI Assistants: Improves virtual assistants by remembering user
preferences, ensuring coherent responses over time.

</details>

### [139] [Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt](https://arxiv.org/abs/2505.05197)
*Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Sébastien Krier,Manfred Diaz,Simon Osindero*

Main category: cs.AI

TLDR: 论文提出了一种名为“appropriateness framework”的替代方法，以应对AI伦理多样性问题，强调冲突管理而非道德统一。


<details>
  <summary>Details</summary>
Motivation: 当前AI伦理解决方案多为“一刀切”模式，忽视了道德多样性，可能导致信任危机和制度不稳定。

Method: 基于冲突理论、文化演化、多智能体系统和制度经济学，提出四项设计原则：上下文基础、社区定制、持续适应和多中心治理。

Result: 该框架将伦理对齐的隐喻从道德统一转向冲突管理，更具实用性和紧迫性。

Conclusion: 采用appropriateness framework是解决AI伦理多样性问题的可行且紧迫的方案。

Abstract: Artificial Intelligence (AI) systems are increasingly placed in positions
where their decisions have real consequences, e.g., moderating online spaces,
conducting research, and advising on policy. Ensuring they operate in a safe
and ethically acceptable fashion is thus critical. However, most solutions have
been a form of one-size-fits-all "alignment". We are worried that such systems,
which overlook enduring moral diversity, will spark resistance, erode trust,
and destabilize our institutions. This paper traces the underlying problem to
an often-unstated Axiom of Rational Convergence: the idea that under ideal
conditions, rational agents will converge in the limit of conversation on a
single ethics. Treating that premise as both optional and doubtful, we propose
what we call the appropriateness framework: an alternative approach grounded in
conflict theory, cultural evolution, multi-agent systems, and institutional
economics. The appropriateness framework treats persistent disagreement as the
normal case and designs for it by applying four principles: (1) contextual
grounding, (2) community customization, (3) continual adaptation, and (4)
polycentric governance. We argue here that adopting these design principles is
a good way to shift the main alignment metaphor from moral unification to a
more productive metaphor of conflict management, and that taking this step is
both desirable and urgent.

</details>

### [140] [ChemRxivQuest: A Curated Chemistry Question-Answer Database Extracted from ChemRxiv Preprints](https://arxiv.org/abs/2505.05232)
*Mahmoud Amiri,Thomas Bocklitz*

Main category: cs.AI

TLDR: ChemRxivQuest是一个化学领域的QA数据集，包含970对高质量问题-答案，覆盖17个化学子领域，支持化学NLP研究与应用。


<details>
  <summary>Details</summary>
Motivation: 解决化学文献快速增长带来的知识获取效率问题，推动化学NLP的发展。

Method: 通过OCR、GPT-4o生成QA对及模糊匹配验证答案的自动化流程构建数据集。

Result: 数据集强调概念、机理、应用和实验问题，适用于检索式QA系统、搜索引擎开发和LLM微调。

Conclusion: ChemRxivQuest为化学NLP研究、教育和工具开发提供了基础资源，未来将扩展并引入专家验证。

Abstract: The rapid expansion of chemistry literature poses significant challenges for
researchers seeking to efficiently access domain-specific knowledge. To support
advancements in chemistry-focused natural language processing (NLP), we present
ChemRxivQuest, a curated dataset of 970 high-quality question-answer (QA) pairs
derived from 155 ChemRxiv preprints across 17 subfields of chemistry. Each QA
pair is explicitly linked to its source text segment to ensure traceability and
contextual accuracy. ChemRxivQuest was constructed using an automated pipeline
that combines optical character recognition (OCR), GPT-4o-based QA generation,
and a fuzzy matching technique for answer verification. The dataset emphasizes
conceptual, mechanistic, applied, and experimental questions, enabling
applications in retrieval-based QA systems, search engine development, and
fine-tuning of domain-adapted large language models. We analyze the dataset's
structure, coverage, and limitations, and outline future directions for
expansion and expert validation. ChemRxivQuest provides a foundational resource
for chemistry NLP research, education, and tool development.

</details>

### [141] [Advancing Neural Network Verification through Hierarchical Safety Abstract Interpretation](https://arxiv.org/abs/2505.05235)
*Luca Marzari,Isabella Mastroeni,Alessandro Farinelli*

Main category: cs.AI

TLDR: 论文提出了一种名为Abstract DNN-Verification的新方法，通过层次化分析不安全输出，提供更细粒度的DNN安全性评估，比传统二元验证方法更高效。


<details>
  <summary>Details</summary>
Motivation: 传统DNN形式化验证方法仅能提供二元（安全/不安全）结果，无法捕捉模型安全性的细微差异，导致要求过于严格或宽松。

Method: 利用抽象解释和输出可达集分析，验证多层次安全性，同时保持计算效率。

Result: 方法能够按抽象安全级别对对抗输入进行排序，提供更详细的模型安全性评估，并在复杂任务和标准基准上验证了有效性。

Conclusion: Abstract DNN-Verification为DNN安全性验证提供了更灵活和高效的方法，优于传统二元验证。

Abstract: Traditional methods for formal verification (FV) of deep neural networks
(DNNs) are constrained by a binary encoding of safety properties, where a model
is classified as either safe or unsafe (robust or not robust). This binary
encoding fails to capture the nuanced safety levels within a model, often
resulting in either overly restrictive or too permissive requirements. In this
paper, we introduce a novel problem formulation called Abstract
DNN-Verification, which verifies a hierarchical structure of unsafe outputs,
providing a more granular analysis of the safety aspect for a given DNN.
Crucially, by leveraging abstract interpretation and reasoning about output
reachable sets, our approach enables assessing multiple safety levels during
the FV process, requiring the same (in the worst case) or even potentially less
computational effort than the traditional binary verification approach.
Specifically, we demonstrate how this formulation allows rank adversarial
inputs according to their abstract safety level violation, offering a more
detailed evaluation of the model's safety and robustness. Our contributions
include a theoretical exploration of the relationship between our novel
abstract safety formulation and existing approaches that employ abstract
interpretation for robustness verification, complexity analysis of the novel
problem introduced, and an empirical evaluation considering both a complex deep
reinforcement learning task (based on Habitat 3.0) and standard
DNN-Verification benchmarks.

</details>

### [142] [A Pain Assessment Framework based on multimodal data and Deep Machine Learning methods](https://arxiv.org/abs/2505.05396)
*Stefanos Gkikas*

Main category: cs.AI

TLDR: 该论文旨在从临床理论角度研究疼痛评估过程，并开发高性能、适用于临床环境的自动疼痛评估方法。


<details>
  <summary>Details</summary>
Motivation: 探索现有自动疼痛评估方法，并从计算角度研究影响疼痛感知的关键因素（如人口统计学因素）。

Method: 设计并开发适用于单模态和多模态配置的自动疼痛评估流程。

Result: 提出的方法取得了最先进的结果，并为人工智能、基础模型和生成式人工智能的新方法探索铺平了道路。

Conclusion: 该研究为自动疼痛评估提供了创新且高效的解决方案，并推动了相关领域的技术发展。

Abstract: From the original abstract:
  This thesis initially aims to study the pain assessment process from a
clinical-theoretical perspective while exploring and examining existing
automatic approaches. Building on this foundation, the primary objective of
this Ph.D. project is to develop innovative computational methods for automatic
pain assessment that achieve high performance and are applicable in real
clinical settings. A primary goal is to thoroughly investigate and assess
significant factors, including demographic elements that impact pain
perception, as recognized in pain research, through a computational standpoint.
Within the limits of the available data in this research area, our goal was to
design, develop, propose, and offer automatic pain assessment pipelines for
unimodal and multimodal configurations that are applicable to the specific
requirements of different scenarios. The studies published in this Ph.D. thesis
showcased the effectiveness of the proposed methods, achieving state-of-the-art
results. Additionally, they paved the way for exploring new approaches in
artificial intelligence, foundation models, and generative artificial
intelligence.

</details>

### [143] [EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation](https://arxiv.org/abs/2505.05440)
*Biao Yi,Xavier Hu,Yurun Chen,Shengyu Zhang,Hongxia Yang,Fan Wu,Fei Wu*

Main category: cs.AI

TLDR: EcoAgent是一个边缘-云协作的多智能体框架，用于移动自动化，通过减少MLLM令牌消耗提高效率。


<details>
  <summary>Details</summary>
Motivation: 解决基于云的移动代理高延迟和高成本问题，同时避免边缘部署的模型失去通用能力。

Method: 采用边缘-云协作框架，包括云端的规划智能体和边缘的执行与观察智能体，通过预理解模块压缩图像文本。

Result: 在AndroidWorld实验中，EcoAgent保持高任务成功率，同时显著减少MLLM令牌消耗。

Conclusion: EcoAgent实现了高效且实用的移动自动化。

Abstract: Cloud-based mobile agents powered by (multimodal) large language models
((M)LLMs) offer strong reasoning abilities but suffer from high latency and
cost. While fine-tuned (M)SLMs enable edge deployment, they often lose general
capabilities and struggle with complex tasks. To address this, we propose
EcoAgent, an Edge-Cloud cOllaborative multi-agent framework for mobile
automation. EcoAgent features a closed-loop collaboration among a cloud-based
Planning Agent and two edge-based agents: the Execution Agent for action
execution and the Observation Agent for verifying outcomes. The Observation
Agent uses a Pre-Understanding Module to compress screen images into concise
text, reducing token usage. In case of failure, the Planning Agent retrieves
screen history and replans via a Reflection Module. Experiments on AndroidWorld
show that EcoAgent maintains high task success rates while significantly
reducing MLLM token consumption, enabling efficient and practical mobile
automation.

</details>

### [144] [Conversational Process Model Redesign](https://arxiv.org/abs/2505.05453)
*Nataliia Klievtsova,Timotheus Kampik,Juergen Mangler,Stefanie Rinderle-Ma*

Main category: cs.AI

TLDR: 论文探讨了利用大型语言模型（LLM）支持业务流程管理的可行性，提出了一种多步骤的对话式流程模型重设计（CPD）方法，并通过评估验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前研究多关注单次提示执行，而忽略了用户与LLM的持续交互。本文旨在探索LLM在迭代式流程模型设计与重设计中的应用。

Method: 提出CPD方法，通过LLM识别流程变更模式、重述变更请求并应用变更，实现可解释和可复现的修改。

Result: 评估表明LLM能较好处理多数变更，但某些模式对LLM和用户较难理解，用户需支持以清晰描述变更。

Conclusion: LLM在业务流程管理中具有潜力，但需进一步优化以支持复杂变更模式。

Abstract: With the recent success of large language models (LLMs), the idea of
AI-augmented Business Process Management systems is becoming more feasible. One
of their essential characteristics is the ability to be conversationally
actionable, allowing humans to interact with the LLM effectively to perform
crucial process life cycle tasks such as process model design and redesign.
However, most current research focuses on single-prompt execution and
evaluation of results, rather than on continuous interaction between the user
and the LLM. In this work, we aim to explore the feasibility of using LLMs to
empower domain experts in the creation and redesign of process models in an
iterative and effective way. The proposed conversational process model redesign
(CPD) approach receives as input a process model and a redesign request by the
user in natural language. Instead of just letting the LLM make changes, the LLM
is employed to (a) identify process change patterns from literature, (b)
re-phrase the change request to be aligned with an expected wording for the
identified pattern (i.e., the meaning), and then to (c) apply the meaning of
the change to the process model. This multi-step approach allows for
explainable and reproducible changes. In order to ensure the feasibility of the
CPD approach, and to find out how well the patterns from literature can be
handled by the LLM, we performed an extensive evaluation. The results show that
some patterns are hard to understand by LLMs and by users. Within the scope of
the study, we demonstrated that users need support to describe the changes
clearly. Overall the evaluation shows that the LLMs can handle most changes
well according to a set of completeness and correctness criteria.

</details>

<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [145] [Histo-Miner: Deep Learning based Tissue Features Extraction Pipeline from H&E Whole Slide Images of Cutaneous Squamous Cell Carcinoma](https://arxiv.org/abs/2505.04672)
*Lucas Sancéré,Carina Lorenz,Doris Helbig,Oana-Diana Persa,Sonja Dengler,Alexander Kreuter,Martim Laimer,Anne Fröhlich,Jennifer Landsberg,Johannes Brägelmann,Katarzyna Bozek*

Main category: cs.CV

TLDR: Histo-Miner是一个基于深度学习的皮肤组织全切片图像分析工具，生成两个标注数据集并用于预测皮肤鳞状细胞癌患者对免疫疗法的反应。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对皮肤组织的标注数据集和开源分析工具，特别是在皮肤鳞状细胞癌（cSCC）领域。

Method: 利用卷积神经网络和视觉变换器，对47,392个标注细胞核和144张肿瘤分割图像进行分析，生成特征向量。

Result: 模型性能优异：细胞核分割mPQ为0.569，分类F1为0.832，肿瘤分割mIoU为0.884。特征向量成功预测患者对免疫疗法的反应。

Conclusion: Histo-Miner在临床场景中具有直接应用价值，为生物学机制提供解释。

Abstract: Recent advancements in digital pathology have enabled comprehensive analysis
of Whole-Slide Images (WSI) from tissue samples, leveraging high-resolution
microscopy and computational capabilities. Despite this progress, there is a
lack of labeled datasets and open source pipelines specifically tailored for
analysis of skin tissue. Here we propose Histo-Miner, a deep learning-based
pipeline for analysis of skin WSIs and generate two datasets with labeled
nuclei and tumor regions. We develop our pipeline for the analysis of patient
samples of cutaneous squamous cell carcinoma (cSCC), a frequent non-melanoma
skin cancer. Utilizing the two datasets, comprising 47,392 annotated cell
nuclei and 144 tumor-segmented WSIs respectively, both from cSCC patients,
Histo-Miner employs convolutional neural networks and vision transformers for
nucleus segmentation and classification as well as tumor region segmentation.
Performance of trained models positively compares to state of the art with
multi-class Panoptic Quality (mPQ) of 0.569 for nucleus segmentation,
macro-averaged F1 of 0.832 for nucleus classification and mean Intersection
over Union (mIoU) of 0.884 for tumor region segmentation. From these
predictions we generate a compact feature vector summarizing tissue morphology
and cellular interactions, which can be used for various downstream tasks.
Here, we use Histo-Miner to predict cSCC patient response to immunotherapy
based on pre-treatment WSIs from 45 patients. Histo-Miner identifies
percentages of lymphocytes, the granulocyte to lymphocyte ratio in tumor
vicinity and the distances between granulocytes and plasma cells in tumors as
predictive features for therapy response. This highlights the applicability of
Histo-Miner to clinically relevant scenarios, providing direct interpretation
of the classification and insights into the underlying biology.

</details>

### [146] [Comparison of Visual Trackers for Biomechanical Analysis of Running](https://arxiv.org/abs/2505.04713)
*Luis F. Gomez,Gonzalo Garrido-Lopez,Julian Fierrez,Aythami Morales,Ruben Tolosana,Javier Rueda,Enrique Navarro*

Main category: cs.CV

TLDR: 论文分析了六种姿态跟踪器在短跑生物力学中的表现，提出了一种后处理模块以减少误差，结果表明基于关节的模型在生物力学分析中具有潜力。


<details>
  <summary>Details</summary>
Motivation: 研究人类姿态估计在短跑生物力学分析中的应用，评估不同跟踪器的性能，并探索提高准确性的方法。

Method: 比较六种跟踪器（两种点跟踪器和四种关节跟踪器）的性能，提出后处理模块进行异常检测和融合预测，实验基于40次短跑和5870帧数据。

Result: 基于关节的模型误差范围为11.41°至4.37°，后处理模块可进一步降低至6.99°和3.88°。

Conclusion: 人类姿态跟踪在短跑生物力学分析中具有价值，但高精度应用仍需改进。

Abstract: Human pose estimation has witnessed significant advancements in recent years,
mainly due to the integration of deep learning models, the availability of a
vast amount of data, and large computational resources. These developments have
led to highly accurate body tracking systems, which have direct applications in
sports analysis and performance evaluation.
  This work analyzes the performance of six trackers: two point trackers and
four joint trackers for biomechanical analysis in sprints. The proposed
framework compares the results obtained from these pose trackers with the
manual annotations of biomechanical experts for more than 5870 frames. The
experimental framework employs forty sprints from five professional runners,
focusing on three key angles in sprint biomechanics: trunk inclination, hip
flex extension, and knee flex extension. We propose a post-processing module
for outlier detection and fusion prediction in the joint angles.
  The experimental results demonstrate that using joint-based models yields
root mean squared errors ranging from 11.41{\deg} to 4.37{\deg}. When
integrated with the post-processing modules, these errors can be reduced to
6.99{\deg} and 3.88{\deg}, respectively. The experimental findings suggest that
human pose tracking approaches can be valuable resources for the biomechanical
analysis of running. However, there is still room for improvement in
applications where high accuracy is required.

</details>

### [147] [Lay-Your-Scene: Natural Scene Layout Generation with Diffusion Transformers](https://arxiv.org/abs/2505.04718)
*Divyansh Srivastava,Xiang Zhang,He Wen,Chenru Wen,Zhuowen Tu*

Main category: cs.CV

TLDR: LayouSyn是一个新颖的文本到布局生成管道，用于自然场景，通过轻量级开源语言模型和新型扩散Transformer架构实现开放词汇生成。


<details>
  <summary>Details</summary>
Motivation: 现有场景布局生成方法要么词汇封闭，要么依赖专有大语言模型，限制了可控图像生成的建模能力和广泛适用性。

Method: 使用轻量级开源语言模型从文本提示中提取场景元素，并结合新型扩散Transformer架构进行条件布局生成。

Result: LayouSyn在空间和数值推理基准测试中表现优于现有方法，达到最先进水平。

Conclusion: LayouSyn不仅提升了布局生成性能，还展示了在图像编辑中的潜在应用价值。

Abstract: We present Lay-Your-Scene (shorthand LayouSyn), a novel text-to-layout
generation pipeline for natural scenes. Prior scene layout generation methods
are either closed-vocabulary or use proprietary large language models for
open-vocabulary generation, limiting their modeling capabilities and broader
applicability in controllable image generation. In this work, we propose to use
lightweight open-source language models to obtain scene elements from text
prompts and a novel aspect-aware diffusion Transformer architecture trained in
an open-vocabulary manner for conditional layout generation. Extensive
experiments demonstrate that LayouSyn outperforms existing methods and achieves
state-of-the-art performance on challenging spatial and numerical reasoning
benchmarks. Additionally, we present two applications of LayouSyn. First, we
show that coarse initialization from large language models can be seamlessly
combined with our method to achieve better results. Second, we present a
pipeline for adding objects to images, demonstrating the potential of LayouSyn
in image editing applications.

</details>

### [148] [False Promises in Medical Imaging AI? Assessing Validity of Outperformance Claims](https://arxiv.org/abs/2505.04720)
*Evangelia Christodoulou,Annika Reinke,Pascaline Andrè,Patrick Godau,Piotr Kalinowski,Rola Houhou,Selen Erkan,Carole H. Sudre,Ninon Burgos,Sofiène Boutaj,Sophie Loizillon,Maëlys Solal,Veronika Cheplygina,Charles Heitz,Michal Kozubek,Michela Antonelli,Nicola Rieke,Antoine Gilson,Leon D. Mayer,Minu D. Tizabi,M. Jorge Cardoso,Amber Simpson,Annette Kopp-Schneider,Gaël Varoquaux,Olivier Colliot,Lena Maier-Hein*

Main category: cs.CV

TLDR: 研究发现，医学影像AI研究中，大多数论文声称新方法优于现有技术，但分析表明这些声称可能缺乏统计支持，存在虚假声称的高概率。


<details>
  <summary>Details</summary>
Motivation: 探讨新提出的方法是否真正优于现有技术，揭示当前基准测试实践中的缺陷。

Method: 采用贝叶斯方法分析医学影像论文，量化虚假声称的概率。

Result: 超过80%的论文声称新方法优于现有技术，86%的分类论文和53%的分割论文存在虚假声称的高概率。

Conclusion: 当前医学影像AI的基准测试实践中，声称的优越性往往缺乏依据，可能误导未来研究方向。

Abstract: Performance comparisons are fundamental in medical imaging Artificial
Intelligence (AI) research, often driving claims of superiority based on
relative improvements in common performance metrics. However, such claims
frequently rely solely on empirical mean performance. In this paper, we
investigate whether newly proposed methods genuinely outperform the state of
the art by analyzing a representative cohort of medical imaging papers. We
quantify the probability of false claims based on a Bayesian approach that
leverages reported results alongside empirically estimated model congruence to
estimate whether the relative ranking of methods is likely to have occurred by
chance. According to our results, the majority (>80%) of papers claims
outperformance when introducing a new method. Our analysis further revealed a
high probability (>5%) of false outperformance claims in 86% of classification
papers and 53% of segmentation papers. These findings highlight a critical flaw
in current benchmarking practices: claims of outperformance in medical imaging
AI are frequently unsubstantiated, posing a risk of misdirecting future
research efforts.

</details>

### [149] [Hyb-KAN ViT: Hybrid Kolmogorov-Arnold Networks Augmented Vision Transformer](https://arxiv.org/abs/2505.04740)
*Sainath Dey,Mitul Goswami,Jashika Sethi,Prasant Kumar Pattnaik*

Main category: cs.CV

TLDR: Hyb-KAN ViT结合小波谱分解和样条优化激活函数，改进ViT中的MLP限制，提出Eff-KAN和Wav-KAN模块，提升多尺度特征提取能力，在多个任务中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决ViT中MLP的固有局限性，同时利用小波函数的边缘检测能力和样条函数的高效性。

Method: 提出Eff-KAN（用样条函数替代MLP）和Wav-KAN（利用小波变换进行多分辨率特征提取），并集成到ViT编码器和分类头中。

Result: 在ImageNet-1K、COCO和ADE20K等任务中表现优异，验证了小波谱先验和样条效率的有效性。

Conclusion: Hyb-KAN ViT为视觉架构中参数效率和多尺度表示的平衡提供了新范式。

Abstract: This study addresses the inherent limitations of Multi-Layer Perceptrons
(MLPs) in Vision Transformers (ViTs) by introducing Hybrid Kolmogorov-Arnold
Network (KAN)-ViT (Hyb-KAN ViT), a novel framework that integrates
wavelet-based spectral decomposition and spline-optimized activation functions,
prior work has failed to focus on the prebuilt modularity of the ViT
architecture and integration of edge detection capabilities of Wavelet
functions. We propose two key modules: Efficient-KAN (Eff-KAN), which replaces
MLP layers with spline functions and Wavelet-KAN (Wav-KAN), leveraging
orthogonal wavelet transforms for multi-resolution feature extraction. These
modules are systematically integrated in ViT encoder layers and classification
heads to enhance spatial-frequency modeling while mitigating computational
bottlenecks. Experiments on ImageNet-1K (Image Recognition), COCO (Object
Detection and Instance Segmentation), and ADE20K (Semantic Segmentation)
demonstrate state-of-the-art performance with Hyb-KAN ViT. Ablation studies
validate the efficacy of wavelet-driven spectral priors in segmentation and
spline-based efficiency in detection tasks. The framework establishes a new
paradigm for balancing parameter efficiency and multi-scale representation in
vision architectures.

</details>

### [150] [Lightweight RGB-D Salient Object Detection from a Speed-Accuracy Tradeoff Perspective](https://arxiv.org/abs/2505.04758)
*Songsong Duan,Xi Yang,Nannan Wang,Xinbo Gao*

Main category: cs.CV

TLDR: 提出SATNet网络，通过深度质量、模态融合和特征表示三方面平衡RGB-D SOD任务中的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D方法在精度和效率间难以平衡，轻量级方法难以实现高精度。

Method: 引入Depth Anything Model提升深度图质量；提出DAM模块解耦多模态特征；开发DIRM模块扩展特征空间；设计DFAM模块聚合特征。

Result: 在五个公开数据集上优于SOTA CNN模型，参数仅5.2M，速度415 FPS。

Conclusion: SATNet在轻量级框架中实现了高效与高精度的平衡。

Abstract: Current RGB-D methods usually leverage large-scale backbones to improve
accuracy but sacrifice efficiency. Meanwhile, several existing lightweight
methods are difficult to achieve high-precision performance. To balance the
efficiency and performance, we propose a Speed-Accuracy Tradeoff Network
(SATNet) for Lightweight RGB-D SOD from three fundamental perspectives: depth
quality, modality fusion, and feature representation. Concerning depth quality,
we introduce the Depth Anything Model to generate high-quality depth maps,which
effectively alleviates the multi-modal gaps in the current datasets. For
modality fusion, we propose a Decoupled Attention Module (DAM) to explore the
consistency within and between modalities. Here, the multi-modal features are
decoupled into dual-view feature vectors to project discriminable information
of feature maps. For feature representation, we develop a Dual Information
Representation Module (DIRM) with a bi-directional inverted framework to
enlarge the limited feature space generated by the lightweight backbones. DIRM
models texture features and saliency features to enrich feature space, and
employ two-way prediction heads to optimal its parameters through a
bi-directional backpropagation. Finally, we design a Dual Feature Aggregation
Module (DFAM) in the decoder to aggregate texture and saliency features.
Extensive experiments on five public RGB-D SOD datasets indicate that the
proposed SATNet excels state-of-the-art (SOTA) CNN-based heavyweight models and
achieves a lightweight framework with 5.2 M parameters and 415 FPS.

</details>

### [151] [Vision-Language-Action Models: Concepts, Progress, Applications and Challenges](https://arxiv.org/abs/2505.04769)
*Ranjan Sapkota,Yang Cao,Konstantinos I. Roumeliotis,Manoj Karkee*

Main category: cs.CV

TLDR: 该论文综述了视觉-语言-动作（VLA）模型的最新进展，涵盖其概念基础、架构创新、应用领域及未来挑战与解决方案。


<details>
  <summary>Details</summary>
Motivation: 旨在统一感知、自然语言理解和动作执行，推动人工智能在机器人和其他领域的应用。

Method: 采用严格的文献综述框架，分析了过去三年发表的80多个VLA模型。

Result: 总结了VLA模型在架构、训练策略和实时推理方面的关键进展，并探讨了多领域应用。

Conclusion: 提出了未来研究方向，包括智能体AI适应和跨具身泛化，为通用人工智能的发展奠定基础。

Abstract: Vision-Language-Action (VLA) models mark a transformative advancement in
artificial intelligence, aiming to unify perception, natural language
understanding, and embodied action within a single computational framework.
This foundational review presents a comprehensive synthesis of recent
advancements in Vision-Language-Action models, systematically organized across
five thematic pillars that structure the landscape of this rapidly evolving
field. We begin by establishing the conceptual foundations of VLA systems,
tracing their evolution from cross-modal learning architectures to generalist
agents that tightly integrate vision-language models (VLMs), action planners,
and hierarchical controllers. Our methodology adopts a rigorous literature
review framework, covering over 80 VLA models published in the past three
years. Key progress areas include architectural innovations,
parameter-efficient training strategies, and real-time inference accelerations.
We explore diverse application domains such as humanoid robotics, autonomous
vehicles, medical and industrial robotics, precision agriculture, and augmented
reality navigation. The review further addresses major challenges across
real-time control, multimodal action representation, system scalability,
generalization to unseen tasks, and ethical deployment risks. Drawing from the
state-of-the-art, we propose targeted solutions including agentic AI
adaptation, cross-embodiment generalization, and unified neuro-symbolic
planning. In our forward-looking discussion, we outline a future roadmap where
VLA models, VLMs, and agentic AI converge to power socially aligned, adaptive,
and general-purpose embodied agents. This work serves as a foundational
reference for advancing intelligent, real-world robotics and artificial general
intelligence. >Vision-language-action, Agentic AI, AI Agents, Vision-language
Models

</details>

### [152] [Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay](https://arxiv.org/abs/2505.04787)
*Sriram Mandalika,Harsha Vardhan,Athira Nambiar*

Main category: cs.CV

TLDR: 提出了一种基于生成重放的持续学习框架R2R，通过不确定性驱动机制和生成重放模块，有效缓解灾难性遗忘，无需预训练模型。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在持续学习中的灾难性遗忘问题，利用未标记数据和生成重放技术提升知识保留能力。

Method: 采用聚类级不确定性反馈机制和动态阈值调整，结合VLM生成重放模块，生成代表性合成数据。

Result: 在多个数据集上取得显著性能提升，最高达98.13%，超越现有方法4.36%。

Conclusion: R2R框架在持续学习中表现出色，为未来研究提供了新的方向。

Abstract: Continual Learning entails progressively acquiring knowledge from new data
while retaining previously acquired knowledge, thereby mitigating
``Catastrophic Forgetting'' in neural networks. Our work presents a novel
uncertainty-driven Unsupervised Continual Learning framework using Generative
Replay, namely ``Replay to Remember (R2R)''. The proposed R2R architecture
efficiently uses unlabelled and synthetic labelled data in a balanced
proportion using a cluster-level uncertainty-driven feedback mechanism and a
VLM-powered generative replay module. Unlike traditional memory-buffer methods
that depend on pretrained models and pseudo-labels, our R2R framework operates
without any prior training. It leverages visual features from unlabeled data
and adapts continuously using clustering-based uncertainty estimation coupled
with dynamic thresholding. Concurrently, a generative replay mechanism along
with DeepSeek-R1 powered CLIP VLM produces labelled synthetic data
representative of past experiences, resembling biological visual thinking that
replays memory to remember and act in new, unseen tasks. Extensive experimental
analyses are carried out in CIFAR-10, CIFAR-100, CINIC-10, SVHN and
TinyImageNet datasets. Our proposed R2R approach improves knowledge retention,
achieving a state-of-the-art performance of 98.13%, 73.06%, 93.41%, 95.18%,
59.74%, respectively, surpassing state-of-the-art performance by over 4.36%.

</details>

### [153] [Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World](https://arxiv.org/abs/2505.04788)
*Bangyan Liao,Zhenjun Zhao,Haoang Li,Yi Zhou,Yingping Zeng,Hao Li,Peidong Liu*

Main category: cs.CV

TLDR: 提出了一种基于凸松弛技术的全局最优方法（GlobustVP），用于曼哈顿世界中的消失点估计，平衡了效率、鲁棒性和全局最优性。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么是次优解，要么追求全局最优但计算成本高，因此需要一种更高效且全局最优的解决方案。

Method: 采用软关联方案和截断多选择误差，将问题转化为QCQP，再松弛为凸SDP问题，并通过迭代求解器GlobustVP独立更新每个消失点及其关联线。

Result: 在合成和真实数据上的实验表明，GlobustVP在效率、鲁棒性和全局最优性方面优于现有方法。

Conclusion: GlobustVP是一种高效且全局最优的消失点估计方法，适用于曼哈顿世界中的3D视觉应用。

Abstract: Determining the vanishing points (VPs) in a Manhattan world, as a fundamental
task in many 3D vision applications, consists of jointly inferring the line-VP
association and locating each VP. Existing methods are, however, either
sub-optimal solvers or pursuing global optimality at a significant cost of
computing time. In contrast to prior works, we introduce convex relaxation
techniques to solve this task for the first time. Specifically, we employ a
``soft'' association scheme, realized via a truncated multi-selection error,
that allows for joint estimation of VPs' locations and line-VP associations.
This approach leads to a primal problem that can be reformulated into a
quadratically constrained quadratic programming (QCQP) problem, which is then
relaxed into a convex semidefinite programming (SDP) problem. To solve this SDP
problem efficiently, we present a globally optimal outlier-robust iterative
solver (called \textbf{GlobustVP}), which independently searches for one VP and
its associated lines in each iteration, treating other lines as outliers. After
each independent update of all VPs, the mutual orthogonality between the three
VPs in a Manhattan world is reinforced via local refinement. Extensive
experiments on both synthetic and real-world data demonstrate that
\textbf{GlobustVP} achieves a favorable balance between efficiency, robustness,
and global optimality compared to previous works. The code is publicly
available at https://github.com/WU-CVGL/GlobustVP.

</details>

### [154] [DetReIDX: A Stress-Test Dataset for Real-World UAV-Based Person Recognition](https://arxiv.org/abs/2505.04793)
*Kailash A. Hambarde,Nzakiese Mbongo,Pavan Kumar MP,Satish Mekewad,Carolina Fernandes,Gökhan Silahtaroğlu,Alice Nithya,Pawan Wasnik,MD. Rashidunnabi,Pranita Samale,Hugo Proença*

Main category: cs.CV

TLDR: DetReIDX是一个大规模的空地行人数据集，旨在测试真实世界条件下行人重识别（ReID）的性能，包含多会话、多视角和多种变化因素。


<details>
  <summary>Details</summary>
Motivation: 现有ReID技术在真实世界复杂条件下表现不佳，且公开数据集未能充分模拟这些挑战。

Method: 构建DetReIDX数据集，包含509个身份的1300万边界框，涵盖多会话、多视角和多种变化因素，并标注了16种软生物特征和多任务标签。

Result: 现有SOTA方法在DetReIDX条件下性能显著下降（检测精度下降80%，Rank-1 ReID下降70%）。

Conclusion: DetReIDX为评估长期ReID提供了有效工具，数据集和协议已公开。

Abstract: Person reidentification (ReID) technology has been considered to perform
relatively well under controlled, ground-level conditions, but it breaks down
when deployed in challenging real-world settings. Evidently, this is due to
extreme data variability factors such as resolution, viewpoint changes, scale
variations, occlusions, and appearance shifts from clothing or session drifts.
Moreover, the publicly available data sets do not realistically incorporate
such kinds and magnitudes of variability, which limits the progress of this
technology. This paper introduces DetReIDX, a large-scale aerial-ground person
dataset, that was explicitly designed as a stress test to ReID under real-world
conditions. DetReIDX is a multi-session set that includes over 13 million
bounding boxes from 509 identities, collected in seven university campuses from
three continents, with drone altitudes between 5.8 and 120 meters. More
important, as a key novelty, DetReIDX subjects were recorded in (at least) two
sessions on different days, with changes in clothing, daylight and location,
making it suitable to actually evaluate long-term person ReID. Plus, data were
annotated from 16 soft biometric attributes and multitask labels for detection,
tracking, ReID, and action recognition. In order to provide empirical evidence
of DetReIDX usefulness, we considered the specific tasks of human detection and
ReID, where SOTA methods catastrophically degrade performance (up to 80% in
detection accuracy and over 70% in Rank-1 ReID) when exposed to DetReIDXs
conditions. The dataset, annotations, and official evaluation protocols are
publicly available at https://www.it.ubi.pt/DetReIDX/

</details>

### [155] [Are Synthetic Corruptions A Reliable Proxy For Real-World Corruptions?](https://arxiv.org/abs/2505.04835)
*Shashank Agnihotri,David Schader,Nico Sharei,Mehmet Ege Kaçar,Margret Keuper*

Main category: cs.CV

TLDR: 论文研究了合成损坏是否可靠替代真实损坏来测试深度学习模型的鲁棒性，发现两者在语义分割模型上的表现有强相关性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在真实应用中易受分布偏移影响，而收集多样化真实数据成本高，因此需要验证合成损坏的可靠性。

Method: 通过大规模基准研究，比较语义分割模型在真实损坏和合成损坏数据集上的表现。

Result: 结果显示平均性能有强相关性，支持合成损坏用于鲁棒性评估。

Conclusion: 合成损坏在特定情况下能有效代表真实损坏，为鲁棒性测试提供了实用替代方案。

Abstract: Deep learning (DL) models are widely used in real-world applications but
remain vulnerable to distribution shifts, especially due to weather and
lighting changes. Collecting diverse real-world data for testing the robustness
of DL models is resource-intensive, making synthetic corruptions an attractive
alternative for robustness testing. However, are synthetic corruptions a
reliable proxy for real-world corruptions? To answer this, we conduct the
largest benchmarking study on semantic segmentation models, comparing
performance on real-world corruptions and synthetic corruptions datasets. Our
results reveal a strong correlation in mean performance, supporting the use of
synthetic corruptions for robustness evaluation. We further analyze
corruption-specific correlations, providing key insights to understand when
synthetic corruptions succeed in representing real-world corruptions.
Open-source Code:
https://github.com/shashankskagnihotri/benchmarking_robustness/tree/segmentation_david/semantic_segmentation

</details>

### [156] [Seeing Cells Clearly: Evaluating Machine Vision Strategies for Microglia Centroid Detection in 3D Images](https://arxiv.org/abs/2505.04838)
*Youjia Zhang*

Main category: cs.CV

TLDR: 比较三种工具（ilastik、3D Morph、Omnipose）在3D显微镜图像中定位小胶质细胞中心点的效果。


<details>
  <summary>Details</summary>
Motivation: 小胶质细胞的形态对脑健康研究至关重要，准确识别其中心点有助于获取更精确的信息。

Method: 使用ilastik、3D Morph和Omnipose三种工具分析3D显微镜图像，评估其定位效果。

Result: 每种工具对小胶质细胞的识别方式不同，结果存在差异，影响从图像中获取的信息。

Conclusion: 工具的选择会影响小胶质细胞中心点的定位结果，需根据研究需求选择合适的工具。

Abstract: Microglia are important cells in the brain, and their shape can tell us a lot
about brain health. In this project, I test three different tools for finding
the center points of microglia in 3D microscope images. The tools include
ilastik, 3D Morph, and Omnipose. I look at how well each one finds the cells
and how their results compare. My findings show that each tool sees the cells
in its own way, and this can affect the kind of information we get from the
images.

</details>

### [157] [ORXE: Orchestrating Experts for Dynamically Configurable Efficiency](https://arxiv.org/abs/2505.04850)
*Qingyuan Wang,Guoxin Wang,Barry Cardiff,Deepu John*

Main category: cs.CV

TLDR: ORXE是一个模块化、适应性强的框架，通过动态调整推理路径实现AI模型的高效实时配置。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要复杂的元模型训练，而ORXE旨在简化开发过程，同时保持高效和灵活性。

Method: 利用预训练专家集合和基于置信度的门控机制，动态分配计算资源。

Result: 在图像分类任务中，ORXE表现优于单个专家和其他动态模型。

Conclusion: ORXE可扩展至其他应用，为多样化部署提供可扩展解决方案。

Abstract: This paper presents ORXE, a modular and adaptable framework for achieving
real-time configurable efficiency in AI models. By leveraging a collection of
pre-trained experts with diverse computational costs and performance levels,
ORXE dynamically adjusts inference pathways based on the complexity of input
samples. Unlike conventional approaches that require complex metamodel
training, ORXE achieves high efficiency and flexibility without complicating
the development process. The proposed system utilizes a confidence-based gating
mechanism to allocate appropriate computational resources for each input. ORXE
also supports adjustments to the preference between inference cost and
prediction performance across a wide range during runtime. We implemented a
training-free ORXE system for image classification tasks, evaluating its
efficiency and accuracy across various devices. The results demonstrate that
ORXE achieves superior performance compared to individual experts and other
dynamic models in most cases. This approach can be extended to other
applications, providing a scalable solution for diverse real-world deployment
scenarios.

</details>

### [158] [Mix-QSAM: Mixed-Precision Quantization of the Segment Anything Model](https://arxiv.org/abs/2505.04861)
*Navin Ranjan,Andreas Savakis*

Main category: cs.CV

TLDR: Mix-QSAM是一种混合精度的后训练量化框架，用于优化Segment Anything Model（SAM）的计算和内存需求，通过层间协同和重要性评分实现高效量化。


<details>
  <summary>Details</summary>
Motivation: SAM的高计算和内存需求限制了其在资源受限设备上的部署，现有固定位宽量化方法在精度和效率上表现不佳。

Method: 提出Mix-QSAM框架，利用KL散度计算层重要性评分，并通过因果互信息度量层间协同性，使用整数二次规划优化位宽分配。

Result: 实验表明，Mix-QSAM在6位和4位混合精度设置下，实例分割和目标检测任务的平均精度提升高达20%。

Conclusion: Mix-QSAM通过混合精度量化显著提升了SAM的效率，同时保持了高精度，适用于资源受限设备。

Abstract: The Segment Anything Model (SAM) is a popular vision foundation model;
however, its high computational and memory demands make deployment on
resource-constrained devices challenging. While Post-Training Quantization
(PTQ) is a practical approach for reducing computational overhead, existing PTQ
methods rely on fixed bit-width quantization, leading to suboptimal accuracy
and efficiency. To address this limitation, we propose Mix-QSAM, a
mixed-precision PTQ framework for SAM. First, we introduce a layer-wise
importance score, derived using Kullback-Leibler (KL) divergence, to quantify
each layer's contribution to the model's output. Second, we introduce
cross-layer synergy, a novel metric based on causal mutual information, to
capture dependencies between adjacent layers. This ensures that highly
interdependent layers maintain similar bit-widths, preventing abrupt precision
mismatches that degrade feature propagation and numerical stability. Using
these metrics, we formulate an Integer Quadratic Programming (IQP) problem to
determine optimal bit-width allocation under model size and bit-operation
constraints, assigning higher precision to critical layers while minimizing
bit-width in less influential layers. Experimental results demonstrate that
Mix-QSAM consistently outperforms existing PTQ methods on instance segmentation
and object detection tasks, achieving up to 20% higher average precision under
6-bit and 4-bit mixed-precision settings, while maintaining computational
efficiency.

</details>

### [159] [Auto-regressive transformation for image alignment](https://arxiv.org/abs/2505.04864)
*Kanggeon Lee,Soochahn Lee,Kyoung Mu Lee*

Main category: cs.CV

TLDR: 提出了一种名为Auto-Regressive Transformation (ART)的新方法，通过自回归框架迭代优化多尺度图像中的变换，显著提升了图像对齐的精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在特征稀疏区域、极端尺度和视场差异以及大变形情况下表现不佳，导致对齐精度不足。

Method: ART利用分层多尺度特征，通过随机采样点迭代优化变换，并结合交叉注意力层聚焦关键区域。

Result: 在多个数据集上的实验表明，ART显著优于现有方法。

Conclusion: ART是一种强大且广泛适用的精确图像对齐新方法。

Abstract: Existing methods for image alignment struggle in cases involving
feature-sparse regions, extreme scale and field-of-view differences, and large
deformations, often resulting in suboptimal accuracy. Robustness to these
challenges improves through iterative refinement of the transformation field
while focusing on critical regions in multi-scale image representations. We
thus propose Auto-Regressive Transformation (ART), a novel method that
iteratively estimates the coarse-to-fine transformations within an
auto-regressive framework. Leveraging hierarchical multi-scale features, our
network refines the transformations using randomly sampled points at each
scale. By incorporating guidance from the cross-attention layer, the model
focuses on critical regions, ensuring accurate alignment even in challenging,
feature-limited conditions. Extensive experiments across diverse datasets
demonstrate that ART significantly outperforms state-of-the-art methods,
establishing it as a powerful new method for precise image alignment with broad
applicability.

</details>

### [160] [Learning from Loss Landscape: Generalizable Mixed-Precision Quantization via Adaptive Sharpness-Aware Gradient Aligning](https://arxiv.org/abs/2505.04877)
*Lianbo Ma,Jianlun Ma,Yuee Zhou,Guoyang Xie,Qiang He,Zhichao Lu*

Main category: cs.CV

TLDR: 提出了一种基于小数据集搜索量化策略并推广至大数据集的方法，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有混合精度量化方法需要在大规模数据集上进行昂贵的搜索，计算成本高。

Method: 通过在小数据集上搜索量化策略并推广至大数据集，结合锐度感知最小化、隐式梯度方向对齐和自适应扰动半径技术。

Result: 在CIFAR10上搜索策略后，ImageNet上达到相同精度，计算成本显著降低，效率提升150%。

Conclusion: 该方法有效解决了大规模量化搜索的高成本问题，提升了效率。

Abstract: Mixed Precision Quantization (MPQ) has become an essential technique for
optimizing neural network by determining the optimal bitwidth per layer.
Existing MPQ methods, however, face a major hurdle: they require a
computationally expensive search for quantization policies on large-scale
datasets. To resolve this issue, we introduce a novel approach that first
searches for quantization policies on small datasets and then generalizes them
to large-scale datasets. This approach simplifies the process, eliminating the
need for large-scale quantization fine-tuning and only necessitating model
weight adjustment. Our method is characterized by three key techniques:
sharpness-aware minimization for enhanced quantization generalization, implicit
gradient direction alignment to handle gradient conflicts among different
optimization objectives, and an adaptive perturbation radius to accelerate
optimization. Both theoretical analysis and experimental results validate our
approach. Using the CIFAR10 dataset (just 0.5\% the size of ImageNet training
data) for MPQ policy search, we achieved equivalent accuracy on ImageNet with a
significantly lower computational cost, while improving efficiency by up to
150% over the baselines.

</details>

### [161] [Cross-Branch Orthogonality for Improved Generalization in Face Deepfake Detection](https://arxiv.org/abs/2505.04888)
*Tharindu Fernando,Clinton Fookes,Sridha Sridharan,Simon Denman*

Main category: cs.CV

TLDR: 论文提出了一种新的深度伪造检测策略，通过利用从粗到细的空间信息、语义信息及其交互作用，结合特征正交性解缠方法，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术快速发展，现有检测器因依赖特定伪造痕迹而难以应对新型伪造内容，导致社会对多媒体内容的信任危机。

Method: 提出了一种基于特征正交性解缠的策略，整合多特征向量，避免特征空间复杂化，同时确保特征区分度和减少冗余。

Result: 在FaceForensics++、Celeb-DF和DFDC数据集上，新方法在跨数据集评估中分别比现有最优方法提升了5%和7%。

Conclusion: 该方法通过多特征整合和解缠策略，显著提升了深度伪造检测的泛化能力和性能。

Abstract: Remarkable advancements in generative AI technology have given rise to a
spectrum of novel deepfake categories with unprecedented leaps in their
realism, and deepfakes are increasingly becoming a nuisance to law enforcement
authorities and the general public. In particular, we observe alarming levels
of confusion, deception, and loss of faith regarding multimedia content within
society caused by face deepfakes, and existing deepfake detectors are
struggling to keep up with the pace of improvements in deepfake generation.
This is primarily due to their reliance on specific forgery artifacts, which
limits their ability to generalise and detect novel deepfake types. To combat
the spread of malicious face deepfakes, this paper proposes a new strategy that
leverages coarse-to-fine spatial information, semantic information, and their
interactions while ensuring feature distinctiveness and reducing the redundancy
of the modelled features. A novel feature orthogonality-based disentanglement
strategy is introduced to ensure branch-level and cross-branch feature
disentanglement, which allows us to integrate multiple feature vectors without
adding complexity to the feature space or compromising generalisation.
Comprehensive experiments on three public benchmarks: FaceForensics++,
Celeb-DF, and the Deepfake Detection Challenge (DFDC) show that these design
choices enable the proposed approach to outperform current state-of-the-art
methods by 5% on the Celeb-DF dataset and 7% on the DFDC dataset in a
cross-dataset evaluation setting.

</details>

### [162] [OWT: A Foundational Organ-Wise Tokenization Framework for Medical Imaging](https://arxiv.org/abs/2505.04899)
*Sifan Song,Siyeop Yoon,Pengfei Jin,Sekeun Kim,Matthew Tivnan,Yujin Oh,Runqi Meng,Ling Chen,Zhiliang Lyu,Dufan Wu,Ning Guo,Xiang Li,Quanzheng Li*

Main category: cs.CV

TLDR: 提出了一种基于器官的分组标记化框架（OWT），通过显式分离图像中的不同器官或语义实体，提升可解释性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有表示学习方法通常生成整体性、黑箱化的嵌入，限制了可解释性和泛化能力，尤其在医学影像中更为突出。

Method: 采用器官分组标记化（OWT）和基于标记组的重建（TGR）训练范式，将图像分解为独立的标记组，每组对应特定器官或语义实体。

Result: 在CT和MRI数据集上，OWT不仅实现了强图像重建和分割性能，还支持语义级生成和检索等新应用。

Conclusion: OWT是一种具有广泛可扩展性和应用潜力的语义解耦表示学习框架，适用于医学影像及其他领域。

Abstract: Recent advances in representation learning often rely on holistic, black-box
embeddings that entangle multiple semantic components, limiting
interpretability and generalization. These issues are especially critical in
medical imaging. To address these limitations, we propose an Organ-Wise
Tokenization (OWT) framework with a Token Group-based Reconstruction (TGR)
training paradigm. Unlike conventional approaches that produce holistic
features, OWT explicitly disentangles an image into separable token groups,
each corresponding to a distinct organ or semantic entity. Our design ensures
each token group encapsulates organ-specific information, boosting
interpretability, generalization, and efficiency while allowing fine-grained
control in downstream tasks. Experiments on CT and MRI datasets demonstrate the
effectiveness of OWT in not only achieving strong image reconstruction and
segmentation performance, but also enabling novel semantic-level generation and
retrieval applications that are out of reach for standard holistic embedding
methods. These findings underscore the potential of OWT as a foundational
framework for semantically disentangled representation learning, offering broad
scalability and applicability to real-world medical imaging scenarios and
beyond.

</details>

### [163] [Pro2SAM: Mask Prompt to SAM with Grid Points for Weakly Supervised Object Localization](https://arxiv.org/abs/2505.04905)
*Xi Yang,Songsong Duan,Nannan Wang,Xinbo Gao*

Main category: cs.CV

TLDR: 论文提出Pro2SAM网络，利用SAM的零样本泛化和细粒度分割能力，结合创新的掩码提示和网格点，提升弱监督目标定位（WSOL）性能。


<details>
  <summary>Details</summary>
Motivation: 现有CAM和自注意力图无法学习像素级细粒度信息，限制了WSOL的进展。

Method: 设计GTFormer生成粗粒度前景图作为掩码提示，结合网格点输入SAM，提出像素级相似度度量匹配掩码。

Result: 在CUB-200-2011和ILSVRC上分别达到84.03%和66.85%的Top-1定位准确率。

Conclusion: Pro2SAM通过结合SAM和创新的提示机制，显著提升了WSOL性能。

Abstract: Weakly Supervised Object Localization (WSOL), which aims to localize objects
by only using image-level labels, has attracted much attention because of its
low annotation cost in real applications. Current studies focus on the Class
Activation Map (CAM) of CNN and the self-attention map of transformer to
identify the region of objects. However, both CAM and self-attention maps can
not learn pixel-level fine-grained information on the foreground objects, which
hinders the further advance of WSOL. To address this problem, we initiatively
leverage the capability of zero-shot generalization and fine-grained
segmentation in Segment Anything Model (SAM) to boost the activation of
integral object regions. Further, to alleviate the semantic ambiguity issue
accrued in single point prompt-based SAM, we propose an innovative mask prompt
to SAM (Pro2SAM) network with grid points for WSOL task. First, we devise a
Global Token Transformer (GTFormer) to generate a coarse-grained foreground map
as a flexible mask prompt, where the GTFormer jointly embeds patch tokens and
novel global tokens to learn foreground semantics. Secondly, we deliver grid
points as dense prompts into SAM to maximize the probability of foreground
mask, which avoids the lack of objects caused by a single point/box prompt.
Finally, we propose a pixel-level similarity metric to come true the mask
matching from mask prompt to SAM, where the mask with the highest score is
viewed as the final localization map. Experiments show that the proposed
Pro2SAM achieves state-of-the-art performance on both CUB-200-2011 and ILSVRC,
with 84.03\% and 66.85\% Top-1 Loc, respectively.

</details>

### [164] [SpatialPrompting: Keyframe-driven Zero-Shot Spatial Reasoning with Off-the-Shelf Multimodal Large Language Models](https://arxiv.org/abs/2505.04911)
*Shun Taguchi,Hideki Deguchi,Takumi Hamazaki,Hiroyuki Sakai*

Main category: cs.CV

TLDR: SpatialPrompting框架利用现成的多模态大语言模型实现零样本三维空间推理，无需昂贵的3D特定微调或专用输入。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的3D特定微调和专用输入（如点云或体素特征），限制了灵活性和可扩展性。

Method: 采用关键帧驱动的提示生成策略，结合视觉-语言相似性、马氏距离、视场和图像清晰度等指标选择关键帧，并与相机位姿数据结合，抽象空间关系。

Result: 在ScanQA和SQA3D等基准数据集上实现了零样本最先进性能。

Conclusion: SpatialPrompting提供了一种更简单、更灵活且可扩展的三维空间推理方法，无需专用输入或微调。

Abstract: This study introduces SpatialPrompting, a novel framework that harnesses the
emergent reasoning capabilities of off-the-shelf multimodal large language
models to achieve zero-shot spatial reasoning in three-dimensional (3D)
environments. Unlike existing methods that rely on expensive 3D-specific
fine-tuning with specialized 3D inputs such as point clouds or voxel-based
features, SpatialPrompting employs a keyframe-driven prompt generation
strategy. This framework uses metrics such as vision-language similarity,
Mahalanobis distance, field of view, and image sharpness to select a diverse
and informative set of keyframes from image sequences and then integrates them
with corresponding camera pose data to effectively abstract spatial
relationships and infer complex 3D structures. The proposed framework not only
establishes a new paradigm for flexible spatial reasoning that utilizes
intuitive visual and positional cues but also achieves state-of-the-art
zero-shot performance on benchmark datasets, such as ScanQA and SQA3D, across
several metrics. The proposed method effectively eliminates the need for
specialized 3D inputs and fine-tuning, offering a simpler and more scalable
alternative to conventional approaches.

</details>

### [165] [GlyphMastero: A Glyph Encoder for High-Fidelity Scene Text Editing](https://arxiv.org/abs/2505.04915)
*Tong Wang,Ting Liu,Xiaochao Qu,Chengjing Wu,Luoqi Liu,Xiaolin Hu*

Main category: cs.CV

TLDR: GlyphMastero是一种专门设计的字形编码器，通过字形注意力模块和多尺度OCR特征融合，显著提升了场景文本编辑的质量和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的方法在生成复杂字符（如中文）时表现不佳，难以保持笔画级精度和整体一致性。

Method: 提出GlyphMastero，结合字形注意力模块和多尺度特征金字塔网络，实现跨层次和多尺度的特征融合。

Result: 在句子准确率上提升18.02%，文本区域Fréchet inception距离降低53.28%。

Conclusion: GlyphMastero通过精细的字形引导和多尺度特征融合，显著提升了场景文本编辑的性能。

Abstract: Scene text editing, a subfield of image editing, requires modifying texts in
images while preserving style consistency and visual coherence with the
surrounding environment. While diffusion-based methods have shown promise in
text generation, they still struggle to produce high-quality results. These
methods often generate distorted or unrecognizable characters, particularly
when dealing with complex characters like Chinese. In such systems, characters
are composed of intricate stroke patterns and spatial relationships that must
be precisely maintained. We present GlyphMastero, a specialized glyph encoder
designed to guide the latent diffusion model for generating texts with
stroke-level precision. Our key insight is that existing methods, despite using
pretrained OCR models for feature extraction, fail to capture the hierarchical
nature of text structures - from individual strokes to stroke-level
interactions to overall character-level structure. To address this, our glyph
encoder explicitly models and captures the cross-level interactions between
local-level individual characters and global-level text lines through our novel
glyph attention module. Meanwhile, our model implements a feature pyramid
network to fuse the multi-scale OCR backbone features at the global-level.
Through these cross-level and multi-scale fusions, we obtain more detailed
glyph-aware guidance, enabling precise control over the scene text generation
process. Our method achieves an 18.02\% improvement in sentence accuracy over
the state-of-the-art multi-lingual scene text editing baseline, while
simultaneously reducing the text-region Fr\'echet inception distance by
53.28\%.

</details>

### [166] [A Simple Detector with Frame Dynamics is a Strong Tracker](https://arxiv.org/abs/2505.04917)
*Chenxu Peng,Chenxu Wang,Minrui Zou,Danyang Li,Zhengpeng Yang,Yimian Dai,Ming-Ming Cheng,Xiang Li*

Main category: cs.CV

TLDR: 提出了一种红外微小目标跟踪方法，通过全局检测和运动感知学习提升性能，在Anti-UAV挑战赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有跟踪器依赖裁剪模板区域且运动建模能力有限，难以处理微小目标。

Method: 结合帧动态和轨迹约束过滤策略，利用帧差和光流编码目标特征与运动特性。

Result: 在多个指标上优于现有方法，在Anti-UAV挑战赛中取得第一和第二名。

Conclusion: 该方法通过创新设计显著提升了红外微小目标跟踪的性能和鲁棒性。

Abstract: Infrared object tracking plays a crucial role in Anti-Unmanned Aerial Vehicle
(Anti-UAV) applications. Existing trackers often depend on cropped template
regions and have limited motion modeling capabilities, which pose challenges
when dealing with tiny targets. To address this, we propose a simple yet
effective infrared tiny-object tracker that enhances tracking performance by
integrating global detection and motion-aware learning with temporal priors.
Our method is based on object detection and achieves significant improvements
through two key innovations. First, we introduce frame dynamics, leveraging
frame difference and optical flow to encode both prior target features and
motion characteristics at the input level, enabling the model to better
distinguish the target from background clutter. Second, we propose a trajectory
constraint filtering strategy in the post-processing stage, utilizing
spatio-temporal priors to suppress false positives and enhance tracking
robustness. Extensive experiments show that our method consistently outperforms
existing approaches across multiple metrics in challenging infrared UAV
tracking scenarios. Notably, we achieve state-of-the-art performance in the 4th
Anti-UAV Challenge, securing 1st place in Track 1 and 2nd place in Track 2.

</details>

### [167] [Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models](https://arxiv.org/abs/2505.04921)
*Yunxin Li,Zhenyu Liu,Zitao Li,Xuanyu Zhang,Zhenran Xu,Xinyu Chen,Haoyuan Shi,Shenyuan Jiang,Xintong Wang,Jifang Wang,Shouzheng Huang,Xinping Zhao,Borui Jiang,Lanqing Hong,Longyue Wang,Zhuotao Tian,Baoxing Huai,Wenhan Luo,Weihua Luo,Zheng Zhang,Baotian Hu,Min Zhang*

Main category: cs.CV

TLDR: 论文综述了多模态推理研究的进展，提出了四阶段发展路线图，并探讨了原生大型多模态推理模型（N-LMRMs）的未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统在开放、不确定和多模态环境中运行，推理能力对实现鲁棒和自适应行为至关重要。

Method: 通过四阶段发展路线图分析多模态推理研究，从任务特定模块到统一的多模态LLMs，再到N-LMRMs。

Result: 多模态推理研究从模块化发展到统一框架，但仍面临全模态泛化、推理深度和代理行为等挑战。

Conclusion: 未来研究方向是开发支持复杂环境中可扩展、代理和自适应推理的原生大型多模态推理模型。

Abstract: Reasoning lies at the heart of intelligence, shaping the ability to make
decisions, draw conclusions, and generalize across domains. In artificial
intelligence, as systems increasingly operate in open, uncertain, and
multimodal environments, reasoning becomes essential for enabling robust and
adaptive behavior. Large Multimodal Reasoning Models (LMRMs) have emerged as a
promising paradigm, integrating modalities such as text, images, audio, and
video to support complex reasoning capabilities and aiming to achieve
comprehensive perception, precise understanding, and deep reasoning. As
research advances, multimodal reasoning has rapidly evolved from modular,
perception-driven pipelines to unified, language-centric frameworks that offer
more coherent cross-modal understanding. While instruction tuning and
reinforcement learning have improved model reasoning, significant challenges
remain in omni-modal generalization, reasoning depth, and agentic behavior. To
address these issues, we present a comprehensive and structured survey of
multimodal reasoning research, organized around a four-stage developmental
roadmap that reflects the field's shifting design philosophies and emerging
capabilities. First, we review early efforts based on task-specific modules,
where reasoning was implicitly embedded across stages of representation,
alignment, and fusion. Next, we examine recent approaches that unify reasoning
into multimodal LLMs, with advances such as Multimodal Chain-of-Thought (MCoT)
and multimodal reinforcement learning enabling richer and more structured
reasoning chains. Finally, drawing on empirical insights from challenging
benchmarks and experimental cases of OpenAI O3 and O4-mini, we discuss the
conceptual direction of native large multimodal reasoning models (N-LMRMs),
which aim to support scalable, agentic, and adaptive reasoning and planning in
complex, real-world environments.

</details>

### [168] [Canny2Palm: Realistic and Controllable Palmprint Generation for Large-scale Pre-training](https://arxiv.org/abs/2505.04922)
*Xingzeng Lan,Xing Duan,Chen Chen,Weiyu Lin,Bo Wang*

Main category: cs.CV

TLDR: 提出了一种名为Canny2Palm的新方法，通过Canny边缘检测器和Pix2Pix网络合成虚拟掌纹，提升识别精度。


<details>
  <summary>Details</summary>
Motivation: 掌纹识别数据稀缺，现有方法难以满足大规模预训练需求。

Method: 使用Canny边缘检测器提取掌纹纹理，结合Pix2Pix网络生成逼真掌纹，并通过重组纹理生成新身份。

Result: 在开放集掌纹识别基准测试中，使用Canny2Palm合成数据预训练的模型识别准确率提升7.2%，且能持续扩展至10,000个合成身份。

Conclusion: Canny2Palm能生成逼真且多样化的掌纹数据，为大规模预训练提供潜力。

Abstract: Palmprint recognition is a secure and privacy-friendly method of biometric
identification. One of the major challenges to improve palmprint recognition
accuracy is the scarcity of palmprint data. Recently, a popular line of
research revolves around the synthesis of virtual palmprints for large-scale
pre-training purposes. In this paper, we propose a novel synthesis method named
Canny2Palm that extracts palm textures with Canny edge detector and uses them
to condition a Pix2Pix network for realistic palmprint generation. By
re-assembling palmprint textures from different identities, we are able to
create new identities by seeding the generator with new assemblies. Canny2Palm
not only synthesizes realistic data following the distribution of real
palmprints but also enables controllable diversity to generate large-scale new
identities. On open-set palmprint recognition benchmarks, models pre-trained
with Canny2Palm synthetic data outperform the state-of-the-art with up to 7.2%
higher identification accuracy. Moreover, the performance of models pre-trained
with Canny2Palm continues to improve given 10,000 synthetic IDs while those
with existing methods already saturate, demonstrating the potential of our
method for large-scale pre-training.

</details>

### [169] [FF-PNet: A Pyramid Network Based on Feature and Field for Brain Image Registration](https://arxiv.org/abs/2505.04938)
*Ying Zhang,Shuai Guo,Chenxi Sun,Yuchen Zhu,Jinhai Xiang*

Main category: cs.CV

TLDR: 提出了一种基于特征和变形场的金字塔配准网络（FF-PNet），通过并行提取粗粒度和细粒度特征，提高了医学图像配准的效率。


<details>
  <summary>Details</summary>
Motivation: 现有模型在并行提取粗粒度和细粒度特征时效率不足，需要改进。

Method: 设计了残差特征融合模块（RFFM）和残差变形场融合模块（RDFFM），并行操作以处理复杂图像变形。

Result: 在LPBA和OASIS数据集上实验表明，FF-PNet在Dice相似系数等指标上优于流行方法。

Conclusion: FF-PNet展示了RFFM和RDFFM的优越特征解码能力，无需注意力机制或多层感知器即可显著提升配准精度。

Abstract: In recent years, deformable medical image registration techniques have made
significant progress. However, existing models still lack efficiency in
parallel extraction of coarse and fine-grained features. To address this, we
construct a new pyramid registration network based on feature and deformation
field (FF-PNet). For coarse-grained feature extraction, we design a Residual
Feature Fusion Module (RFFM), for fine-grained image deformation, we propose a
Residual Deformation Field Fusion Module (RDFFM). Through the parallel
operation of these two modules, the model can effectively handle complex image
deformations. It is worth emphasizing that the encoding stage of FF-PNet only
employs traditional convolutional neural networks without any attention
mechanisms or multilayer perceptrons, yet it still achieves remarkable
improvements in registration accuracy, fully demonstrating the superior feature
decoding capabilities of RFFM and RDFFM. We conducted extensive experiments on
the LPBA and OASIS datasets. The results show our network consistently
outperforms popular methods in metrics like the Dice Similarity Coefficient.

</details>

### [170] [Building-Guided Pseudo-Label Learning for Cross-Modal Building Damage Mapping](https://arxiv.org/abs/2505.04941)
*Jiepan Li,He Huang,Yu Sheng,Yujun Guo,Wei He*

Main category: cs.CV

TLDR: 提出了一种基于建筑引导的伪标签学习框架，用于从多模态遥感图像中准确评估建筑损坏。


<details>
  <summary>Details</summary>
Motivation: 灾害响应和恢复规划需要准确的建筑损坏评估，但多模态图像间的差异和不确定性是主要挑战。

Method: 通过建筑提取模型和变化检测模型，结合多模型融合、测试时增强和低不确定性伪标签策略。

Result: 在2025 IEEE GRSS数据融合竞赛数据集中取得最高mIoU分数（54.28%），并获得第一名。

Conclusion: 该方法通过建筑引导的伪标签策略显著提升了建筑损坏分类的准确性和可靠性。

Abstract: Accurate building damage assessment using bi-temporal multi-modal remote
sensing images is essential for effective disaster response and recovery
planning. This study proposes a novel Building-Guided Pseudo-Label Learning
Framework to address the challenges of mapping building damage from
pre-disaster optical and post-disaster SAR images. First, we train a series of
building extraction models using pre-disaster optical images and building
labels. To enhance building segmentation, we employ multi-model fusion and
test-time augmentation strategies to generate pseudo-probabilities, followed by
a low-uncertainty pseudo-label training method for further refinement. Next, a
change detection model is trained on bi-temporal cross-modal images and damaged
building labels. To improve damage classification accuracy, we introduce a
building-guided low-uncertainty pseudo-label refinement strategy, which
leverages building priors from the previous step to guide pseudo-label
generation for damaged buildings, reducing uncertainty and enhancing
reliability. Experimental results on the 2025 IEEE GRSS Data Fusion Contest
dataset demonstrate the effectiveness of our approach, which achieved the
highest mIoU score (54.28%) and secured first place in the competition.

</details>

### [171] [T2VTextBench: A Human Evaluation Benchmark for Textual Control in Video Generation Models](https://arxiv.org/abs/2505.04946)
*Xuyang Guo,Jiayan Huo,Zhenmei Shi,Zhao Song,Jiahao Zhang,Jiale Zhao*

Main category: cs.CV

TLDR: 论文介绍了T2VTextBench，首个专注于评估文本到视频模型中屏幕文本保真度和时间一致性的基准测试，发现现有模型在生成清晰、一致的文本方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到视频生成技术在高保真度和指令遵循方面取得了进展，但现有模型在生成精确屏幕文本（如字幕或数学公式）方面的能力尚未得到充分验证，这对需要高文本准确性的应用提出了挑战。

Method: 提出T2VTextBench基准测试，通过结合复杂文本字符串和动态场景变化的提示，评估模型在多帧中保持详细指令的能力，测试了十种最先进的系统。

Result: 大多数模型难以生成清晰、一致的文本，揭示了当前视频生成器在文本处理方面的关键不足。

Conclusion: 研究结果指出了未来研究的明确方向，即增强视频合成中的文本处理能力。

Abstract: Thanks to recent advancements in scalable deep architectures and large-scale
pretraining, text-to-video generation has achieved unprecedented capabilities
in producing high-fidelity, instruction-following content across a wide range
of styles, enabling applications in advertising, entertainment, and education.
However, these models' ability to render precise on-screen text, such as
captions or mathematical formulas, remains largely untested, posing significant
challenges for applications requiring exact textual accuracy. In this work, we
introduce T2VTextBench, the first human-evaluation benchmark dedicated to
evaluating on-screen text fidelity and temporal consistency in text-to-video
models. Our suite of prompts integrates complex text strings with dynamic scene
changes, testing each model's ability to maintain detailed instructions across
frames. We evaluate ten state-of-the-art systems, ranging from open-source
solutions to commercial offerings, and find that most struggle to generate
legible, consistent text. These results highlight a critical gap in current
video generators and provide a clear direction for future research aimed at
enhancing textual manipulation in video synthesis.

</details>

### [172] [An Efficient Method for Accurate Pose Estimation and Error Correction of Cuboidal Objects](https://arxiv.org/abs/2505.04962)
*Utsav Rai,Hardik Mehta,Vismay Vakharia,Aditya Choudhary,Amit Parmar,Rolif Lima,Kaushik Das*

Main category: cs.CV

TLDR: 提出了一种高效方法，用于精确估计立方体物体的姿态，并通过线性时间方法减少姿态误差。


<details>
  <summary>Details</summary>
Motivation: 解决在自主拾取立方体物体时高精度姿态估计的需求，避免传统方法的时间开销和不确定性。

Method: 提出了一种线性时间方法进行姿态误差估计和校正，替代传统的全局点云配准和局部配准算法。

Result: 实现了高效且精确的立方体物体姿态估计，减少了误差和执行时间。

Conclusion: 该方法为立方体物体的高精度姿态估计提供了一种高效且可靠的解决方案。

Abstract: The proposed system outlined in this paper is a solution to a use case that
requires the autonomous picking of cuboidal objects from an organized or
unorganized pile with high precision. This paper presents an efficient method
for precise pose estimation of cuboid-shaped objects, which aims to reduce
errors in target pose in a time-efficient manner. Typical pose estimation
methods like global point cloud registrations are prone to minor pose errors
for which local registration algorithms are generally used to improve pose
accuracy. However, due to the execution time overhead and uncertainty in the
error of the final achieved pose, an alternate, linear time approach is
proposed for pose error estimation and correction. This paper presents an
overview of the solution followed by a detailed description of individual
modules of the proposed algorithm.

</details>

### [173] [ViCTr: Vital Consistency Transfer for Pathology Aware Image Synthesis](https://arxiv.org/abs/2505.04963)
*Onkar Susladkar,Gayatri Deshmukh,Yalcin Tur,Ulas Bagci*

Main category: cs.CV

TLDR: ViCTr是一种新型两阶段框架，结合校正流轨迹和Tweedie校正扩散过程，用于高保真、病理感知的医学图像合成，显著提升效率和效果。


<details>
  <summary>Details</summary>
Motivation: 医学图像合成面临标注数据有限、模态差异和复杂病理（如肝硬化）表示的挑战，现有方法难以同时保持解剖保真度和病理特征。

Method: ViCTr采用两阶段框架：预训练阶段使用EWC保留解剖结构，微调阶段通过LoRA模块精确控制病理严重程度，并支持一步采样。

Result: 在BTCV、AMOS和CirrMRI600+数据集上表现优异，MFID为17.01，比现有方法低28%，并提升nnUNet分割性能3.8%。

Conclusion: ViCTr首次实现细粒度、病理感知的MRI合成，填补了AI医学影像研究的空白。

Abstract: Synthesizing medical images remains challenging due to limited annotated
pathological data, modality domain gaps, and the complexity of representing
diffuse pathologies such as liver cirrhosis. Existing methods often struggle to
maintain anatomical fidelity while accurately modeling pathological features,
frequently relying on priors derived from natural images or inefficient
multi-step sampling. In this work, we introduce ViCTr (Vital Consistency
Transfer), a novel two-stage framework that combines a rectified flow
trajectory with a Tweedie-corrected diffusion process to achieve high-fidelity,
pathology-aware image synthesis. First, we pretrain ViCTr on the ATLAS-8k
dataset using Elastic Weight Consolidation (EWC) to preserve critical
anatomical structures. We then fine-tune the model adversarially with Low-Rank
Adaptation (LoRA) modules for precise control over pathology severity. By
reformulating Tweedie's formula within a linear trajectory framework, ViCTr
supports one-step sampling, reducing inference from 50 steps to just 4, without
sacrificing anatomical realism. We evaluate ViCTr on BTCV (CT), AMOS (MRI), and
CirrMRI600+ (cirrhosis) datasets. Results demonstrate state-of-the-art
performance, achieving a Medical Frechet Inception Distance (MFID) of 17.01 for
cirrhosis synthesis 28% lower than existing approaches and improving nnUNet
segmentation by +3.8% mDSC when used for data augmentation. Radiologist reviews
indicate that ViCTr-generated liver cirrhosis MRIs are clinically
indistinguishable from real scans. To our knowledge, ViCTr is the first method
to provide fine-grained, pathology-aware MRI synthesis with graded severity
control, closing a critical gap in AI-driven medical imaging research.

</details>

### [174] [CAG-VLM: Fine-Tuning of a Large-Scale Model to Recognize Angiographic Images for Next-Generation Diagnostic Systems](https://arxiv.org/abs/2505.04964)
*Yuto Nakamura,Satoshi Kodera,Haruki Settai,Hiroki Shinohara,Masatsugu Tamura,Tomohiro Noguchi,Tatsuki Furusawa,Ryo Takizawa,Tempei Kabayama,Norihiko Takeda*

Main category: cs.CV

TLDR: 论文提出了一种两阶段的AI支持决策流程，用于冠状动脉造影（CAG）图像分析，并构建了一个双语数据集。通过训练CNN和微调视觉语言模型（VLM），实现了高精度的侧向分类和临床报告生成。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉造影（CAG）的解读和治疗规划依赖专家，AI支持可提高效率和准确性。

Method: 1. 从539例检查中采样14,686帧图像，标注关键帧和侧向性，训练CNN模型；2. 应用CNN提取关键帧，构建双语平行语料库，微调三种VLM模型。

Result: CNN在侧向性分类上F1得分为0.96；微调后的Gemma3模型在临床评分中表现最佳（7.20/10）。

Conclusion: 研究表明，经过微调的VLM能有效辅助心脏病专家生成CAG图像的临床报告和治疗建议。

Abstract: Coronary angiography (CAG) is the gold-standard imaging modality for
evaluating coronary artery disease, but its interpretation and subsequent
treatment planning rely heavily on expert cardiologists. To enable AI-based
decision support, we introduce a two-stage, physician-curated pipeline and a
bilingual (Japanese/English) CAG image-report dataset. First, we sample 14,686
frames from 539 exams and annotate them for key-frame detection and left/right
laterality; a ConvNeXt-Base CNN trained on this data achieves 0.96 F1 on
laterality classification, even on low-contrast frames. Second, we apply the
CNN to 243 independent exams, extract 1,114 key frames, and pair each with its
pre-procedure report and expert-validated diagnostic and treatment summary,
yielding a parallel corpus. We then fine-tune three open-source VLMs
(PaliGemma2, Gemma3, and ConceptCLIP-enhanced Gemma3) via LoRA and evaluate
them using VLScore and cardiologist review. Although PaliGemma2 w/LoRA attains
the highest VLScore, Gemma3 w/LoRA achieves the top clinician rating (mean
7.20/10); we designate this best-performing model as CAG-VLM. These results
demonstrate that specialized, fine-tuned VLMs can effectively assist
cardiologists in generating clinical reports and treatment recommendations from
CAG images.

</details>

### [175] [DenseGrounding: Improving Dense Language-Vision Semantics for Ego-Centric 3D Visual Grounding](https://arxiv.org/abs/2505.04965)
*Henry Zheng,Hao Shi,Qihang Peng,Yong Xien Chng,Rui Huang,Yepeng Weng,Zhongchao Shi,Gao Huang*

Main category: cs.CV

TLDR: DenseGrounding提出了一种新方法，通过增强视觉和文本语义，解决了3D视觉定位中的稀疏点云融合和有限文本语义问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 推动智能代理通过自然语言理解和交互3D环境，解决3D视觉定位中的视觉语义丢失和文本语义不足问题。

Method: 引入Hierarchical Scene Semantic Enhancer保留密集视觉语义，使用Language Semantic Enhancer增强文本描述。

Result: 在完整数据集和小型子集上分别提升5.81%和7.56%，并在CVPR 2024挑战赛中获奖。

Conclusion: DenseGrounding通过多模态语义增强，显著提升了3D视觉定位的性能和鲁棒性。

Abstract: Enabling intelligent agents to comprehend and interact with 3D environments
through natural language is crucial for advancing robotics and human-computer
interaction. A fundamental task in this field is ego-centric 3D visual
grounding, where agents locate target objects in real-world 3D spaces based on
verbal descriptions. However, this task faces two significant challenges: (1)
loss of fine-grained visual semantics due to sparse fusion of point clouds with
ego-centric multi-view images, (2) limited textual semantic context due to
arbitrary language descriptions. We propose DenseGrounding, a novel approach
designed to address these issues by enhancing both visual and textual
semantics. For visual features, we introduce the Hierarchical Scene Semantic
Enhancer, which retains dense semantics by capturing fine-grained global scene
features and facilitating cross-modal alignment. For text descriptions, we
propose a Language Semantic Enhancer that leverages large language models to
provide rich context and diverse language descriptions with additional context
during model training. Extensive experiments show that DenseGrounding
significantly outperforms existing methods in overall accuracy, with
improvements of 5.81% and 7.56% when trained on the comprehensive full dataset
and smaller mini subset, respectively, further advancing the SOTA in egocentric
3D visual grounding. Our method also achieves 1st place and receives the
Innovation Award in the CVPR 2024 Autonomous Grand Challenge Multi-view 3D
Visual Grounding Track, validating its effectiveness and robustness.

</details>

### [176] [ReAlign: Bilingual Text-to-Motion Generation via Step-Aware Reward-Guided Alignment](https://arxiv.org/abs/2505.04974)
*Wanjiang Weng,Xiaofeng Tan,Hongsong Wang,Pan Zhou*

Main category: cs.CV

TLDR: 论文提出BiHumanML3D双语数据集和BiMD模型，结合ReAlign方法提升双语文本到动作生成的质量和对齐效果。


<details>
  <summary>Details</summary>
Motivation: 解决双语文本到动作生成中数据集缺失和文本-动作分布不对齐的问题。

Method: 提出BiHumanML3D数据集和BiMD模型，结合Reward-guided sampling Alignment (ReAlign)方法优化生成过程。

Result: 实验表明该方法显著提升了文本-动作对齐和动作质量。

Conclusion: BiHumanML3D和BiMD模型结合ReAlign方法有效解决了双语文本到动作生成的关键挑战。

Abstract: Bilingual text-to-motion generation, which synthesizes 3D human motions from
bilingual text inputs, holds immense potential for cross-linguistic
applications in gaming, film, and robotics. However, this task faces critical
challenges: the absence of bilingual motion-language datasets and the
misalignment between text and motion distributions in diffusion models, leading
to semantically inconsistent or low-quality motions. To address these
challenges, we propose BiHumanML3D, a novel bilingual human motion dataset,
which establishes a crucial benchmark for bilingual text-to-motion generation
models. Furthermore, we propose a Bilingual Motion Diffusion model (BiMD),
which leverages cross-lingual aligned representations to capture semantics,
thereby achieving a unified bilingual model. Building upon this, we propose
Reward-guided sampling Alignment (ReAlign) method, comprising a step-aware
reward model to assess alignment quality during sampling and a reward-guided
strategy that directs the diffusion process toward an optimally aligned
distribution. This reward model integrates step-aware tokens and combines a
text-aligned module for semantic consistency and a motion-aligned module for
realism, refining noisy motions at each timestep to balance probability density
and alignment. Experiments demonstrate that our approach significantly improves
text-motion alignment and motion quality compared to existing state-of-the-art
methods. Project page: https://wengwanjiang.github.io/ReAlign-page/.

</details>

### [177] [Federated Deconfounding and Debiasing Learning for Out-of-Distribution Generalization](https://arxiv.org/abs/2505.04979)
*Zhuang Qi,Sijin Zhou,Lei Meng,Han Hu,Han Yu,Xiangxu Meng*

Main category: cs.CV

TLDR: FedDDL方法通过构建因果图和去混淆学习模块，解决联邦学习中的属性偏见问题，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中属性偏见导致模型性能下降，现有方法缺乏对推理路径的全面分析。

Method: 提出FedDDL方法，包括客户端内去混淆学习模块和客户端间去偏学习模块，通过因果图和后门调整消除干扰。

Result: 在2个基准数据集上，FedDDL平均Top-1准确率比现有方法高4.5%。

Conclusion: FedDDL通过因果分析和去偏模块，有效提升模型对主要对象的关注能力。

Abstract: Attribute bias in federated learning (FL) typically leads local models to
optimize inconsistently due to the learning of non-causal associations,
resulting degraded performance. Existing methods either use data augmentation
for increasing sample diversity or knowledge distillation for learning
invariant representations to address this problem. However, they lack a
comprehensive analysis of the inference paths, and the interference from
confounding factors limits their performance. To address these limitations, we
propose the \underline{Fed}erated \underline{D}econfounding and
\underline{D}ebiasing \underline{L}earning (FedDDL) method. It constructs a
structured causal graph to analyze the model inference process, and performs
backdoor adjustment to eliminate confounding paths. Specifically, we design an
intra-client deconfounding learning module for computer vision tasks to
decouple background and objects, generating counterfactual samples that
establish a connection between the background and any label, which stops the
model from using the background to infer the label. Moreover, we design an
inter-client debiasing learning module to construct causal prototypes to reduce
the proportion of the background in prototype components. Notably, it bridges
the gap between heterogeneous representations via causal prototypical
regularization. Extensive experiments on 2 benchmarking datasets demonstrate
that \methodname{} significantly enhances the model capability to focus on main
objects in unseen data, leading to 4.5\% higher Top-1 Accuracy on average over
9 state-of-the-art existing methods.

</details>

### [178] [StabStitch++: Unsupervised Online Video Stitching with Spatiotemporal Bidirectional Warps](https://arxiv.org/abs/2505.05001)
*Lang Nie,Chunyu Lin,Kang Liao,Yun Zhang,Shuaicheng Liu,Yao Zhao*

Main category: cs.CV

TLDR: 论文提出StabStitch++框架，解决视频拼接中的warping shake问题，通过无监督学习同时实现空间拼接和时间稳定化。


<details>
  <summary>Details</summary>
Motivation: 视频拼接中，即使输入视频稳定，拼接后仍会出现时间上的抖动（warping shake），影响视觉体验。

Method: 设计双向分解模块解耦单应变换，结合空间和时间变形，提出平滑模型优化拼接轨迹。

Result: StabStitch++在性能、鲁棒性和效率上优于现有方法，支持实时在线视频拼接。

Conclusion: StabStitch++通过同时优化对齐和稳定化，显著提升了视频拼接质量。

Abstract: We retarget video stitching to an emerging issue, named warping shake, which
unveils the temporal content shakes induced by sequentially unsmooth warps when
extending image stitching to video stitching. Even if the input videos are
stable, the stitched video can inevitably cause undesired warping shakes and
affect the visual experience. To address this issue, we propose StabStitch++, a
novel video stitching framework to realize spatial stitching and temporal
stabilization with unsupervised learning simultaneously. First, different from
existing learning-based image stitching solutions that typically warp one image
to align with another, we suppose a virtual midplane between original image
planes and project them onto it. Concretely, we design a differentiable
bidirectional decomposition module to disentangle the homography transformation
and incorporate it into our spatial warp, evenly spreading alignment burdens
and projective distortions across two views. Then, inspired by camera paths in
video stabilization, we derive the mathematical expression of stitching
trajectories in video stitching by elaborately integrating spatial and temporal
warps. Finally, a warp smoothing model is presented to produce stable stitched
videos with a hybrid loss to simultaneously encourage content alignment,
trajectory smoothness, and online collaboration. Compared with StabStitch that
sacrifices alignment for stabilization, StabStitch++ makes no compromise and
optimizes both of them simultaneously, especially in the online mode. To
establish an evaluation benchmark and train the learning framework, we build a
video stitching dataset with a rich diversity in camera motions and scenes.
Experiments exhibit that StabStitch++ surpasses current solutions in stitching
performance, robustness, and efficiency, offering compelling advancements in
this field by building a real-time online video stitching system.

</details>

### [179] [Automated Thoracolumbar Stump Rib Detection and Analysis in a Large CT Cohort](https://arxiv.org/abs/2505.05004)
*Hendrik Möller,Hanna Schön,Alina Dima,Benjamin Keinert-Weth,Robert Graf,Matan Atad,Johannes Paetzold,Friederike Jungmann,Rickmer Braren,Florian Kofler,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke*

Main category: cs.CV

TLDR: 该研究提出了一种自动化检测胸腰椎残根肋骨的方法，通过深度学习模型和形态学分析显著提高了检测精度和定量分析能力。


<details>
  <summary>Details</summary>
Motivation: 胸腰椎残根肋骨是胸腰椎过渡椎或计数异常的重要指标，传统方法依赖人工定性评估，本研究旨在实现自动化检测和定量分析。

Method: 训练高分辨率深度学习模型进行肋骨分割，并使用迭代算法和分段线性插值评估肋骨长度。

Result: 模型分割效果显著优于现有方法（Dice分数0.997 vs. 0.779），肋骨长度评估成功率达98.2%。形态学分析显示残根肋骨在位置、厚度和方向上与完整肋骨有显著差异。

Conclusion: 研究证明了自动化检测残根肋骨的可行性，并公开了模型权重和掩码供公共使用。

Abstract: Thoracolumbar stump ribs are one of the essential indicators of thoracolumbar
transitional vertebrae or enumeration anomalies. While some studies manually
assess these anomalies and describe the ribs qualitatively, this study aims to
automate thoracolumbar stump rib detection and analyze their morphology
quantitatively. To this end, we train a high-resolution deep-learning model for
rib segmentation and show significant improvements compared to existing models
(Dice score 0.997 vs. 0.779, p-value < 0.01). In addition, we use an iterative
algorithm and piece-wise linear interpolation to assess the length of the ribs,
showing a success rate of 98.2%. When analyzing morphological features, we show
that stump ribs articulate more posteriorly at the vertebrae (-19.2 +- 3.8 vs
-13.8 +- 2.5, p-value < 0.01), are thinner (260.6 +- 103.4 vs. 563.6 +- 127.1,
p-value < 0.01), and are oriented more downwards and sideways within the first
centimeters in contrast to full-length ribs. We show that with partially
visible ribs, these features can achieve an F1-score of 0.84 in differentiating
stump ribs from regular ones. We publish the model weights and masks for public
use.

</details>

### [180] [Driving with Context: Online Map Matching for Complex Roads Using Lane Markings and Scenario Recognition](https://arxiv.org/abs/2505.05007)
*Xin Bi,Zhichao Li,Yuxuan Xia,Panpan Tong,Lijuan Zhang,Yang Chen,Junsheng Fu*

Main category: cs.CV

TLDR: 提出了一种基于隐马尔可夫模型（HMM）和多概率因子的在线标准定义（SD）地图匹配方法，显著提升了复杂路网中的匹配精度。


<details>
  <summary>Details</summary>
Motivation: 当前在线地图匹配方法在复杂路网（尤其是多层道路区域）中容易出错，影响了车辆导航和智能驾驶功能的激活。

Method: 通过多车道跟踪方法生成车道标记，并与SD地图结合构建增强SD地图；利用车道标记检测和场景识别生成概率因子，优化HMM模型。

Result: 在欧洲和中国的道路测试中，该方法显著优于基准方法，F1分数在Zenseact Open Dataset和上海多层道路区域分别达到98.04%和94.60%。

Conclusion: 该方法在复杂路网中实现了高精度的在线地图匹配，尤其在多层道路区域表现优异。

Abstract: Accurate online map matching is fundamental to vehicle navigation and the
activation of intelligent driving functions. Current online map matching
methods are prone to errors in complex road networks, especially in multilevel
road area. To address this challenge, we propose an online Standard Definition
(SD) map matching method by constructing a Hidden Markov Model (HMM) with
multiple probability factors. Our proposed method can achieve accurate map
matching even in complex road networks by carefully leveraging lane markings
and scenario recognition in the designing of the probability factors. First,
the lane markings are generated by a multi-lane tracking method and associated
with the SD map using HMM to build an enriched SD map. In areas covered by the
enriched SD map, the vehicle can re-localize itself by performing Iterative
Closest Point (ICP) registration for the lane markings. Then, the probability
factor accounting for the lane marking detection can be obtained using the
association probability between adjacent lanes and roads. Second, the driving
scenario recognition model is applied to generate the emission probability
factor of scenario recognition, which improves the performance of map matching
on elevated roads and ordinary urban roads underneath them. We validate our
method through extensive road tests in Europe and China, and the experimental
results show that our proposed method effectively improves the online map
matching accuracy as compared to other existing methods, especially in
multilevel road area. Specifically, the experiments show that our proposed
method achieves $F_1$ scores of 98.04% and 94.60% on the Zenseact Open Dataset
and test data of multilevel road areas in Shanghai respectively, significantly
outperforming benchmark methods. The implementation is available at
https://github.com/TRV-Lab/LMSR-OMM.

</details>

### [181] [Adaptive Contextual Embedding for Robust Far-View Borehole Detection](https://arxiv.org/abs/2505.05008)
*Xuesong Liu,Tianyu Hao,Emmett J. Ientilucci*

Main category: cs.CV

TLDR: 提出一种自适应检测方法，通过EMA统计更新改进YOLO架构，解决小尺度、高密度分布的钻孔检测问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以检测小尺度、高密度且视觉特征有限的钻孔，影响爆破操作的安全与效率。

Method: 结合自适应增强、嵌入稳定化和上下文细化，利用EMA统计更新改进特征提取。

Result: 在采石场数据集上显著优于基线YOLO方法，验证了方法的有效性。

Conclusion: 该方法在复杂工业场景中表现优异，提升了钻孔检测的稳定性和准确性。

Abstract: In controlled blasting operations, accurately detecting densely distributed
tiny boreholes from far-view imagery is critical for operational safety and
efficiency. However, existing detection methods often struggle due to small
object scales, highly dense arrangements, and limited distinctive visual
features of boreholes. To address these challenges, we propose an adaptive
detection approach that builds upon existing architectures (e.g., YOLO) by
explicitly leveraging consistent embedding representations derived through
exponential moving average (EMA)-based statistical updates.
  Our method introduces three synergistic components: (1) adaptive augmentation
utilizing dynamically updated image statistics to robustly handle illumination
and texture variations; (2) embedding stabilization to ensure consistent and
reliable feature extraction; and (3) contextual refinement leveraging spatial
context for improved detection accuracy. The pervasive use of EMA in our method
is particularly advantageous given the limited visual complexity and small
scale of boreholes, allowing stable and robust representation learning even
under challenging visual conditions. Experiments on a challenging proprietary
quarry-site dataset demonstrate substantial improvements over baseline
YOLO-based architectures, highlighting our method's effectiveness in realistic
and complex industrial scenarios.

</details>

### [182] [SOAP: Style-Omniscient Animatable Portraits](https://arxiv.org/abs/2505.05022)
*Tingting Liao,Yujian Zheng,Adilbek Karmanov,Liwen Hu,Leyang Jin,Yuliang Xiu,Hao Li*

Main category: cs.CV

TLDR: SOAP是一个风格全知的框架，能够从任意肖像生成具有拓扑一致性和动画控制的3D头像。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在风格多样性、动画控制和细节处理上的不足。

Method: 利用多视角扩散模型和自适应优化流程，结合FLAME网格变形和可微分渲染。

Result: 生成的3D头像支持FACS动画，保留细节（如发型、配饰），优于现有技术。

Conclusion: SOAP在单视角头像建模和图像到3D生成方面表现优异，代码和数据已开源。

Abstract: Creating animatable 3D avatars from a single image remains challenging due to
style limitations (realistic, cartoon, anime) and difficulties in handling
accessories or hairstyles. While 3D diffusion models advance single-view
reconstruction for general objects, outputs often lack animation controls or
suffer from artifacts because of the domain gap. We propose SOAP, a
style-omniscient framework to generate rigged, topology-consistent avatars from
any portrait. Our method leverages a multiview diffusion model trained on 24K
3D heads with multiple styles and an adaptive optimization pipeline to deform
the FLAME mesh while maintaining topology and rigging via differentiable
rendering. The resulting textured avatars support FACS-based animation,
integrate with eyeballs and teeth, and preserve details like braided hair or
accessories. Extensive experiments demonstrate the superiority of our method
over state-of-the-art techniques for both single-view head modeling and
diffusion-based generation of Image-to-3D. Our code and data are publicly
available for research purposes at https://github.com/TingtingLiao/soap.

</details>

### [183] [Split Matching for Inductive Zero-shot Semantic Segmentation](https://arxiv.org/abs/2505.05023)
*Jialei Chen,Xu Zheng,Dongyue Li,Chong Yi,Seigo Ito,Danda Pani Paudel,Luc Van Gool,Hiroshi Murase,Daisuke Deguchi*

Main category: cs.CV

TLDR: 论文提出Split Matching（SM）策略，通过解耦匈牙利匹配为两部分，分别处理已见类别和潜在类别，结合CLIP特征聚类和多尺度特征增强，在零样本语义分割任务中取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决零样本语义分割中传统匈牙利匹配方法因缺乏未标注类别监督而导致的过拟合和误分类问题。

Method: 提出Split Matching策略，将查询分为已见组和候选组，分别优化；利用CLIP特征聚类生成伪掩码，并通过多尺度特征增强模块（MFE）提升空间细节捕捉能力。

Result: 在标准基准测试中取得最优性能。

Conclusion: SM是首个在归纳式零样本语义分割中引入解耦匈牙利匹配的方法，显著提升了未标注类别的分割效果。

Abstract: Zero-shot Semantic Segmentation (ZSS) aims to segment categories that are not
annotated during training. While fine-tuning vision-language models has
achieved promising results, these models often overfit to seen categories due
to the lack of supervision for unseen classes. As an alternative to fully
supervised approaches, query-based segmentation has shown great latent in ZSS,
as it enables object localization without relying on explicit labels. However,
conventional Hungarian matching, a core component in query-based frameworks,
needs full supervision and often misclassifies unseen categories as background
in the setting of ZSS. To address this issue, we propose Split Matching (SM), a
novel assignment strategy that decouples Hungarian matching into two
components: one for seen classes in annotated regions and another for latent
classes in unannotated regions (referred to as unseen candidates).
Specifically, we partition the queries into seen and candidate groups, enabling
each to be optimized independently according to its available supervision. To
discover unseen candidates, we cluster CLIP dense features to generate pseudo
masks and extract region-level embeddings using CLS tokens. Matching is then
conducted separately for the two groups based on both class-level similarity
and mask-level consistency. Additionally, we introduce a Multi-scale Feature
Enhancement (MFE) module that refines decoder features through residual
multi-scale aggregation, improving the model's ability to capture spatial
details across resolutions. SM is the first to introduce decoupled Hungarian
matching under the inductive ZSS setting, and achieves state-of-the-art
performance on two standard benchmarks.

</details>

### [184] [xTrace: A Facial Expressive Behaviour Analysis Tool for Continuous Affect Recognition](https://arxiv.org/abs/2505.05043)
*Mani Kumar Tellamekala,Shashank Jaiswal,Thomas Smith,Timur Alamev,Gary McKeown,Anthony Brown,Michel Valstar*

Main category: cs.CV

TLDR: xTrace是一种用于分析面部表情行为的工具，解决了数据稀缺和特征提取的挑战，并在自然场景下表现出高准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 构建一个在自然场景下实时分析面部表情行为的系统面临两大挑战：缺乏大规模标记数据集和难以提取高效、可解释的面部特征。

Method: xTrace利用最大规模的面部情感视频数据集（约45万视频）训练模型，并采用可解释且高效的面部特征描述符。

Result: 在5万视频的验证集上，xTrace的平均CCC为0.86，平均绝对误差为0.13，表现出高准确性和鲁棒性。

Conclusion: xTrace在2D情感空间中具有高准确性，对非正面头部姿态鲁棒，且其不确定性估计与准确性高度相关。

Abstract: Recognising expressive behaviours in face videos is a long-standing challenge
in Affective Computing. Despite significant advancements in recent years, it
still remains a challenge to build a robust and reliable system for
naturalistic and in-the-wild facial expressive behaviour analysis in real time.
This paper addresses two key challenges in building such a system: (1). The
paucity of large-scale labelled facial affect video datasets with extensive
coverage of the 2D emotion space, and (2). The difficulty of extracting facial
video features that are discriminative, interpretable, robust, and
computationally efficient. Toward addressing these challenges, we introduce
xTrace, a robust tool for facial expressive behaviour analysis and predicting
continuous values of dimensional emotions, namely valence and arousal, from
in-the-wild face videos.
  To address challenge (1), our affect recognition model is trained on the
largest facial affect video data set, containing ~450k videos that cover most
emotion zones in the dimensional emotion space, making xTrace highly versatile
in analysing a wide spectrum of naturalistic expressive behaviours. To address
challenge (2), xTrace uses facial affect descriptors that are not only
explainable, but can also achieve a high degree of accuracy and robustness with
low computational complexity. The key components of xTrace are benchmarked
against three existing tools: MediaPipe, OpenFace, and Augsburg Affect Toolbox.
On an in-the-wild validation set composed of 50k videos, xTrace achieves 0.86
mean CCC and 0.13 mean absolute error values. We present a detailed error
analysis of affect predictions from xTrace, illustrating (a). its ability to
recognise emotions with high accuracy across most bins in the 2D emotion space,
(b). its robustness to non-frontal head pose angles, and (c). a strong
correlation between its uncertainty estimates and its accuracy.

</details>

### [185] [UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model](https://arxiv.org/abs/2505.05049)
*Timo Kaiser,Thomas Norrenbrock,Bodo Rosenhahn*

Main category: cs.CV

TLDR: 本文提出了一种基于贝叶斯熵的轻量级不确定性量化方法USAM，用于解决SAM模型在语义分割中的不确定性量化问题。


<details>
  <summary>Details</summary>
Motivation: 由于SAM模型的类无关性和模糊性，现有不确定性量化方法难以适用，因此需要一种新的理论框架来量化其不确定性。

Method: 提出了一种基于贝叶斯熵的理论框架，联合考虑偶然性、认知性和任务不确定性，并训练了轻量级后处理方法USAM。

Result: USAM在多个数据集（SA-V、MOSE、ADE20k、DAVIS、COCO）上表现出优越的预测能力，且计算成本低、易于使用。

Conclusion: USAM提供了一种高效的不确定性量化方案，支持用户提示、增强半监督流程，并平衡了准确性与成本效率。

Abstract: The introduction of the Segment Anything Model (SAM) has paved the way for
numerous semantic segmentation applications. For several tasks, quantifying the
uncertainty of SAM is of particular interest. However, the ambiguous nature of
the class-agnostic foundation model SAM challenges current uncertainty
quantification (UQ) approaches. This paper presents a theoretically motivated
uncertainty quantification model based on a Bayesian entropy formulation
jointly respecting aleatoric, epistemic, and the newly introduced task
uncertainty. We use this formulation to train USAM, a lightweight post-hoc UQ
method. Our model traces the root of uncertainty back to under-parameterised
models, insufficient prompts or image ambiguities. Our proposed deterministic
USAM demonstrates superior predictive capabilities on the SA-V, MOSE, ADE20k,
DAVIS, and COCO datasets, offering a computationally cheap and easy-to-use UQ
alternative that can support user-prompting, enhance semi-supervised pipelines,
or balance the tradeoff between accuracy and cost efficiency.

</details>

### [186] [ULFine: Unbiased Lightweight Fine-tuning for Foundation-Model-Assisted Long-Tailed Semi-Supervised Learning](https://arxiv.org/abs/2505.05062)
*Enhao Zhang,Chaohua Li,Chuanxing Geng,Songcan Chen*

Main category: cs.CV

TLDR: 论文探索了视觉基础模型（如CLIP）对长尾半监督学习（LTSSL）的影响，提出了三种策略（LP、LFT、FFT），发现FFT性能下降，LP和LFT对尾部类别帮助有限。作者提出ULFine策略，通过自适应拟合和双逻辑融合减少偏差，显著提升性能并降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 研究视觉基础模型在长尾半监督学习中的作用，解决现有策略在尾部类别上的性能不足问题。

Method: 采用三种策略（LP、LFT、FFT）分析模型表现，提出ULFine策略，结合自适应拟合和双逻辑融合。

Result: FFT性能下降，LP和LFT对尾部类别帮助有限；ULFine显著降低训练成本并提升预测准确率。

Conclusion: ULFine通过减少偏差和优化训练策略，显著提升了长尾半监督学习的性能。

Abstract: Based on the success of large-scale visual foundation models like CLIP in
various downstream tasks, this paper initially attempts to explore their impact
on Long-Tailed Semi-Supervised Learning (LTSSL) by employing the foundation
model with three strategies: Linear Probing (LP), Lightweight Fine-Tuning
(LFT), and Full Fine-Tuning (FFT). Our analysis presents the following
insights: i) Compared to LTSSL algorithms trained from scratch, FFT results in
a decline in model performance, whereas LP and LFT, although boosting overall
model performance, exhibit negligible benefits to tail classes. ii) LP produces
numerous false pseudo-labels due to \textit{underlearned} training data, while
LFT can reduce the number of these false labels but becomes overconfident about
them owing to \textit{biased fitting} training data. This exacerbates the
pseudo-labeled and classifier biases inherent in LTSSL, limiting performance
improvement in the tail classes. With these insights, we propose a Unbiased
Lightweight Fine-tuning strategy, \textbf{ULFine}, which mitigates the
overconfidence via confidence-aware adaptive fitting of textual prototypes and
counteracts the pseudo-labeled and classifier biases via complementary fusion
of dual logits. Extensive experiments demonstrate that ULFine markedly
decreases training costs by over ten times and substantially increases
prediction accuracies compared to state-of-the-art methods.

</details>

### [187] [FG-CLIP: Fine-Grained Visual and Textual Alignment](https://arxiv.org/abs/2505.05071)
*Chunyu Xie,Bin Wang,Fanjing Kong,Jincheng Li,Dawei Liang,Gengshen Zhang,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TLDR: FG-CLIP通过生成大量长标题图像对、构建高质量数据集和引入难负样本，提升了CLIP在细粒度理解任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决CLIP在细粒度理解任务中的不足，因其仅关注粗粒度短标题。

Method: 1. 生成16亿长标题图像对；2. 构建1200万图像和4000万区域标注的高质量数据集；3. 引入1000万难负样本。

Result: FG-CLIP在细粒度理解、开放词汇目标检测等任务中优于CLIP和其他先进方法。

Conclusion: FG-CLIP有效捕捉细粒度细节并提升模型性能，相关资源已开源。

Abstract: Contrastive Language-Image Pre-training (CLIP) excels in multimodal tasks
such as image-text retrieval and zero-shot classification but struggles with
fine-grained understanding due to its focus on coarse-grained short captions.
To address this, we propose Fine-Grained CLIP (FG-CLIP), which enhances
fine-grained understanding through three key innovations. First, we leverage
large multimodal models to generate 1.6 billion long caption-image pairs for
capturing global-level semantic details. Second, a high-quality dataset is
constructed with 12 million images and 40 million region-specific bounding
boxes aligned with detailed captions to ensure precise, context-rich
representations. Third, 10 million hard fine-grained negative samples are
incorporated to improve the model's ability to distinguish subtle semantic
differences. Corresponding training methods are meticulously designed for these
data. Extensive experiments demonstrate that FG-CLIP outperforms the original
CLIP and other state-of-the-art methods across various downstream tasks,
including fine-grained understanding, open-vocabulary object detection,
image-text retrieval, and general multimodal benchmarks. These results
highlight FG-CLIP's effectiveness in capturing fine-grained image details and
improving overall model performance. The related data, code, and models are
available at https://github.com/360CVGroup/FG-CLIP.

</details>

### [188] [Visual Affordances: Enabling Robots to Understand Object Functionality](https://arxiv.org/abs/2505.05074)
*Tommaso Apicella,Alessio Xompero,Andrea Cavallaro*

Main category: cs.CV

TLDR: 论文提出了一种统一的视觉可供性预测方法，解决了现有方法因定义不一致导致的复现性问题，并引入了Affordance Sheet以提高透明度。


<details>
  <summary>Details</summary>
Motivation: 解决视觉可供性预测中因任务定义不一致导致的复现性问题，促进公平和可靠的比较基准。

Method: 提出统一的可供性预测框架，系统综述现有方法和数据集，并引入Affordance Sheet记录解决方案、数据集和验证细节。

Result: 通过将视觉可供性预测与物理世界关联，提出了一个通用框架，并以物体重量为例展示了其影响。

Conclusion: 该方法填补了可供性感知与机器人执行之间的空白，为任务完成提供了更全面的信息。

Abstract: Human-robot interaction for assistive technologies relies on the prediction
of affordances, which are the potential actions a robot can perform on objects.
Predicting object affordances from visual perception is formulated differently
for tasks such as grasping detection, affordance classification, affordance
segmentation, and hand-object interaction synthesis. In this work, we highlight
the reproducibility issue in these redefinitions, making comparative benchmarks
unfair and unreliable. To address this problem, we propose a unified
formulation for visual affordance prediction, provide a comprehensive and
systematic review of previous works highlighting strengths and limitations of
methods and datasets, and analyse what challenges reproducibility. To favour
transparency, we introduce the Affordance Sheet, a document to detail the
proposed solution, the datasets, and the validation. As the physical properties
of an object influence the interaction with the robot, we present a generic
framework that links visual affordance prediction to the physical world. Using
the weight of an object as an example for this framework, we discuss how
estimating object mass can affect the affordance prediction. Our approach
bridges the gap between affordance perception and robot actuation, and accounts
for the complete information about objects of interest and how the robot
interacts with them to accomplish its task.

</details>

### [189] [PIDiff: Image Customization for Personalized Identities with Diffusion Models](https://arxiv.org/abs/2505.05081)
*Jinyu Gu,Haipeng Liu,Meng Wang,Yang Wang*

Main category: cs.CV

TLDR: PIDiff是一种基于微调的扩散模型，用于个性化身份文本到图像生成，通过W+空间和身份定制微调策略避免语义纠缠，实现准确特征提取和定位。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能解耦身份信息和背景信息，导致生成图像失去关键身份特征且多样性降低。

Method: 结合W+空间和身份定制微调策略，提出交叉注意力块和参数优化策略。

Result: 实验验证了PIDiff在保留身份信息和生成多样化图像方面的有效性。

Conclusion: PIDiff通过避免语义纠缠，实现了更准确的身份特征提取和定位，同时保持了预训练模型的生成能力。

Abstract: Text-to-image generation for personalized identities aims at incorporating
the specific identity into images using a text prompt and an identity image.
Based on the powerful generative capabilities of DDPMs, many previous works
adopt additional prompts, such as text embeddings and CLIP image embeddings, to
represent the identity information, while they fail to disentangle the identity
information and background information. As a result, the generated images not
only lose key identity characteristics but also suffer from significantly
reduced diversity. To address this issue, previous works have combined the W+
space from StyleGAN with diffusion models, leveraging this space to provide a
more accurate and comprehensive representation of identity features through
multi-level feature extraction. However, the entanglement of identity and
background information in in-the-wild images during training prevents accurate
identity localization, resulting in severe semantic interference between
identity and background. In this paper, we propose a novel fine-tuning-based
diffusion model for personalized identities text-to-image generation, named
PIDiff, which leverages the W+ space and an identity-tailored fine-tuning
strategy to avoid semantic entanglement and achieves accurate feature
extraction and localization. Style editing can also be achieved by PIDiff
through preserving the characteristics of identity features in the W+ space,
which vary from coarse to fine. Through the combination of the proposed
cross-attention block and parameter optimization strategy, PIDiff preserves the
identity information and maintains the generation capability for in-the-wild
images of the pre-trained model during inference. Our experimental results
validate the effectiveness of our method in this task.

</details>

### [190] [Nonlinear Motion-Guided and Spatio-Temporal Aware Network for Unsupervised Event-Based Optical Flow](https://arxiv.org/abs/2505.05089)
*Zuntao Liu,Hao Zhuang,Junjie Jiang,Yuhang Song,Zheng Fang*

Main category: cs.CV

TLDR: 论文提出了一种名为E-NMSTFlow的无监督事件相机光流估计网络，专注于长时间序列，通过利用丰富的时空信息和非线性运动补偿损失提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件的光流估计方法忽略了事件的时空特性，并假设线性运动，导致长时间序列中的误差增加。

Method: 提出了STMFA和AMFE模块，利用时空信息学习数据关联，并引入非线性运动补偿损失。

Result: 在MVSEC和DSEC-Flow数据集上，该方法在无监督学习方法中排名第一。

Conclusion: E-NMSTFlow通过利用时空信息和非线性运动补偿，显著提升了事件相机光流估计的准确性。

Abstract: Event cameras have the potential to capture continuous motion information
over time and space, making them well-suited for optical flow estimation.
However, most existing learning-based methods for event-based optical flow
adopt frame-based techniques, ignoring the spatio-temporal characteristics of
events. Additionally, these methods assume linear motion between consecutive
events within the loss time window, which increases optical flow errors in
long-time sequences. In this work, we observe that rich spatio-temporal
information and accurate nonlinear motion between events are crucial for
event-based optical flow estimation. Therefore, we propose E-NMSTFlow, a novel
unsupervised event-based optical flow network focusing on long-time sequences.
We propose a Spatio-Temporal Motion Feature Aware (STMFA) module and an
Adaptive Motion Feature Enhancement (AMFE) module, both of which utilize rich
spatio-temporal information to learn spatio-temporal data associations.
Meanwhile, we propose a nonlinear motion compensation loss that utilizes the
accurate nonlinear motion between events to improve the unsupervised learning
of our network. Extensive experiments demonstrate the effectiveness and
superiority of our method. Remarkably, our method ranks first among
unsupervised learning methods on the MVSEC and DSEC-Flow datasets. Our project
page is available at https://wynelio.github.io/E-NMSTFlow.

</details>

### [191] [DispBench: Benchmarking Disparity Estimation to Synthetic Corruptions](https://arxiv.org/abs/2505.05091)
*Shashank Agnihotri,Amaan Ansari,Annika Dackermann,Fabian Rösch,Margret Keuper*

Main category: cs.CV

TLDR: 论文介绍了DispBench，一个用于系统评估视差估计方法可靠性的基准工具，填补了该领域标准化评估的空白。


<details>
  <summary>Details</summary>
Motivation: 深度学习在视差估计任务中表现优异，但其对分布偏移和对抗攻击的敏感性引发了对其可靠性和泛化能力的担忧。目前缺乏标准化基准来评估这些方法的鲁棒性。

Method: 提出DispBench，通过合成图像损坏（如对抗攻击和2D常见损坏）在多数据集和多样损坏场景下评估视差估计方法的鲁棒性。

Result: 进行了迄今为止最广泛的视差估计方法性能和鲁棒性分析，揭示了准确性、可靠性和泛化能力之间的关键关联。

Conclusion: DispBench为视差估计方法的鲁棒性评估提供了标准化工具，推动了该领域的进步。

Abstract: Deep learning (DL) has surpassed human performance on standard benchmarks,
driving its widespread adoption in computer vision tasks. One such task is
disparity estimation, estimating the disparity between matching pixels in
stereo image pairs, which is crucial for safety-critical applications like
medical surgeries and autonomous navigation. However, DL-based disparity
estimation methods are highly susceptible to distribution shifts and
adversarial attacks, raising concerns about their reliability and
generalization. Despite these concerns, a standardized benchmark for evaluating
the robustness of disparity estimation methods remains absent, hindering
progress in the field.
  To address this gap, we introduce DispBench, a comprehensive benchmarking
tool for systematically assessing the reliability of disparity estimation
methods. DispBench evaluates robustness against synthetic image corruptions
such as adversarial attacks and out-of-distribution shifts caused by 2D Common
Corruptions across multiple datasets and diverse corruption scenarios. We
conduct the most extensive performance and robustness analysis of disparity
estimation methods to date, uncovering key correlations between accuracy,
reliability, and generalization. Open-source code for DispBench:
https://github.com/shashankskagnihotri/benchmarking_robustness/tree/disparity_estimation/final/disparity_estimation

</details>

### [192] [MDE-Edit: Masked Dual-Editing for Multi-Object Image Editing via Diffusion Models](https://arxiv.org/abs/2505.05101)
*Hongyang Zhu,Haipeng Liu,Bo Fu,Yang Wang*

Main category: cs.CV

TLDR: MDE-Edit提出了一种无需训练的推理阶段优化方法，通过双损失设计（OAL和CCL）实现复杂多目标场景中的精确编辑。


<details>
  <summary>Details</summary>
Motivation: 多目标编辑在重叠或交互对象场景中存在定位不准确和属性-对象不匹配的问题，现有方法难以解决。

Method: 提出MDE-Edit，通过Object Alignment Loss（OAL）和Color Consistency Loss（CCL）优化扩散模型的噪声潜在特征。

Result: 实验表明MDE-Edit在编辑准确性和视觉质量上优于现有方法。

Conclusion: MDE-Edit为复杂多目标图像编辑任务提供了鲁棒的解决方案。

Abstract: Multi-object editing aims to modify multiple objects or regions in complex
scenes while preserving structural coherence. This task faces significant
challenges in scenarios involving overlapping or interacting objects: (1)
Inaccurate localization of target objects due to attention misalignment,
leading to incomplete or misplaced edits; (2) Attribute-object mismatch, where
color or texture changes fail to align with intended regions due to
cross-attention leakage, creating semantic conflicts (\textit{e.g.}, color
bleeding into non-target areas). Existing methods struggle with these
challenges: approaches relying on global cross-attention mechanisms suffer from
attention dilution and spatial interference between objects, while mask-based
methods fail to bind attributes to geometrically accurate regions due to
feature entanglement in multi-object scenarios. To address these limitations,
we propose a training-free, inference-stage optimization approach that enables
precise localized image manipulation in complex multi-object scenes, named
MDE-Edit. MDE-Edit optimizes the noise latent feature in diffusion models via
two key losses: Object Alignment Loss (OAL) aligns multi-layer cross-attention
with segmentation masks for precise object positioning, and Color Consistency
Loss (CCL) amplifies target attribute attention within masks while suppressing
leakage to adjacent regions. This dual-loss design ensures localized and
coherent multi-object edits. Extensive experiments demonstrate that MDE-Edit
outperforms state-of-the-art methods in editing accuracy and visual quality,
offering a robust solution for complex multi-object image manipulation tasks.

</details>

### [193] [Automated vision-based assistance tools in bronchoscopy: stenosis severity estimation](https://arxiv.org/abs/2505.05136)
*Clara Tomasini,Javier Rodriguez-Puigvert,Dinora Polanco,Manuel Viñuales,Luis Riazuelo,Ana Cristina Murillo*

Main category: cs.CV

TLDR: 提出了一种基于支气管镜图像的自动化声门下狭窄严重程度评估方法，无需CT扫描，提高了诊断的一致性和效率。


<details>
  <summary>Details</summary>
Motivation: 声门下狭窄的评估通常依赖主观的视觉检查或CT扫描，缺乏自动化且公开的方法和数据集。

Method: 利用支气管镜图像中的光照衰减效应分割和跟踪气道，构建3D模型以测量狭窄程度。

Result: 方法在真实支气管镜数据上验证，与CT和专家评估结果一致，具有可靠的可重复性。

Conclusion: 自动化方法可辅助诊断，减少CT辐射，并发布了首个公开的声门下狭窄评估基准。

Abstract: Purpose: Subglottic stenosis refers to the narrowing of the subglottis, the
airway between the vocal cords and the trachea. Its severity is typically
evaluated by estimating the percentage of obstructed airway. This estimation
can be obtained from CT data or through visual inspection by experts exploring
the region. However, visual inspections are inherently subjective, leading to
less consistent and robust diagnoses. No public methods or datasets are
currently available for automated evaluation of this condition from
bronchoscopy video.
  Methods: We propose a pipeline for automated subglottic stenosis severity
estimation during the bronchoscopy exploration, without requiring the physician
to traverse the stenosed region. Our approach exploits the physical effect of
illumination decline in endoscopy to segment and track the lumen and obtain a
3D model of the airway. This 3D model is obtained from a single frame and is
used to measure the airway narrowing.
  Results: Our pipeline is the first to enable automated and robust subglottic
stenosis severity measurement using bronchoscopy images. The results show
consistency with ground-truth estimations from CT scans and expert estimations,
and reliable repeatability across multiple estimations on the same patient. Our
evaluation is performed on our new Subglottic Stenosis Dataset of real
bronchoscopy procedures data.
  Conclusion: We demonstrate how to automate evaluation of subglottic stenosis
severity using only bronchoscopy. Our approach can assist with and shorten
diagnosis and monitoring procedures, with automated and repeatable estimations
and less exploration time, and save radiation exposure to patients as no CT is
required. Additionally, we release the first public benchmark for subglottic
stenosis severity assessment.

</details>

### [194] [Probabilistic Embeddings for Frozen Vision-Language Models: Uncertainty Quantification with Gaussian Process Latent Variable Models](https://arxiv.org/abs/2505.05163)
*Aishwarya Venkataramanan,Paul Bodesheim,Joachim Denzler*

Main category: cs.CV

TLDR: GroVE是一种后处理方法，通过高斯过程潜在变量模型（GPLVM）从冻结的视觉语言模型（VLM）中获取概率嵌入，解决了确定性嵌入无法捕捉不确定性的问题。


<details>
  <summary>Details</summary>
Motivation: 标准VLM的确定性嵌入难以处理视觉和文本描述中的模糊性及多对应关系，现有方法需要大量数据且未利用预训练VLM的强大表示能力。

Method: GroVE基于GPLVM，学习共享低维潜在空间，通过单模态嵌入重构和跨模态对齐目标优化，生成不确定性感知的概率嵌入。

Result: GroVE在跨模态检索、视觉问答和主动学习等任务中实现了最先进的不确定性校准。

Conclusion: GroVE提供了一种高效的后处理方法，无需重新训练VLM即可生成高质量的概率嵌入。

Abstract: Vision-Language Models (VLMs) learn joint representations by mapping images
and text into a shared latent space. However, recent research highlights that
deterministic embeddings from standard VLMs often struggle to capture the
uncertainties arising from the ambiguities in visual and textual descriptions
and the multiple possible correspondences between images and texts. Existing
approaches tackle this by learning probabilistic embeddings during VLM
training, which demands large datasets and does not leverage the powerful
representations already learned by large-scale VLMs like CLIP. In this paper,
we propose GroVE, a post-hoc approach to obtaining probabilistic embeddings
from frozen VLMs. GroVE builds on Gaussian Process Latent Variable Model
(GPLVM) to learn a shared low-dimensional latent space where image and text
inputs are mapped to a unified representation, optimized through single-modal
embedding reconstruction and cross-modal alignment objectives. Once trained,
the Gaussian Process model generates uncertainty-aware probabilistic
embeddings. Evaluation shows that GroVE achieves state-of-the-art uncertainty
calibration across multiple downstream tasks, including cross-modal retrieval,
visual question answering, and active learning.

</details>

### [195] [PaniCar: Securing the Perception of Advanced Driving Assistance Systems Against Emergency Vehicle Lighting](https://arxiv.org/abs/2505.05183)
*Elad Feldman,Jacob Shams,Dudi Biton,Alfred Chen,Shaoyuan Xie,Satoru Koda,Yisroel Mirsky,Asaf Shabtai,Yuval Elovici,Ben Nassi*

Main category: cs.CV

TLDR: 研究发现自动驾驶汽车在紧急车辆灯光照射下，物体检测性能下降，提出了一种名为Caracetamol的框架以提升检测稳定性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车在紧急车辆灯光照射下可能无法检测到附近物体，存在安全隐患。

Method: 评估了7种商用ADAS系统、4种物体检测器和14种紧急车辆灯光模式，并提出了Caracetamol框架。

Result: Caracetamol提升了YOLOv3和Faster RCNN的检测置信度，并能在30-50 FPS下实时运行。

Conclusion: Caracetamol能有效缓解紧急车辆灯光对物体检测的负面影响，提升自动驾驶安全性。

Abstract: The safety of autonomous cars has come under scrutiny in recent years,
especially after 16 documented incidents involving Teslas (with autopilot
engaged) crashing into parked emergency vehicles (police cars, ambulances, and
firetrucks). While previous studies have revealed that strong light sources
often introduce flare artifacts in the captured image, which degrade the image
quality, the impact of flare on object detection performance remains unclear.
In this research, we unveil PaniCar, a digital phenomenon that causes an object
detector's confidence score to fluctuate below detection thresholds when
exposed to activated emergency vehicle lighting. This vulnerability poses a
significant safety risk, and can cause autonomous vehicles to fail to detect
objects near emergency vehicles. In addition, this vulnerability could be
exploited by adversaries to compromise the security of advanced driving
assistance systems (ADASs). We assess seven commercial ADASs (Tesla Model 3,
"manufacturer C", HP, Pelsee, AZDOME, Imagebon, Rexing), four object detectors
(YOLO, SSD, RetinaNet, Faster R-CNN), and 14 patterns of emergency vehicle
lighting to understand the influence of various technical and environmental
factors. We also evaluate four SOTA flare removal methods and show that their
performance and latency are insufficient for real-time driving constraints. To
mitigate this risk, we propose Caracetamol, a robust framework designed to
enhance the resilience of object detectors against the effects of activated
emergency vehicle lighting. Our evaluation shows that on YOLOv3 and Faster
RCNN, Caracetamol improves the models' average confidence of car detection by
0.20, the lower confidence bound by 0.33, and reduces the fluctuation range by
0.33. In addition, Caracetamol is capable of processing frames at a rate of
between 30-50 FPS, enabling real-time ADAS car detection.

</details>

### [196] [Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language Models](https://arxiv.org/abs/2505.05189)
*Wei Peng,Kang Liu,Jianchen Hu,Meng Zhang*

Main category: cs.CV

TLDR: Biomed-DPT是一种知识增强的双模态提示调优技术，通过结合文本和视觉提示，显著提升了生物医学图像分类任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前提示学习方法仅使用文本提示，忽略了生物医学图像的特殊结构（如复杂解剖结构和细微病理特征）。

Method: Biomed-DPT设计了双模态提示：文本提示包括临床模板和LLM驱动的领域适应提示，视觉提示引入零向量作为软提示以优化注意力权重。

Result: 在11个生物医学图像数据集上平均分类准确率达66.14%，在基类和新型类上分别达到78.06%和75.97%，优于CoOp方法。

Conclusion: Biomed-DPT通过双模态提示和知识蒸馏，显著提升了生物医学图像分类的性能。

Abstract: Prompt learning is one of the most effective paradigms for adapting
pre-trained vision-language models (VLMs) to the biomedical image
classification tasks in few shot scenarios. However, most of the current prompt
learning methods only used the text prompts and ignored the particular
structures (such as the complex anatomical structures and subtle pathological
features) in the biomedical images. In this work, we propose Biomed-DPT, a
knowledge-enhanced dual modality prompt tuning technique. In designing the text
prompt, Biomed-DPT constructs a dual prompt including the template-driven
clinical prompts and the large language model (LLM)-driven domain-adapted
prompts, then extracts the clinical knowledge from the domain-adapted prompts
through the knowledge distillation technique. In designing the vision prompt,
Biomed-DPT introduces the zero vector as a soft prompt to leverage attention
re-weighting so that the focus on non-diagnostic regions and the recognition of
non-critical pathological features are avoided. Biomed-DPT achieves an average
classification accuracy of 66.14\% across 11 biomedical image datasets covering
9 modalities and 10 organs, with performance reaching 78.06\% in base classes
and 75.97\% in novel classes, surpassing the Context Optimization (CoOp) method
by 6.20\%, 3.78\%, and 8.04\%, respectively. Our code are available at
\underline{https://github.com/Kanyooo/Biomed-DPT}.

</details>

### [197] [EAM: Enhancing Anything with Diffusion Transformers for Blind Super-Resolution](https://arxiv.org/abs/2505.05209)
*Haizhen Xie,Kunpeng Du,Qiangyu Yan,Sen Lu,Jianhong Han,Hanting Chen,Hailin Hu,Jie Hu*

Main category: cs.CV

TLDR: EAM是一种新型盲超分辨率方法，利用Diffusion Transformers（DiT）和创新的Ψ-DiT块，结合多模态提示生成策略，显著提升了图像恢复性能。


<details>
  <summary>Details</summary>
Motivation: 利用预训练的文本到图像扩散模型（T2I）指导盲超分辨率（BSR），并通过DiT替代传统U-Net架构以提升性能。

Method: 提出EAM方法，结合Ψ-DiT块、渐进式掩码图像建模策略和主题感知提示生成策略，优化T2I模型的先验知识利用。

Result: EAM在多个数据集上取得最先进成果，定量指标和视觉质量均优于现有方法。

Conclusion: EAM通过DiT和多模态策略显著提升了BSR任务的性能，同时降低了训练成本。

Abstract: Utilizing pre-trained Text-to-Image (T2I) diffusion models to guide Blind
Super-Resolution (BSR) has become a predominant approach in the field. While
T2I models have traditionally relied on U-Net architectures, recent
advancements have demonstrated that Diffusion Transformers (DiT) achieve
significantly higher performance in this domain. In this work, we introduce
Enhancing Anything Model (EAM), a novel BSR method that leverages DiT and
outperforms previous U-Net-based approaches. We introduce a novel block,
$\Psi$-DiT, which effectively guides the DiT to enhance image restoration. This
block employs a low-resolution latent as a separable flow injection control,
forming a triple-flow architecture that effectively leverages the prior
knowledge embedded in the pre-trained DiT. To fully exploit the prior guidance
capabilities of T2I models and enhance their generalization in BSR, we
introduce a progressive Masked Image Modeling strategy, which also reduces
training costs. Additionally, we propose a subject-aware prompt generation
strategy that employs a robust multi-modal model in an in-context learning
framework. This strategy automatically identifies key image areas, provides
detailed descriptions, and optimizes the utilization of T2I diffusion priors.
Our experiments demonstrate that EAM achieves state-of-the-art results across
multiple datasets, outperforming existing methods in both quantitative metrics
and visual quality.

</details>

### [198] [HQC-NBV: A Hybrid Quantum-Classical View Planning Approach](https://arxiv.org/abs/2505.05212)
*Xiaotong Yu,Chang Wen Chen*

Main category: cs.CV

TLDR: HQC-NBV是一种混合量子-经典框架，用于高效视图规划，通过量子特性提升探索效率，比经典方法高49.2%。


<details>
  <summary>Details</summary>
Motivation: 解决传统视图规划方法在复杂场景中计算可扩展性和解决方案最优性的不足。

Method: 提出基于哈密顿量公式和参数中心变分ansatz的混合量子-经典框架，利用双向交替纠缠模式捕捉参数层次依赖。

Result: 实验显示量子组件显著提升性能，探索效率比经典方法高49.2%。

Conclusion: 该研究为量子计算在机器人感知系统中的集成提供了突破性进展，为机器人视觉任务提供了新范式。

Abstract: Efficient view planning is a fundamental challenge in computer vision and
robotic perception, critical for tasks ranging from search and rescue
operations to autonomous navigation. While classical approaches, including
sampling-based and deterministic methods, have shown promise in planning camera
viewpoints for scene exploration, they often struggle with computational
scalability and solution optimality in complex settings. This study introduces
HQC-NBV, a hybrid quantum-classical framework for view planning that leverages
quantum properties to efficiently explore the parameter space while maintaining
robustness and scalability. We propose a specific Hamiltonian formulation with
multi-component cost terms and a parameter-centric variational ansatz with
bidirectional alternating entanglement patterns that capture the hierarchical
dependencies between viewpoint parameters. Comprehensive experiments
demonstrate that quantum-specific components provide measurable performance
advantages. Compared to the classical methods, our approach achieves up to
49.2% higher exploration efficiency across diverse environments. Our analysis
of entanglement architecture and coherence-preserving terms provides insights
into the mechanisms of quantum advantage in robotic exploration tasks. This
work represents a significant advancement in integrating quantum computing into
robotic perception systems, offering a paradigm-shifting solution for various
robot vision tasks.

</details>

### [199] [Diffusion Model Quantization: A Review](https://arxiv.org/abs/2505.05215)
*Qian Zeng,Chenggong Hu,Mingli Song,Jie Song*

Main category: cs.CV

TLDR: 本文综述了扩散模型量化的最新进展，分析了当前技术挑战、分类方法及量化效果，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 为了在资源受限的边缘设备上高效部署扩散模型，量化技术成为关键。本文旨在总结和分析该领域的最新进展。

Method: 通过分类和评估现有量化技术，结合定性和定量分析，包括视觉和轨迹检查，对扩散模型量化进行全面研究。

Result: 量化技术在扩散模型中表现出显著效果，但存在误差影响。本文提供了详细的评估和比较结果。

Conclusion: 未来研究可探索更高效的量化方法，以优化生成模型在实际应用中的性能。

Abstract: Recent success of large text-to-image models has empirically underscored the
exceptional performance of diffusion models in generative tasks. To facilitate
their efficient deployment on resource-constrained edge devices, model
quantization has emerged as a pivotal technique for both compression and
acceleration. This survey offers a thorough review of the latest advancements
in diffusion model quantization, encapsulating and analyzing the current state
of the art in this rapidly advancing domain. First, we provide an overview of
the key challenges encountered in the quantization of diffusion models,
including those based on U-Net architectures and Diffusion Transformers (DiT).
We then present a comprehensive taxonomy of prevalent quantization techniques,
engaging in an in-depth discussion of their underlying principles.
Subsequently, we perform a meticulous analysis of representative diffusion
model quantization schemes from both qualitative and quantitative perspectives.
From a quantitative standpoint, we rigorously benchmark a variety of methods
using widely recognized datasets, delivering an extensive evaluation of the
most recent and impactful research in the field. From a qualitative standpoint,
we categorize and synthesize the effects of quantization errors, elucidating
these impacts through both visual analysis and trajectory examination. In
conclusion, we outline prospective avenues for future research, proposing novel
directions for the quantization of generative models in practical applications.
The list of related papers, corresponding codes, pre-trained models and
comparison results are publicly available at the survey project homepage
https://github.com/TaylorJocelyn/Diffusion-Model-Quantization.

</details>

### [200] [Does CLIP perceive art the same way we do?](https://arxiv.org/abs/2505.05229)
*Andrea Asperti,Leonardo Dessì,Maria Chiara Tonetti,Nico Wu*

Main category: cs.CV

TLDR: 研究探讨CLIP模型在理解艺术作品（包括人类创作和AI生成图像）时与人类视觉感知的异同，评估其在内容、风格等多维度的表现，并讨论其在生成式任务中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 探索CLIP模型是否能够像人类一样理解和解释艺术作品，尤其是在高层次的语义和风格信息提取方面。

Method: 通过设计针对性任务，比较CLIP的响应与人类标注和专家基准，评估其在内容、场景理解、艺术风格等维度的表现。

Result: 揭示了CLIP在视觉表征上的优势和局限，特别是在美学线索和艺术意图方面的表现。

Conclusion: 强调了多模态系统在创意领域应用时需更强的可解释性，尤其是在涉及主观性和细微差别的场景中。

Abstract: CLIP has emerged as a powerful multimodal model capable of connecting images
and text through joint embeddings, but to what extent does it "see" the same
way humans do - especially when interpreting artworks? In this paper, we
investigate CLIP's ability to extract high-level semantic and stylistic
information from paintings, including both human-created and AI-generated
imagery. We evaluate its perception across multiple dimensions: content, scene
understanding, artistic style, historical period, and the presence of visual
deformations or artifacts. By designing targeted probing tasks and comparing
CLIP's responses to human annotations and expert benchmarks, we explore its
alignment with human perceptual and contextual understanding. Our findings
reveal both strengths and limitations in CLIP's visual representations,
particularly in relation to aesthetic cues and artistic intent. We further
discuss the implications of these insights for using CLIP as a guidance
mechanism during generative processes, such as style transfer or prompt-based
image synthesis. Our work highlights the need for deeper interpretability in
multimodal systems, especially when applied to creative domains where nuance
and subjectivity play a central role.

</details>

### [201] [PADriver: Towards Personalized Autonomous Driving](https://arxiv.org/abs/2505.05240)
*Genghua Kou,Fan Jia,Weixin Mao,Yingfei Liu,Yucheng Zhao,Ziheng Zhang,Osamu Yoshie,Tiancai Wang,Ying Li,Xiangyu Zhang*

Main category: cs.CV

TLDR: PADriver是一个基于多模态大语言模型的个性化自动驾驶框架，通过闭环基准测试PAD-Highway验证其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够结合个性化文本提示和实时场景理解的自动驾驶系统，以提升驾驶决策的安全性和个性化。

Method: 利用多模态大语言模型处理流式视频帧和个性化文本提示，进行场景理解、危险等级估计和动作决策。

Result: 在PAD-Highway基准测试中，PADriver在多种评价指标上优于现有方法，并支持多种驾驶模式。

Conclusion: PADriver通过闭环框架和个性化提示实现了高效且安全的自动驾驶决策，具有广泛的应用潜力。

Abstract: In this paper, we propose PADriver, a novel closed-loop framework for
personalized autonomous driving (PAD). Built upon Multi-modal Large Language
Model (MLLM), PADriver takes streaming frames and personalized textual prompts
as inputs. It autoaggressively performs scene understanding, danger level
estimation and action decision. The predicted danger level reflects the risk of
the potential action and provides an explicit reference for the final action,
which corresponds to the preset personalized prompt. Moreover, we construct a
closed-loop benchmark named PAD-Highway based on Highway-Env simulator to
comprehensively evaluate the decision performance under traffic rules. The
dataset contains 250 hours videos with high-quality annotation to facilitate
the development of PAD behavior analysis. Experimental results on the
constructed benchmark show that PADriver outperforms state-of-the-art
approaches on different evaluation metrics, and enables various driving modes.

</details>

### [202] [PlaceIt3D: Language-Guided Object Placement in Real 3D Scenes](https://arxiv.org/abs/2505.05288)
*Ahmed Abdelreheem,Filippo Aleotti,Jamie Watson,Zawar Qureshi,Abdelrahman Eldesokey,Peter Wonka,Gabriel Brostow,Sara Vicente,Guillermo Garcia-Hernando*

Main category: cs.CV

TLDR: 论文提出了一种新任务：语言引导的3D场景物体放置，并建立了相关基准和数据集。


<details>
  <summary>Details</summary>
Motivation: 解决3D场景中语言引导物体放置的模糊性和几何关系推理问题。

Method: 提出了新的基准、评估协议、数据集和首个非平凡基线方法。

Result: 建立了任务基准和数据集，并提供了初步方法。

Conclusion: 该任务和基准有望成为评估通用3D LLM模型的标准之一。

Abstract: We introduce the novel task of Language-Guided Object Placement in Real 3D
Scenes. Our model is given a 3D scene's point cloud, a 3D asset, and a textual
prompt broadly describing where the 3D asset should be placed. The task here is
to find a valid placement for the 3D asset that respects the prompt. Compared
with other language-guided localization tasks in 3D scenes such as grounding,
this task has specific challenges: it is ambiguous because it has multiple
valid solutions, and it requires reasoning about 3D geometric relationships and
free space. We inaugurate this task by proposing a new benchmark and evaluation
protocol. We also introduce a new dataset for training 3D LLMs on this task, as
well as the first method to serve as a non-trivial baseline. We believe that
this challenging task and our new benchmark could become part of the suite of
benchmarks used to evaluate and compare generalist 3D LLM models.

</details>

### [203] [PRE-Mamba: A 4D State Space Model for Ultra-High-Frequent Event Camera Deraining](https://arxiv.org/abs/2505.05307)
*Ciyu Ruan,Ruishan Guo,Zihang Gong,Jingao Xu,Wenhan Yang,Xinlei Chen*

Main category: cs.CV

TLDR: PRE-Mamba是一种基于点的事件相机去雨框架，通过4D事件云表示和时空解耦融合模块，结合多尺度状态空间模型，高效去除雨天噪声。


<details>
  <summary>Details</summary>
Motivation: 现有事件相机去雨方法在时间精度、去雨效果和计算效率之间存在权衡，需改进。

Method: 提出4D事件云表示、时空解耦融合模块（STDF）和多尺度状态空间模型（MS3M），结合频域正则化。

Result: 在EventRain-27K数据集上表现优异（SR 0.95，NR 0.91，0.4s/M事件），参数仅0.26M。

Conclusion: PRE-Mamba在多种雨强、视角及雪天条件下泛化能力强，性能优越。

Abstract: Event cameras excel in high temporal resolution and dynamic range but suffer
from dense noise in rainy conditions. Existing event deraining methods face
trade-offs between temporal precision, deraining effectiveness, and
computational efficiency. In this paper, we propose PRE-Mamba, a novel
point-based event camera deraining framework that fully exploits the
spatiotemporal characteristics of raw event and rain. Our framework introduces
a 4D event cloud representation that integrates dual temporal scales to
preserve high temporal precision, a Spatio-Temporal Decoupling and Fusion
module (STDF) that enhances deraining capability by enabling shallow decoupling
and interaction of temporal and spatial information, and a Multi-Scale State
Space Model (MS3M) that captures deeper rain dynamics across dual-temporal and
multi-spatial scales with linear computational complexity. Enhanced by
frequency-domain regularization, PRE-Mamba achieves superior performance (0.95
SR, 0.91 NR, and 0.4s/M events) with only 0.26M parameters on EventRain-27K, a
comprehensive dataset with labeled synthetic and real-world sequences.
Moreover, our method generalizes well across varying rain intensities,
viewpoints, and even snowy conditions.

</details>

### [204] [Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects](https://arxiv.org/abs/2505.05318)
*Agnese Chiatti,Sara Bernardini,Lara Shibelski Godoy Piccolo,Viola Schiaffonati,Matteo Matteucci*

Main category: cs.CV

TLDR: 本文综述了用户与视觉语言模型（VLM）交互中的信任动态，提出多学科分类法，并基于文献和用户研讨会提出未来研究的初步要求。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（VLM）的广泛应用，需要研究用户对其的信任动态，以保护用户并指导其使用。

Method: 通过多学科分类法（认知科学能力、协作模式、代理行为）综述相关研究，并结合用户研讨会的发现。

Result: 总结了信任动态的关键因素，并提出了未来VLM信任研究的初步要求。

Conclusion: 未来研究应关注多学科视角，以更好地理解和设计用户与VLM的信任关系。

Abstract: The rapid adoption of Vision Language Models (VLMs), pre-trained on large
image-text and video-text datasets, calls for protecting and informing users
about when to trust these systems. This survey reviews studies on trust
dynamics in user-VLM interactions, through a multi-disciplinary taxonomy
encompassing different cognitive science capabilities, collaboration modes, and
agent behaviours. Literature insights and findings from a workshop with
prospective VLM users inform preliminary requirements for future VLM trust
studies.

</details>

### [205] [Feature-Augmented Deep Networks for Multiscale Building Segmentation in High-Resolution UAV and Satellite Imagery](https://arxiv.org/abs/2505.05321)
*Chintan B. Maniyar,Minakshi Kumar,Gengchen Mai*

Main category: cs.CV

TLDR: 该研究提出了一种基于深度学习的多尺度建筑分割框架，结合多分辨率RGB图像和特征增强输入，通过优化的训练策略显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 高分辨率RGB图像中建筑分割的挑战包括光谱相似性、阴影和不规则几何形状，需要更有效的解决方案。

Method: 使用多传感器数据集，引入PCA、VDVI、MBI和Sobel边缘滤波器等特征增强输入，采用Res-U-Net架构，并结合层冻结、循环学习率和SuperConvergence等训练策略。

Result: 在WorldView-3图像上测试，模型总体准确率为96.5%，F1分数为0.86，IoU为0.80，优于现有RGB基准。

Conclusion: 结合多分辨率图像、特征增强和优化训练策略，能够实现稳健的遥感建筑分割。

Abstract: Accurate building segmentation from high-resolution RGB imagery remains
challenging due to spectral similarity with non-building features, shadows, and
irregular building geometries. In this study, we present a comprehensive deep
learning framework for multiscale building segmentation using RGB aerial and
satellite imagery with spatial resolutions ranging from 0.4m to 2.7m. We curate
a diverse, multi-sensor dataset and introduce feature-augmented inputs by
deriving secondary representations including Principal Component Analysis
(PCA), Visible Difference Vegetation Index (VDVI), Morphological Building Index
(MBI), and Sobel edge filters from RGB channels. These features guide a
Res-U-Net architecture in learning complex spatial patterns more effectively.
We also propose training policies incorporating layer freezing, cyclical
learning rates, and SuperConvergence to reduce training time and resource
usage. Evaluated on a held-out WorldView-3 image, our model achieves an overall
accuracy of 96.5%, an F1-score of 0.86, and an Intersection over Union (IoU) of
0.80, outperforming existing RGB-based benchmarks. This study demonstrates the
effectiveness of combining multi-resolution imagery, feature augmentation, and
optimized training strategies for robust building segmentation in remote
sensing applications.

</details>

### [206] [Aesthetics Without Semantics](https://arxiv.org/abs/2505.05331)
*C. Alejandro Parraga,Olivier Penacchio,Marcos Muňoz Gonzalez,Bogdan Raducanu,Xavier Otazu*

Main category: cs.CV

TLDR: 论文通过创建最小语义内容（MSC）数据库，解决了现有美学研究中偏向美丽图像的偏差问题，并展示了丑陋图像如何影响美学评价与图像特征的关系。


<details>
  <summary>Details</summary>
Motivation: 美学判断涉及复杂的感知和认知因素，现有数据库偏向美丽图像，限制了美学响应的研究和预测。

Method: 创建MSC数据库，包含10,426张图像，每张由100名观察者评估，并利用图像指标分析美丽与丑陋图像对美学评价的影响。

Result: 研究发现，增加丑陋图像可以改变甚至逆转图像特征与美学评价之间的关系。

Conclusion: 现有美学研究可能因美学值范围有限而放大、低估或遗漏重要效果。

Abstract: While it is easy for human observers to judge an image as beautiful or ugly,
aesthetic decisions result from a combination of entangled perceptual and
cognitive (semantic) factors, making the understanding of aesthetic judgements
particularly challenging from a scientific point of view. Furthermore, our
research shows a prevailing bias in current databases, which include mostly
beautiful images, further complicating the study and prediction of aesthetic
responses. We address these limitations by creating a database of images with
minimal semantic content and devising, and next exploiting, a method to
generate images on the ugly side of aesthetic valuations. The resulting Minimum
Semantic Content (MSC) database consists of a large and balanced collection of
10,426 images, each evaluated by 100 observers. We next use established image
metrics to demonstrate how augmenting an image set biased towards beautiful
images with ugly images can modify, or even invert, an observed relationship
between image features and aesthetics valuation. Taken together, our study
reveals that works in empirical aesthetics attempting to link image content and
aesthetic judgements may magnify, underestimate, or simply miss interesting
effects due to a limitation of the range of aesthetic values they consider.

</details>

### [207] [Progressive Inertial Poser: Progressive Real-Time Kinematic Chain Estimation for 3D Full-Body Pose from Three IMU Sensors](https://arxiv.org/abs/2505.05336)
*Zunjie Zhu,Yan Zhao,Yihan Hu,Guoxiang Wang,Hai Qiu,Bolun Zheng,Chenggang Yan,Feng Xu*

Main category: cs.CV

TLDR: 提出了一种仅使用头戴和手腕三个IMU传感器的全身姿态估计方法ProgIP，结合神经网络和人体动力学模型，性能优于同类方法。


<details>
  <summary>Details</summary>
Motivation: 提高虚拟现实中全身姿态估计的实用性，减少硬件复杂度。

Method: 结合Transformer Encoder和双向LSTM的编码器，以及基于MLP的解码器，分阶段渐进式估计姿态。

Result: 在多个公开数据集上表现优于同类方法，与使用六个IMU传感器的方法相当。

Conclusion: ProgIP方法在减少传感器数量的同时，实现了高效的全身姿态估计。

Abstract: The motion capture system that supports full-body virtual representation is
of key significance for virtual reality. Compared to vision-based systems,
full-body pose estimation from sparse tracking signals is not limited by
environmental conditions or recording range. However, previous works either
face the challenge of wearing additional sensors on the pelvis and lower-body
or rely on external visual sensors to obtain global positions of key joints. To
improve the practicality of the technology for virtual reality applications, we
estimate full-body poses using only inertial data obtained from three Inertial
Measurement Unit (IMU) sensors worn on the head and wrists, thereby reducing
the complexity of the hardware system. In this work, we propose a method called
Progressive Inertial Poser (ProgIP) for human pose estimation, which combines
neural network estimation with a human dynamics model, considers the
hierarchical structure of the kinematic chain, and employs a multi-stage
progressive network estimation with increased depth to reconstruct full-body
motion in real time. The encoder combines Transformer Encoder and bidirectional
LSTM (TE-biLSTM) to flexibly capture the temporal dependencies of the inertial
sequence, while the decoder based on multi-layer perceptrons (MLPs) transforms
high-dimensional features and accurately projects them onto Skinned
Multi-Person Linear (SMPL) model parameters. Quantitative and qualitative
experimental results on multiple public datasets show that our method
outperforms state-of-the-art methods with the same inputs, and is comparable to
recent works using six IMU sensors.

</details>

### [208] [Hearing and Seeing Through CLIP: A Framework for Self-Supervised Sound Source Localization](https://arxiv.org/abs/2505.05343)
*Sooyoung Park,Arda Senocak,Joon Son Chung*

Main category: cs.CV

TLDR: 本文提出了一种基于CLIP的自监督方法，用于声音源定位，无需显式文本输入，并通过对比音频-视觉对齐目标实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 探索如何将CLIP的成功扩展到声音源定位任务，同时避免依赖显式文本输入。

Method: 提出一个框架，将音频映射为与CLIP文本编码器兼容的令牌，生成音频驱动的嵌入，并通过对比音频-视觉对齐目标提取视觉特征。

Result: 实验表明，该方法在五种任务中均优于现有方法，并在零样本设置下表现出强泛化能力。

Conclusion: 预训练多模态基础模型的对齐知识能够生成更完整和紧凑的声音源定位，且LLM引导的扩展进一步增强了模型性能。

Abstract: Large-scale vision-language models demonstrate strong multimodal alignment
and generalization across diverse tasks. Among them, CLIP stands out as one of
the most successful approaches. In this work, we extend the application of CLIP
to sound source localization, proposing a self-supervised method operates
without explicit text input. We introduce a framework that maps audios into
tokens compatible with CLIP's text encoder, producing audio-driven embeddings.
These embeddings are used to generate sounding region masks, from which visual
features are extracted and aligned with the audio embeddings through a
contrastive audio-visual correspondence objective. Our findings show that
alignment knowledge of pre-trained multimodal foundation model enables our
method to generate more complete and compact localization for sounding objects.
We further propose an LLM-guided extension that distills object-aware
audio-visual scene understanding into the model during training to enhance
alignment. Extensive experiments across five diverse tasks demonstrate that our
method, in all variants, outperforms state-of-the-art approaches and achieves
strong generalization in zero-shot settings.

</details>

### [209] [TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and Generation](https://arxiv.org/abs/2505.05422)
*Haokun Lin,Teng Wang,Yixiao Ge,Yuying Ge,Zhichao Lu,Ying Wei,Qingfu Zhang,Zhenan Sun,Ying Shan*

Main category: cs.CV

TLDR: TokLIP是一种视觉分词器，通过语义化向量量化（VQ）标记并结合CLIP级语义，解决了多模态统一中的高训练计算开销和低理解性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如Chameleon和Emu3）在多模态统一中存在高计算开销和低语义理解的问题，TokLIP旨在通过改进标记化方法解决这些问题。

Method: TokLIP结合低层离散VQ分词器与ViT标记编码器，分离理解和生成目标，无需定制量化操作。

Result: TokLIP在数据效率和语义理解上表现优异，同时提升生成能力，适用于自回归Transformer的理解和生成任务。

Conclusion: TokLIP通过改进标记化方法，显著提升了多模态任务的性能和效率。

Abstract: Pioneering token-based works such as Chameleon and Emu3 have established a
foundation for multimodal unification but face challenges of high training
computational overhead and limited comprehension performance due to a lack of
high-level semantics. In this paper, we introduce TokLIP, a visual tokenizer
that enhances comprehension by semanticizing vector-quantized (VQ) tokens and
incorporating CLIP-level semantics while enabling end-to-end multimodal
autoregressive training with standard VQ tokens. TokLIP integrates a low-level
discrete VQ tokenizer with a ViT-based token encoder to capture high-level
continuous semantics. Unlike previous approaches (e.g., VILA-U) that discretize
high-level features, TokLIP disentangles training objectives for comprehension
and generation, allowing the direct application of advanced VQ tokenizers
without the need for tailored quantization operations. Our empirical results
demonstrate that TokLIP achieves exceptional data efficiency, empowering visual
tokens with high-level semantic understanding while enhancing low-level
generative capacity, making it well-suited for autoregressive Transformers in
both comprehension and generation tasks. The code and models are available at
https://github.com/TencentARC/TokLIP.

</details>

### [210] [Joint Super-Resolution and Segmentation for 1-m Impervious Surface Area Mapping in China's Yangtze River Economic Belt](https://arxiv.org/abs/2505.05367)
*Jie Deng,Danfeng Hong,Chenyu Li,Naoto Yokoya*

Main category: cs.CV

TLDR: 提出了一种名为JointSeg的新框架，结合超分辨率和分割技术，直接从Sentinel-2影像生成1米分辨率的地表不透水面（ISA）地图。该方法在多模态跨分辨率输入上训练，优于传统方法，并在复杂地形和城乡区域表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统方法在生成高分辨率ISA地图时成本高且难以扩展，而JointSeg提供了一种经济高效的替代方案，同时解决了复杂地形和城乡区域的分类挑战。

Method: JointSeg框架通过逐步从10米提升到1米分辨率，保留空间纹理，并通过跨尺度特征融合确保高分类精度。

Result: 生成的ISA-1产品覆盖220万平方公里，F1分数达85.71%，优于其他基准产品，并在不同地形中表现稳健。

Conclusion: JointSeg不仅显著提升了ISA地图的精度和适用性，还通过时间序列分析揭示了区域城市化动态。

Abstract: We propose a novel joint framework by integrating super-resolution and
segmentation, called JointSeg, which enables the generation of 1-meter ISA maps
directly from freely available Sentinel-2 imagery. JointSeg was trained on
multimodal cross-resolution inputs, offering a scalable and affordable
alternative to traditional approaches. This synergistic design enables gradual
resolution enhancement from 10m to 1m while preserving fine-grained spatial
textures, and ensures high classification fidelity through effective
cross-scale feature fusion. This method has been successfully applied to the
Yangtze River Economic Belt (YREB), a region characterized by complex
urban-rural patterns and diverse topography. As a result, a comprehensive ISA
mapping product for 2021, referred to as ISA-1, was generated, covering an area
of over 2.2 million square kilometers. Quantitative comparisons against the 10m
ESA WorldCover and other benchmark products reveal that ISA-1 achieves an
F1-score of 85.71%, outperforming bilinear-interpolation-based segmentation by
9.5%, and surpassing other ISA datasets by 21.43%-61.07%. In densely urbanized
areas (e.g., Suzhou, Nanjing), ISA-1 reduces ISA overestimation through
improved discrimination of green spaces and water bodies. Conversely, in
mountainous regions (e.g., Ganzi, Zhaotong), it identifies significantly more
ISA due to its enhanced ability to detect fragmented anthropogenic features
such as rural roads and sparse settlements, demonstrating its robustness across
diverse landscapes. Moreover, we present biennial ISA maps from 2017 to 2023,
capturing spatiotemporal urbanization dynamics across representative cities.
The results highlight distinct regional growth patterns: rapid expansion in
upstream cities, moderate growth in midstream regions, and saturation in
downstream metropolitan areas.

</details>

### [211] [Adaptive Markup Language Generation for Contextually-Grounded Visual Document Understanding](https://arxiv.org/abs/2505.05446)
*Han Xiao,Yina Xie,Guanxin Tan,Yinghao Chen,Rui Hu,Ke Wang,Aojun Zhou,Hao Li,Hao Shao,Xudong Lu,Peng Gao,Yafei Wen,Xiaoxin Chen,Shuai Ren,Hongsheng Li*

Main category: cs.CV

TLDR: 提出了一种利用标记语言生成结构化文档表示的创新方法，并引入两个细粒度数据集，显著提升了视觉文档理解能力。


<details>
  <summary>Details</summary>
Motivation: 视觉文档理解领域因缺乏详细上下文信息而存在挑战，现有数据集难以支持稳健的理解。

Method: 采用自适应生成标记语言（如Markdown、JSON等）的管道，构建结构化文档表示，并引入DocMark-Pile和DocMark-Instruct两个数据集。

Result: 模型在多个视觉文档理解基准测试中显著优于现有技术，提升了复杂视觉场景下的推理和理解能力。

Conclusion: 提出的方法和数据集有效解决了视觉文档理解的挑战，推动了该领域的进展。

Abstract: Visual Document Understanding has become essential with the increase of
text-rich visual content. This field poses significant challenges due to the
need for effective integration of visual perception and textual comprehension,
particularly across diverse document types with complex layouts. Moreover,
existing fine-tuning datasets for this domain often fall short in providing the
detailed contextual information for robust understanding, leading to
hallucinations and limited comprehension of spatial relationships among visual
elements. To address these challenges, we propose an innovative pipeline that
utilizes adaptive generation of markup languages, such as Markdown, JSON, HTML,
and TiKZ, to build highly structured document representations and deliver
contextually-grounded responses. We introduce two fine-grained structured
datasets: DocMark-Pile, comprising approximately 3.8M pretraining data pairs
for document parsing, and DocMark-Instruct, featuring 624k fine-tuning data
annotations for grounded instruction following. Extensive experiments
demonstrate that our proposed model significantly outperforms existing
state-of-theart MLLMs across a range of visual document understanding
benchmarks, facilitating advanced reasoning and comprehension capabilities in
complex visual scenarios. Our code and models are released at https://github.
com/Euphoria16/DocMark.

</details>

### [212] [Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks](https://arxiv.org/abs/2505.05375)
*Kejie Zhao,Wenjia Hua,Aiersi Tuerhong,Luziwei Leng,Yuxin Ma,Qinghua Guo*

Main category: cs.CV

TLDR: 论文提出了一种适用于脉冲神经网络（SNNs）的低功耗在线测试时间适应（OTTA）框架，称为阈值调制（TM），通过动态调整神经元阈值提升模型在分布偏移下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有OTTA方法主要针对传统人工神经网络设计，不适用于SNNs，且SNNs在边缘设备部署后适应分布偏移的能力成为关键挑战。

Method: 提出TM方法，通过神经元动力学启发的归一化动态调整神经元阈值，更适配神经形态硬件。

Result: 在基准数据集上验证了TM方法的有效性，提升了SNNs在分布偏移下的鲁棒性，同时保持低计算成本。

Conclusion: TM为SNNs的在线测试时间适应提供了实用解决方案，并为未来神经形态芯片设计提供了启发。

Abstract: Recently, spiking neural networks (SNNs), deployed on neuromorphic chips,
provide highly efficient solutions on edge devices in different scenarios.
However, their ability to adapt to distribution shifts after deployment has
become a crucial challenge. Online test-time adaptation (OTTA) offers a
promising solution by enabling models to dynamically adjust to new data
distributions without requiring source data or labeled target samples.
Nevertheless, existing OTTA methods are largely designed for traditional
artificial neural networks and are not well-suited for SNNs. To address this
gap, we propose a low-power, neuromorphic chip-friendly online test-time
adaptation framework, aiming to enhance model generalization under distribution
shifts. The proposed approach is called Threshold Modulation (TM), which
dynamically adjusts the firing threshold through neuronal dynamics-inspired
normalization, being more compatible with neuromorphic hardware. Experimental
results on benchmark datasets demonstrate the effectiveness of this method in
improving the robustness of SNNs against distribution shifts while maintaining
low computational cost. The proposed method offers a practical solution for
online test-time adaptation of SNNs, providing inspiration for the design of
future neuromorphic chips. The demo code is available at
github.com/NneurotransmitterR/TM-OTTA-SNN.

</details>

### [213] [StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant](https://arxiv.org/abs/2505.05467)
*Haibo Wang,Bo Feng,Zhengfeng Lai,Mingze Xu,Shiyu Li,Weifeng Ge,Afshin Dehghan,Meng Cao,Ping Huang*

Main category: cs.CV

TLDR: StreamBridge是一个将离线Video-LLMs转换为支持流式处理的框架，解决了实时多轮理解和主动响应的问题。


<details>
  <summary>Details</summary>
Motivation: 现有模型在在线场景中存在多轮实时理解能力不足和缺乏主动响应机制的问题。

Method: 采用内存缓冲与轮衰减压缩策略支持长上下文多轮交互，并引入轻量级激活模型实现持续主动响应。

Result: StreamBridge显著提升了离线Video-LLMs的流式理解能力，优于GPT-4o和Gemini 1.5 Pro，同时在标准视频理解任务中表现优异。

Conclusion: StreamBridge为离线Video-LLMs提供了高效的流式处理能力，并在性能和适应性上表现出色。

Abstract: We present StreamBridge, a simple yet effective framework that seamlessly
transforms offline Video-LLMs into streaming-capable models. It addresses two
fundamental challenges in adapting existing models into online scenarios: (1)
limited capability for multi-turn real-time understanding, and (2) lack of
proactive response mechanisms. Specifically, StreamBridge incorporates (1) a
memory buffer combined with a round-decayed compression strategy, supporting
long-context multi-turn interactions, and (2) a decoupled, lightweight
activation model that can be effortlessly integrated into existing Video-LLMs,
enabling continuous proactive responses. To further support StreamBridge, we
construct Stream-IT, a large-scale dataset tailored for streaming video
understanding, featuring interleaved video-text sequences and diverse
instruction formats. Extensive experiments show that StreamBridge significantly
improves the streaming understanding capabilities of offline Video-LLMs across
various tasks, outperforming even proprietary models such as GPT-4o and Gemini
1.5 Pro. Simultaneously, it achieves competitive or superior performance on
standard video understanding benchmarks.

</details>

### [214] [GeomHair: Reconstruction of Hair Strands from Colorless 3D Scans](https://arxiv.org/abs/2505.05376)
*Rachmadio Noval Lazuardi,Artem Sevastopolsky,Egor Zakharov,Matthias Niessner,Vanessa Sklyarova*

Main category: cs.CV

TLDR: 提出了一种从无色3D扫描中直接重建头发丝的新方法，利用多模态头发方向提取，无需依赖颜色信息。


<details>
  <summary>Details</summary>
Motivation: 头发丝重建是计算机视觉和图形学中的基础问题，用于高保真数字头像合成、动画和AR/VR应用。现有方法依赖RGB捕捉，对环境敏感且难以提取复杂发型的导向丝方向。

Method: 通过扫描表面特征提取和神经2D线检测器估计头发方向，结合扩散先验和合成头发扫描数据集进行优化。

Result: 方法能准确重建简单和复杂发型，无需颜色信息。

Conclusion: 提出了Strands400数据集，促进进一步研究。

Abstract: We propose a novel method that reconstructs hair strands directly from
colorless 3D scans by leveraging multi-modal hair orientation extraction. Hair
strand reconstruction is a fundamental problem in computer vision and graphics
that can be used for high-fidelity digital avatar synthesis, animation, and
AR/VR applications. However, accurately recovering hair strands from raw scan
data remains challenging due to human hair's complex and fine-grained
structure. Existing methods typically rely on RGB captures, which can be
sensitive to the environment and can be a challenging domain for extracting the
orientation of guiding strands, especially in the case of challenging
hairstyles. To reconstruct the hair purely from the observed geometry, our
method finds sharp surface features directly on the scan and estimates strand
orientation through a neural 2D line detector applied to the renderings of scan
shading. Additionally, we incorporate a diffusion prior trained on a diverse
set of synthetic hair scans, refined with an improved noise schedule, and
adapted to the reconstructed contents via a scan-specific text prompt. We
demonstrate that this combination of supervision signals enables accurate
reconstruction of both simple and intricate hairstyles without relying on color
information. To facilitate further research, we introduce Strands400, the
largest publicly available dataset of hair strands with detailed surface
geometry extracted from real-world data, which contains reconstructed hair
strands from the scans of 400 subjects.

</details>

### [215] [EDmamba: A Simple yet Effective Event Denoising Method with State Space Model](https://arxiv.org/abs/2505.05391)
*Ciyu Ruan,Zihang Gong,Ruishan Guo,Jingao Xu,Xinlei Chen*

Main category: cs.CV

TLDR: 提出了一种基于状态空间模型（SSMs）的事件去噪框架，结合几何和极性感知特征提取，在高效性和准确性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 事件相机的高动态范围和低延迟特性使其在高速视觉中表现优异，但输出噪声问题需要高效去噪方法以保持其实时处理能力。现有方法在计算强度和鲁棒性之间存在矛盾。

Method: 采用4D事件云表示事件，包含粗粒度特征提取模块（CFE），以及空间Mamba（S-SSM）和时间Mamba（T-SSM）分别建模局部几何结构和全局时间动态。

Result: 方法在参数数量（88.89K）、推理时间（0.0685s/100K事件）和准确性（0.982）上均达到最优，比基于Transformer的方法快36倍且准确率高2.08%。

Conclusion: 提出的SSM框架在事件去噪中实现了高效与高精度的平衡，为实时高速视觉应用提供了可行解决方案。

Abstract: Event cameras excel in high-speed vision due to their high temporal
resolution, high dynamic range, and low power consumption. However, as dynamic
vision sensors, their output is inherently noisy, making efficient denoising
essential to preserve their ultra-low latency and real-time processing
capabilities. Existing event denoising methods struggle with a critical
dilemma: computationally intensive approaches compromise the sensor's
high-speed advantage, while lightweight methods often lack robustness across
varying noise levels. To address this, we propose a novel event denoising
framework based on State Space Models (SSMs). Our approach represents events as
4D event clouds and includes a Coarse Feature Extraction (CFE) module that
extracts embedding features from both geometric and polarity-aware subspaces.
The model is further composed of two essential components: A Spatial Mamba
(S-SSM) that models local geometric structures and a Temporal Mamba (T-SSM)
that captures global temporal dynamics, efficiently propagating spatiotemporal
features across events. Experiments demonstrate that our method achieves
state-of-the-art accuracy and efficiency, with 88.89K parameters, 0.0685s per
100K events inference time, and a 0.982 accuracy score, outperforming
Transformer-based methods by 2.08% in denoising accuracy and 36X faster.

</details>

### [216] [PillarMamba: Learning Local-Global Context for Roadside Point Cloud via Hybrid State Space Model](https://arxiv.org/abs/2505.05397)
*Zhang Zhang,Chao Sun,Chao Yue,Da Wen,Tianze Wang,Jianghao Leng*

Main category: cs.CV

TLDR: 本文提出了一种基于Cross-stage State-space Group (CSG)的框架PillarMamba，用于路边点云的3D物体检测，通过混合状态空间块(HSB)解决局部连接和历史关系遗忘问题，并在DAIR-V2X-I基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 路边点云的3D物体检测尚未被充分探索，而点云检测器的性能关键在于网络的感受野和场景上下文利用能力。Mamba模型因其高效的全局感受野成为新选择。

Method: 提出PillarMamba框架，结合CSG和HSB模块，通过跨阶段特征融合增强网络表达能力，同时利用局部卷积和残差注意力解决局部连接和历史记忆问题。

Result: 在DAIR-V2X-I基准测试中表现优于现有方法。

Conclusion: PillarMamba通过结合Mamba模型和局部-全局上下文处理，显著提升了路边点云检测的性能。

Abstract: Serving the Intelligent Transport System (ITS) and Vehicle-to-Everything
(V2X) tasks, roadside perception has received increasing attention in recent
years, as it can extend the perception range of connected vehicles and improve
traffic safety. However, roadside point cloud oriented 3D object detection has
not been effectively explored. To some extent, the key to the performance of a
point cloud detector lies in the receptive field of the network and the ability
to effectively utilize the scene context. The recent emergence of Mamba, based
on State Space Model (SSM), has shaken up the traditional convolution and
transformers that have long been the foundational building blocks, due to its
efficient global receptive field. In this work, we introduce Mamba to
pillar-based roadside point cloud perception and propose a framework based on
Cross-stage State-space Group (CSG), called PillarMamba. It enhances the
expressiveness of the network and achieves efficient computation through
cross-stage feature fusion. However, due to the limitations of scan directions,
state space model faces local connection disrupted and historical relationship
forgotten. To address this, we propose the Hybrid State-space Block (HSB) to
obtain the local-global context of roadside point cloud. Specifically, it
enhances neighborhood connections through local convolution and preserves
historical memory through residual attention. The proposed method outperforms
the state-of-the-art methods on the popular large scale roadside benchmark:
DAIR-V2X-I. The code will be released soon.

</details>

### [217] [SITE: towards Spatial Intelligence Thorough Evaluation](https://arxiv.org/abs/2505.05456)
*Wenqi Wang,Reuben Tan,Pengyue Zhu,Jianwei Yang,Zhengyuan Yang,Lijuan Wang,Andrey Kolobov,Jianfeng Gao,Boqing Gong*

Main category: cs.CV

TLDR: SITE是一个用于评估大型视觉语言模型空间智能的基准数据集，涵盖多种视觉模态和空间智能因素。实验显示领先模型在空间定向方面落后于人类专家，且空间推理能力与具身AI任务表现正相关。


<details>
  <summary>Details</summary>
Motivation: 空间智能（SI）在多个学科中至关重要，但目前缺乏标准化的评估方法。SITE旨在填补这一空白，提供全面的评估基准。

Method: 通过结合自下而上的31个现有数据集调查和自上而下的认知科学分类系统，设计了包含视图采集和动态场景的新任务类型。

Result: 实验表明，领先模型在空间定向等基本SI因素上表现不佳，且空间推理能力与具身AI任务表现呈正相关。

Conclusion: SITE为空间智能评估提供了标准化工具，揭示了当前模型的局限性，并强调了空间推理能力在AI任务中的重要性。

Abstract: Spatial intelligence (SI) represents a cognitive ability encompassing the
visualization, manipulation, and reasoning about spatial relationships,
underpinning disciplines from neuroscience to robotics. We introduce SITE, a
benchmark dataset towards SI Thorough Evaluation in a standardized format of
multi-choice visual question-answering, designed to assess large
vision-language models' spatial intelligence across diverse visual modalities
(single-image, multi-image, and video) and SI factors (figural to environmental
scales, spatial visualization and orientation, intrinsic and extrinsic, static
and dynamic). Our approach to curating the benchmark combines a bottom-up
survey about 31 existing datasets and a top-down strategy drawing upon three
classification systems in cognitive science, which prompt us to design two
novel types of tasks about view-taking and dynamic scenes. Extensive
experiments reveal that leading models fall behind human experts especially in
spatial orientation, a fundamental SI factor. Moreover, we demonstrate a
positive correlation between a model's spatial reasoning proficiency and its
performance on an embodied AI task.

</details>

### [218] [Generating Physically Stable and Buildable LEGO Designs from Text](https://arxiv.org/abs/2505.05469)
*Ava Pun,Kangle Deng,Ruixuan Liu,Deva Ramanan,Changliu Liu,Jun-Yan Zhu*

Main category: cs.CV

TLDR: LegoGPT是一种从文本提示生成物理稳定LEGO模型的创新方法，通过大规模数据集和语言模型实现，并结合物理验证提升稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决从文本生成物理稳定LEGO模型的挑战，填补现有技术的空白。

Method: 构建大规模稳定LEGO数据集，训练自回归语言模型，结合物理验证和回滚机制优化生成。

Result: 生成的LEGO模型稳定、多样且美观，支持手动和自动组装，并发布了数据集和代码。

Conclusion: LegoGPT为文本到LEGO模型生成提供了高效解决方案，具有实际应用潜力。

Abstract: We introduce LegoGPT, the first approach for generating physically stable
LEGO brick models from text prompts. To achieve this, we construct a
large-scale, physically stable dataset of LEGO designs, along with their
associated captions, and train an autoregressive large language model to
predict the next brick to add via next-token prediction. To improve the
stability of the resulting designs, we employ an efficient validity check and
physics-aware rollback during autoregressive inference, which prunes infeasible
token predictions using physics laws and assembly constraints. Our experiments
show that LegoGPT produces stable, diverse, and aesthetically pleasing LEGO
designs that align closely with the input text prompts. We also develop a
text-based LEGO texturing method to generate colored and textured designs. We
show that our designs can be assembled manually by humans and automatically by
robotic arms. We also release our new dataset, StableText2Lego, containing over
47,000 LEGO structures of over 28,000 unique 3D objects accompanied by detailed
captions, along with our code and models at the project website:
https://avalovelace1.github.io/LegoGPT/.

</details>

### [219] [Flow-GRPO: Training Flow Matching Models via Online RL](https://arxiv.org/abs/2505.05470)
*Jie Liu,Gongye Liu,Jiajun Liang,Yangguang Li,Jiaheng Liu,Xintao Wang,Pengfei Wan,Di Zhang,Wanli Ouyang*

Main category: cs.CV

TLDR: Flow-GRPO首次将在线强化学习（RL）融入流匹配模型，通过ODE-to-SDE转换和降噪减少策略提升采样效率和性能。


<details>
  <summary>Details</summary>
Motivation: 将强化学习引入流匹配模型，以提升生成任务的准确性和效率。

Method: 采用ODE-to-SDE转换和降噪减少策略，优化训练和采样过程。

Result: 在文本到图像任务中显著提升性能，如GenEval准确率从63%升至95%，文本渲染准确率从59%升至92%。

Conclusion: Flow-GRPO在提升生成任务性能的同时，保持图像质量和多样性，未出现奖励作弊现象。

Abstract: We propose Flow-GRPO, the first method integrating online reinforcement
learning (RL) into flow matching models. Our approach uses two key strategies:
(1) an ODE-to-SDE conversion that transforms a deterministic Ordinary
Differential Equation (ODE) into an equivalent Stochastic Differential Equation
(SDE) that matches the original model's marginal distribution at all timesteps,
enabling statistical sampling for RL exploration; and (2) a Denoising Reduction
strategy that reduces training denoising steps while retaining the original
inference timestep number, significantly improving sampling efficiency without
performance degradation. Empirically, Flow-GRPO is effective across multiple
text-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly
perfect object counts, spatial relations, and fine-grained attributes, boosting
GenEval accuracy from $63\%$ to $95\%$. In visual text rendering, its accuracy
improves from $59\%$ to $92\%$, significantly enhancing text generation.
Flow-GRPO also achieves substantial gains in human preference alignment.
Notably, little to no reward hacking occurred, meaning rewards did not increase
at the cost of image quality or diversity, and both remained stable in our
experiments.

</details>

### [220] [Mogao: An Omni Foundation Model for Interleaved Multi-Modal Generation](https://arxiv.org/abs/2505.05472)
*Chao Liao,Liyang Liu,Xun Wang,Zhengxiong Luo,Xinyu Zhang,Wenliang Zhao,Jie Wu,Liang Li,Zhi Tian,Weilin Huang*

Main category: cs.CV

TLDR: Mogao是一个统一框架，通过因果方法实现交错多模态生成，结合自回归和扩散模型的优势，支持文本和图像的任意交错序列处理。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型多限于单模态生成，Mogao旨在通过技术改进实现交错多模态生成，提升多模态理解和生成能力。

Method: 采用深度融合设计、双视觉编码器、交错旋转位置嵌入和多模态无分类器引导，结合大规模数据集训练策略。

Result: Mogao在多模态理解和文本到图像生成中达到SOTA，并能生成高质量的交错输出，具备零样本图像编辑和组合生成能力。

Conclusion: Mogao作为全能模态基础模型，为统一多模态系统的未来发展铺平了道路。

Abstract: Recent progress in unified models for image understanding and generation has
been impressive, yet most approaches remain limited to single-modal generation
conditioned on multiple modalities. In this paper, we present Mogao, a unified
framework that advances this paradigm by enabling interleaved multi-modal
generation through a causal approach. Mogao integrates a set of key technical
improvements in architecture design, including a deep-fusion design, dual
vision encoders, interleaved rotary position embeddings, and multi-modal
classifier-free guidance, which allow it to harness the strengths of both
autoregressive models for text generation and diffusion models for high-quality
image synthesis. These practical improvements also make Mogao particularly
effective to process interleaved sequences of text and images arbitrarily. To
further unlock the potential of unified models, we introduce an efficient
training strategy on a large-scale, in-house dataset specifically curated for
joint text and image generation. Extensive experiments show that Mogao not only
achieves state-of-the-art performance in multi-modal understanding and
text-to-image generation, but also excels in producing high-quality, coherent
interleaved outputs. Its emergent capabilities in zero-shot image editing and
compositional generation highlight Mogao as a practical omni-modal foundation
model, paving the way for future development and scaling the unified
multi-modal systems.

</details>

### [221] [DiffusionSfM: Predicting Structure and Motion via Ray Origin and Endpoint Diffusion](https://arxiv.org/abs/2505.05473)
*Qitao Zhao,Amy Lin,Jeff Tan,Jason Y. Zhang,Deva Ramanan,Shubham Tulsiani*

Main category: cs.CV

TLDR: 提出了一种名为DiffusionSfM的数据驱动多视角推理方法，直接通过多视角图像推断3D场景几何和相机姿态，优于传统和基于学习的方法。


<details>
  <summary>Details</summary>
Motivation: 当前SfM方法通常采用两阶段流程，结合学习或几何对偶推理与全局优化步骤，而本文旨在通过数据驱动方法直接推断3D场景几何和相机姿态。

Method: DiffusionSfM将场景几何和相机姿态参数化为全局坐标系中的像素级光线起点和终点，并使用基于Transformer的去噪扩散模型进行预测。针对训练中的缺失数据和无限场景坐标问题，提出了专用机制。

Result: 在合成和真实数据集上的实验表明，DiffusionSfM优于传统和基于学习的方法，并能自然建模不确定性。

Conclusion: DiffusionSfM提供了一种高效且鲁棒的多视角推理方法，为3D重建领域带来了新的可能性。

Abstract: Current Structure-from-Motion (SfM) methods typically follow a two-stage
pipeline, combining learned or geometric pairwise reasoning with a subsequent
global optimization step. In contrast, we propose a data-driven multi-view
reasoning approach that directly infers 3D scene geometry and camera poses from
multi-view images. Our framework, DiffusionSfM, parameterizes scene geometry
and cameras as pixel-wise ray origins and endpoints in a global frame and
employs a transformer-based denoising diffusion model to predict them from
multi-view inputs. To address practical challenges in training diffusion models
with missing data and unbounded scene coordinates, we introduce specialized
mechanisms that ensure robust learning. We empirically validate DiffusionSfM on
both synthetic and real datasets, demonstrating that it outperforms classical
and learning-based approaches while naturally modeling uncertainty.

</details>

### [222] [3D Scene Generation: A Survey](https://arxiv.org/abs/2505.05474)
*Beichen Wen,Haozhe Xie,Zhaoxi Chen,Fangzhou Hong,Ziwei Liu*

Main category: cs.CV

TLDR: 本文综述了3D场景生成的最新进展，将其分为四种范式：程序生成、神经3D生成、基于图像的生成和基于视频的生成，并分析了技术基础、优缺点及未来方向。


<details>
  <summary>Details</summary>
Motivation: 3D场景生成在沉浸式媒体、机器人等领域有广泛应用，但早期方法多样性不足，需要更高效且逼真的生成技术。

Method: 通过深度学习生成模型（如GANs、扩散模型）和3D表示（如NeRF、3D高斯）学习真实场景分布，提升生成质量。

Result: 总结了现有方法的性能、数据集和评估协议，并指出生成能力、3D表示等关键挑战。

Conclusion: 未来方向包括更高保真度、物理感知生成和统一感知生成模型，推动生成AI与3D视觉的结合。

Abstract: 3D scene generation seeks to synthesize spatially structured, semantically
meaningful, and photorealistic environments for applications such as immersive
media, robotics, autonomous driving, and embodied AI. Early methods based on
procedural rules offered scalability but limited diversity. Recent advances in
deep generative models (e.g., GANs, diffusion models) and 3D representations
(e.g., NeRF, 3D Gaussians) have enabled the learning of real-world scene
distributions, improving fidelity, diversity, and view consistency. Recent
advances like diffusion models bridge 3D scene synthesis and photorealism by
reframing generation as image or video synthesis problems. This survey provides
a systematic overview of state-of-the-art approaches, organizing them into four
paradigms: procedural generation, neural 3D-based generation, image-based
generation, and video-based generation. We analyze their technical foundations,
trade-offs, and representative results, and review commonly used datasets,
evaluation protocols, and downstream applications. We conclude by discussing
key challenges in generation capacity, 3D representation, data and annotations,
and evaluation, and outline promising directions including higher fidelity,
physics-aware and interactive generation, and unified perception-generation
models. This review organizes recent advances in 3D scene generation and
highlights promising directions at the intersection of generative AI, 3D
vision, and embodied intelligence. To track ongoing developments, we maintain
an up-to-date project page:
https://github.com/hzxie/Awesome-3D-Scene-Generation.

</details>

### [223] [SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with Video Diffusion and Data Augmentation](https://arxiv.org/abs/2505.05475)
*Yonwoo Choi*

Main category: cs.CV

TLDR: SVAD结合视频扩散模型和3D高斯泼溅技术，从单张图像生成高质量可动画3D人体化身，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单视角下重建完整3D信息存在困难，3DGS需要多视角数据，而视频扩散模型在一致性和身份保持上表现不佳。

Method: 通过视频扩散生成合成训练数据，结合身份保持和图像修复模块优化数据，并用于训练3DGS化身。

Result: SVAD在身份一致性和细节保持上优于现有单图像方法，支持实时渲染，且无需依赖密集训练数据。

Conclusion: SVAD通过结合扩散模型和3DGS，为单图像输入的高保真化身生成提供了新方法。

Abstract: Creating high-quality animatable 3D human avatars from a single image remains
a significant challenge in computer vision due to the inherent difficulty of
reconstructing complete 3D information from a single viewpoint. Current
approaches face a clear limitation: 3D Gaussian Splatting (3DGS) methods
produce high-quality results but require multiple views or video sequences,
while video diffusion models can generate animations from single images but
struggle with consistency and identity preservation. We present SVAD, a novel
approach that addresses these limitations by leveraging complementary strengths
of existing techniques. Our method generates synthetic training data through
video diffusion, enhances it with identity preservation and image restoration
modules, and utilizes this refined data to train 3DGS avatars. Comprehensive
evaluations demonstrate that SVAD outperforms state-of-the-art (SOTA)
single-image methods in maintaining identity consistency and fine details
across novel poses and viewpoints, while enabling real-time rendering
capabilities. Through our data augmentation pipeline, we overcome the
dependency on dense monocular or multi-view training data typically required by
traditional 3DGS approaches. Extensive quantitative, qualitative comparisons
show our method achieves superior performance across multiple metrics against
baseline models. By effectively combining the generative power of diffusion
models with both the high-quality results and rendering efficiency of 3DGS, our
work establishes a new approach for high-fidelity avatar generation from a
single image input.

</details>

<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [224] [Cryptogenic stroke and migraine: using probabilistic independence and machine learning to uncover latent sources of disease from the electronic health record](https://arxiv.org/abs/2505.04631)
*Joshua W. Betts,John M. Still,Thomas A. Lasko*

Main category: stat.AP

TLDR: 论文提出了一种数据驱动方法，利用电子健康记录（EHR）数据构建10年风险预测模型，用于预测偏头痛患者的隐源性卒中（CS）风险。


<details>
  <summary>Details</summary>
Motivation: 偏头痛与隐源性卒中（CS）风险增加相关，但两者关系尚不明确，且缺乏临床指南。

Method: 从EHR数据中提取概率独立的潜在变量，构建因果图，并训练随机森林模型预测CS风险。

Result: 模型表现良好（ROC 0.771），识别出10个最具预测性的CS风险因素，其中药物干预是最重要因素。

Conclusion: 药物干预是降低偏头痛患者CS风险的关键，同时发现过敏性鼻炎可能是潜在致病因素。

Abstract: Migraine is a common but complex neurological disorder that doubles the
lifetime risk of cryptogenic stroke (CS). However, this relationship remains
poorly characterized, and few clinical guidelines exist to reduce this
associated risk. We therefore propose a data-driven approach to extract
probabilistically-independent sources from electronic health record (EHR) data
and create a 10-year risk-predictive model for CS in migraine patients. These
sources represent external latent variables acting on the causal graph
constructed from the EHR data and approximate root causes of CS in our
population. A random forest model trained on patient expressions of these
sources demonstrated good accuracy (ROC 0.771) and identified the top 10 most
predictive sources of CS in migraine patients. These sources revealed that
pharmacologic interventions were the most important factor in minimizing CS
risk in our population and identified a factor related to allergic rhinitis as
a potential causative source of CS in migraine patients.

</details>

<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [225] [Physics-informed solution reconstruction in elasticity and heat transfer using the explicit constraint force method](https://arxiv.org/abs/2505.04875)
*Conor Rowan,Kurt Maute,Alireza Doostan*

Main category: cs.CE

TLDR: 论文分析了物理信息神经网络（PINNs）在解决重建问题时的局限性，并提出了一种新方法（ECFM）以提升可解释性、鲁棒性和数据一致性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决PINNs在真实世界中因物理模型与测量数据不一致而导致的性能问题。

Method: 提出“显式约束力方法”（ECFM），通过控制约束引入的源项来优化重建。

Result: 实验证明ECFM在弹性和热传导问题中能提供更可预测和可定制的重建结果。

Conclusion: ECFM方法通过满足可解释性、鲁棒性和数据一致性标准，显著提升了PINNs在噪声数据下的重建性能。

Abstract: One use case of ``physics-informed neural networks'' (PINNs) is solution
reconstruction, which aims to estimate the full-field state of a physical
system from sparse measurements. Parameterized governing equations of the
system are used in tandem with the measurements to regularize the regression
problem. However, in real-world solution reconstruction problems, the
parameterized governing equation may be inconsistent with the physical
phenomena that give rise to the measurement data. We show that due to assuming
consistency between the true and parameterized physics, PINNs-based approaches
may fail to satisfy three basic criteria of interpretability, robustness, and
data consistency. As we argue, these criteria ensure that (i) the quality of
the reconstruction can be assessed, (ii) the reconstruction does not depend
strongly on the choice of physics loss, and (iii) that in certain situations,
the physics parameters can be uniquely recovered. In the context of elasticity
and heat transfer, we demonstrate how standard formulations of the physics loss
and techniques for constraining the solution to respect the measurement data
lead to different ``constraint forces" -- which we define as additional source
terms arising from the constraints -- and that these constraint forces can
significantly influence the reconstructed solution. To avoid the potentially
substantial influence of the choice of physics loss and method of constraint
enforcement on the reconstructed solution, we propose the ``explicit constraint
force method'' (ECFM) to gain control of the source term introduced by the
constraint. We then show that by satisfying the criteria of interpretability,
robustness, and data consistency, this approach leads to more predictable and
customizable reconstructions from noisy measurement data, even when the
parameterization of the missing physics is inconsistent with the measured
system.

</details>

<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [226] [Geometric Fault-Tolerant Neural Network Tracking Control of Unknown Systems on Matrix Lie Groups](https://arxiv.org/abs/2505.04725)
*Robin Chhabra,Farzaneh Abdollahi*

Main category: eess.SY

TLDR: 提出了一种基于几何神经网络的跟踪控制器，用于处理矩阵李群上未知动态、执行器故障和有界扰动的系统。


<details>
  <summary>Details</summary>
Motivation: 解决矩阵李群上系统在未知动态、执行器故障和扰动下的跟踪控制问题。

Method: 利用矩阵李群的左不变性，提出与李群结构兼容的神经网络权重学习规则，避免参数化奇异性。

Result: 通过Lyapunov直接方法证明了所有误差信号的最终有界性，并通过仿真验证了方法的有效性。

Conclusion: 该方法在特殊欧几里得群上的多智能体系统分散编队控制中表现出色。

Abstract: We present a geometric neural network-based tracking controller for systems
evolving on matrix Lie groups under unknown dynamics, actuator faults, and
bounded disturbances. Leveraging the left-invariance of the tangent bundle of
matrix Lie groups, viewed as an embedded submanifold of the vector space
$\R^{N\times N}$, we propose a set of learning rules for neural network weights
that are intrinsically compatible with the Lie group structure and do not
require explicit parameterization. Exploiting the geometric properties of Lie
groups, this approach circumvents parameterization singularities and enables a
global search for optimal weights. The ultimate boundedness of all error
signals -- including the neural network weights, the coordinate-free
configuration error function, and the tracking velocity error -- is established
using Lyapunov's direct method. To validate the effectiveness of the proposed
method, we provide illustrative simulation results for decentralized formation
control of multi-agent systems on the Special Euclidean group.

</details>

### [227] [LAPSO: A Unified Optimization View for Learning-Augmented Power System Operations](https://arxiv.org/abs/2505.05203)
*Wangkun Xu,Zhongda Chu,Fei Teng*

Main category: eess.SY

TLDR: 论文提出了一种名为LAPSO的框架，通过机器学习和传统优化方法的结合，解决高比例可再生能源下电力系统运行的经济性、稳定性和鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 高比例可再生能源的渗透对传统电力系统运行方法提出了挑战，需要更经济、稳定和鲁棒的决策。

Method: 提出LAPSO框架，从优化角度出发，整合电力系统的预测、运行和控制任务，统一机器学习和基于模型的优化目标。

Result: 通过系统分析和仿真验证了LAPSO的有效性，设计了稳定性约束优化（SCO）和目标导向预测（OBF）等新算法。

Conclusion: LAPSO框架成功填补了机器学习和传统优化方法之间的鸿沟，并提供了开源工具包支持实际应用。

Abstract: With the high penetration of renewables, traditional model-based power system
operation is challenged to deliver economic, stable, and robust decisions.
Machine learning has emerged as a powerful modeling tool for capturing complex
dynamics to address these challenges. However, its separate design often lacks
systematic integration with existing methods. To fill the gap, this paper
proposes a holistic framework of Learning-Augmented Power System Operations
(LAPSO, pronounced as Lap-So). Adopting a native optimization perspective,
LAPSO is centered on the operation stage and aims to break the boundary between
temporally siloed power system tasks, such as forecast, operation and control,
while unifying the objectives of machine learning and model-based optimizations
at both training and inference stages. Systematic analysis and simulations
demonstrate the effectiveness of applying LAPSO in designing new integrated
algorithms, such as stability-constrained optimization (SCO) and
objective-based forecasting (OBF), while enabling end-to-end tracing of
different sources of uncertainties. In addition, a dedicated Python
package-lapso is introduced to automatically augment existing power system
optimization models with learnable components. All code and data are available
at https://github.com/xuwkk/lapso_exp.

</details>

<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [228] [Error Analysis of Deep PDE Solvers for Option Pricing](https://arxiv.org/abs/2505.05121)
*Jasper Rou*

Main category: q-fin.CP

TLDR: 研究评估了深度PDE求解器在期权定价中的实用性和准确性，比较了Deep Galerkin Method和TDGF方法在Black-Scholes和Heston模型中的表现。


<details>
  <summary>Details</summary>
Motivation: 深度学习的PDE求解器在期权定价中的应用潜力尚未被充分理解，阻碍了其实际应用。

Method: 通过实验比较Deep Galerkin Method和TDGF方法，评估其收敛速度、训练时间及参数影响。

Result: 分析了采样阶段数、样本数、网络层数、节点数等因素对性能的影响，并针对TDGF评估了离散化方案和时间步数。

Conclusion: 研究为深度PDE求解器在期权定价中的实际应用提供了实用见解。

Abstract: Option pricing often requires solving partial differential equations (PDEs).
Although deep learning-based PDE solvers have recently emerged as quick
solutions to this problem, their empirical and quantitative accuracy remain not
well understood, hindering their real-world applicability. In this research,
our aim is to offer actionable insights into the utility of deep PDE solvers
for practical option pricing implementation. Through comparative experiments in
both the Black--Scholes and the Heston model, we assess the empirical
performance of two neural network algorithms to solve PDEs: the Deep Galerkin
Method and the Time Deep Gradient Flow method (TDGF). We determine their
empirical convergence rates and training time as functions of (i) the number of
sampling stages, (ii) the number of samples, (iii) the number of layers, and
(iv) the number of nodes per layer. For the TDGF, we also consider the order of
the discretization scheme and the number of time steps.

</details>

<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [229] [Guiding Evolutionary AutoEncoder Training with Activation-Based Pruning Operators](https://arxiv.org/abs/2505.05138)
*Steven Jorgensen,Erik Hemberg,Jamal Toutouh,Una-May O'Reilly*

Main category: cs.NE

TLDR: 论文提出了一种基于进化计算的神经网络剪枝新方法，专注于同时剪枝自编码器的编码器和解码器，并引入两种新的突变算子。研究发现，在低维剪枝环境中，基于激活的剪枝优于随机剪枝，但在协同进化场景中，随机剪枝效果更好。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过进化计算优化自编码器的剪枝过程，以提高效率并保持性能。

Method: 引入两种基于激活的突变算子指导剪枝，并在协同进化与经典训练两种场景下进行对比实验。

Result: 在经典训练中，基于激活的剪枝优于随机剪枝；而在协同进化中，随机剪枝表现更好。

Conclusion: 激活引导的剪枝在低维环境中更有效，而协同进化策略通过高维剪枝实现更好的鲁棒性。

Abstract: This study explores a novel approach to neural network pruning using
evolutionary computation, focusing on simultaneously pruning the encoder and
decoder of an autoencoder. We introduce two new mutation operators that use
layer activations to guide weight pruning. Our findings reveal that one of
these activation-informed operators outperforms random pruning, resulting in
more efficient autoencoders with comparable performance to canonically trained
models. Prior work has established that autoencoder training is effective and
scalable with a spatial coevolutionary algorithm that cooperatively coevolves a
population of encoders with a population of decoders, rather than one
autoencoder. We evaluate how the same activity-guided mutation operators
transfer to this context. We find that random pruning is better than guided
pruning, in the coevolutionary setting. This suggests activation-based guidance
proves more effective in low-dimensional pruning environments, where
constrained sample spaces can lead to deviations from true uniformity in
randomization. Conversely, population-driven strategies enhance robustness by
expanding the total pruning dimensionality, achieving statistically uniform
randomness that better preserves system dynamics. We experiment with pruning
according to different schedules and present best combinations of operator and
schedule for the canonical and coevolving populations cases.

</details>

<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [230] [Representing spherical tensors with scalar-based machine-learning models](https://arxiv.org/abs/2505.05404)
*Michelangelo Domina,Filippo Bigi,Paolo Pegolo,Michele Ceriotti*

Main category: physics.chem-ph

TLDR: 论文提出了一种新的方法来处理3D点云的旋转对称性学习问题，通过将等变函数表示为点云坐标的标量函数与具有适当对称性的小张量基的乘积。


<details>
  <summary>Details</summary>
Motivation: 旋转对称性在物理学中至关重要，但现有的等变模型计算复杂且实现繁琐，而无约束架构则学习近似对称性，因此需要一种更高效的方法。

Method: 将等变函数表示为点云坐标的标量函数与对称张量基的乘积，并提出近似表达式以提高计算效率。

Result: 提出的方法在保持对称性的同时，计算速度快、实现简单，并在实际应用中表现出高准确性。

Conclusion: 该方法为处理3D点云的旋转对称性提供了一种高效且实用的解决方案。

Abstract: Rotational symmetry plays a central role in physics, providing an elegant
framework to describe how the properties of 3D objects -- from atoms to the
macroscopic scale -- transform under the action of rigid rotations. Equivariant
models of 3D point clouds are able to approximate structure-property relations
in a way that is fully consistent with the structure of the rotation group, by
combining intermediate representations that are themselves spherical tensors.
The symmetry constraints however make this approach computationally demanding
and cumbersome to implement, which motivates increasingly popular unconstrained
architectures that learn approximate symmetries as part of the training
process. In this work, we explore a third route to tackle this learning
problem, where equivariant functions are expressed as the product of a scalar
function of the point cloud coordinates and a small basis of tensors with the
appropriate symmetry. We also propose approximations of the general expressions
that, while lacking universal approximation properties, are fast, simple to
implement, and accurate in practical settings.

</details>

<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [231] [Incentive-Aware Machine Learning; Robustness, Fairness, Improvement & Causality](https://arxiv.org/abs/2505.05211)
*Chara Podimata*

Main category: cs.GT

TLDR: 本文探讨了激励感知机器学习（ML）的新兴领域，重点关注个体可能通过策略性修改输入以影响结果的算法决策。研究分为三个视角：鲁棒性、公平性和改进/因果关系，并提出了统一框架。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决个体策略性行为对ML系统的影响，确保系统的鲁棒性、公平性和社会效益。

Method: 通过分类研究视角（鲁棒性、公平性、改进/因果关系）并提出统一框架，涵盖离线、在线和因果设置。

Result: 提出了一种激励感知ML的统一框架，并总结了理论进展和实际解决方案。

Conclusion: 激励感知ML系统需进一步区分策略性行为与真实改进，并解决代理异质性等关键挑战。

Abstract: The article explores the emerging domain of incentive-aware machine learning
(ML), which focuses on algorithmic decision-making in contexts where
individuals can strategically modify their inputs to influence outcomes. It
categorizes the research into three perspectives: robustness, aiming to design
models resilient to "gaming"; fairness, analyzing the societal impacts of such
systems; and improvement/causality, recognizing situations where strategic
actions lead to genuine personal or societal improvement. The paper introduces
a unified framework encapsulating models for these perspectives, including
offline, online, and causal settings, and highlights key challenges such as
differentiating between gaming and improvement and addressing heterogeneity
among agents. By synthesizing findings from diverse works, we outline
theoretical advancements and practical solutions for robust, fair, and
causally-informed incentive-aware ML systems.

</details>

<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [232] [D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation](https://arxiv.org/abs/2505.04860)
*I-Chun Arthur Liu,Jason Chen,Gaurav Sukhatme,Daniel Seita*

Main category: cs.RO

TLDR: D-CODA是一种用于双机械臂模仿学习的离线数据增强方法，通过扩散模型生成视角一致的腕部摄像头图像和动作标签。


<details>
  <summary>Details</summary>
Motivation: 双机械臂操作的高维度和协调需求使得数据收集成本高，需要可扩展的数据增强方法。

Method: 使用扩散模型生成视角一致的图像和动作标签，并通过约束优化确保双机械臂协调的可行性。

Result: 在5个模拟和3个真实任务中，D-CODA表现优于基线方法，验证了其数据增强的有效性。

Conclusion: D-CODA为双机械臂模仿学习提供了一种可扩展的数据增强解决方案。

Abstract: Learning bimanual manipulation is challenging due to its high dimensionality
and tight coordination required between two arms. Eye-in-hand imitation
learning, which uses wrist-mounted cameras, simplifies perception by focusing
on task-relevant views. However, collecting diverse demonstrations remains
costly, motivating the need for scalable data augmentation. While prior work
has explored visual augmentation in single-arm settings, extending these
approaches to bimanual manipulation requires generating viewpoint-consistent
observations across both arms and producing corresponding action labels that
are both valid and feasible. In this work, we propose Diffusion for COordinated
Dual-arm Data Augmentation (D-CODA), a method for offline data augmentation
tailored to eye-in-hand bimanual imitation learning that trains a diffusion
model to synthesize novel, viewpoint-consistent wrist-camera images for both
arms while simultaneously generating joint-space action labels. It employs
constrained optimization to ensure that augmented states involving
gripper-to-object contacts adhere to constraints suitable for bimanual
coordination. We evaluate D-CODA on 5 simulated and 3 real-world tasks. Our
results across 2250 simulation trials and 300 real-world trials demonstrate
that it outperforms baselines and ablations, showing its potential for scalable
data augmentation in eye-in-hand bimanual manipulation. Our project website is
at: https://dcodaaug.github.io/D-CODA/.

</details>

### [233] [X-Driver: Explainable Autonomous Driving with Vision-Language Models](https://arxiv.org/abs/2505.05098)
*Wei Liu,Jiyuan Zhang,Binxiong Zheng,Yufeng Hu,Yingzhan Lin,Zengfeng Zeng*

Main category: cs.RO

TLDR: X-Driver是一个基于多模态大语言模型（MLLMs）的端到端自动驾驶框架，通过Chain-of-Thought（CoT）和自回归建模提升感知与决策能力，在封闭环评测中表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶框架在封闭环评测中成功率低，限制了实际部署。

Method: 提出X-Driver框架，结合MLLMs、CoT和自回归建模，优化感知与决策。

Result: 在CARLA仿真环境中验证，X-Driver在封闭环评测中表现优于SOTA，并提升决策可解释性。

Conclusion: 结构化推理对端到端驾驶至关重要，X-Driver为未来封闭环自动驾驶研究提供了强基线。

Abstract: End-to-end autonomous driving has advanced significantly, offering benefits
such as system simplicity and stronger driving performance in both open-loop
and closed-loop settings than conventional pipelines. However, existing
frameworks still suffer from low success rates in closed-loop evaluations,
highlighting their limitations in real-world deployment. In this paper, we
introduce X-Driver, a unified multi-modal large language models(MLLMs)
framework designed for closed-loop autonomous driving, leveraging
Chain-of-Thought(CoT) and autoregressive modeling to enhance perception and
decision-making. We validate X-Driver across multiple autonomous driving tasks
using public benchmarks in CARLA simulation environment, including
Bench2Drive[6]. Our experimental results demonstrate superior closed-loop
performance, surpassing the current state-of-the-art(SOTA) while improving the
interpretability of driving decisions. These findings underscore the importance
of structured reasoning in end-to-end driving and establish X-Driver as a
strong baseline for future research in closed-loop autonomous driving.

</details>

### [234] [AI and Vision based Autonomous Navigation of Nano-Drones in Partially-Known Environments](https://arxiv.org/abs/2505.04972)
*Mattia Sartori,Chetna Singhal,Neelabhro Roy,Davide Brunelli,James Gross*

Main category: cs.RO

TLDR: 本文提出了一种基于AI和视觉的避障方法，用于30克重的Crazyflie 2.1无人机在部分已知环境中的自主飞行。通过将导航任务分为边缘计算和机载执行两部分，解决了资源限制问题。


<details>
  <summary>Details</summary>
Motivation: 由于纳米无人机资源有限，实现其安全自主导航和高阶任务（如探索和监视）极具挑战性。本文旨在解决这一问题。

Method: 提出了一种AI辅助的视觉反应式规划方法，将导航任务分为边缘计算（深度学习目标检测）和机载执行（规划算法）。

Result: 实验表明，无人机能以每秒8帧的速度运行，模型性能达到60.8的COCO平均精度。现场测试中，无人机以1米/秒的速度飞行并成功避障。

Conclusion: 该方法为纳米无人机的实时导航提供了可行方案，并可扩展至自主探索任务。

Abstract: The miniaturisation of sensors and processors, the advancements in connected
edge intelligence, and the exponential interest in Artificial Intelligence are
boosting the affirmation of autonomous nano-size drones in the Internet of
Robotic Things ecosystem. However, achieving safe autonomous navigation and
high-level tasks such as exploration and surveillance with these tiny platforms
is extremely challenging due to their limited resources. This work focuses on
enabling the safe and autonomous flight of a pocket-size, 30-gram platform
called Crazyflie 2.1 in a partially known environment. We propose a novel
AI-aided, vision-based reactive planning method for obstacle avoidance under
the ambit of Integrated Sensing, Computing and Communication paradigm. We deal
with the constraints of the nano-drone by splitting the navigation task into
two parts: a deep learning-based object detector runs on the edge (external
hardware) while the planning algorithm is executed onboard. The results show
the ability to command the drone at $\sim8$ frames-per-second and a model
performance reaching a COCO mean-average-precision of $60.8$. Field experiments
demonstrate the feasibility of the solution with the drone flying at a top
speed of $1$ m/s while steering away from an obstacle placed in an unknown
position and reaching the target destination. The outcome highlights the
compatibility of the communication delay and the model performance with the
requirements of the real-time navigation task. We provide a feasible
alternative to a fully onboard implementation that can be extended to
autonomous exploration with nano-drones.

</details>

### [235] [Steerable Scene Generation with Post Training and Inference-Time Search](https://arxiv.org/abs/2505.04831)
*Nicholas Pfaff,Hongkai Dai,Sergey Zakharov,Shun Iwase,Russ Tedrake*

Main category: cs.RO

TLDR: 提出了一种基于扩散模型的场景生成方法，用于机器人训练，支持任务导向的场景合成。


<details>
  <summary>Details</summary>
Motivation: 手动构建满足任务需求的3D场景成本高且稀缺，需要一种自动生成大规模场景的方法。

Method: 训练统一的扩散生成模型，预测物体及其位姿，并通过强化学习、条件生成或推理时搜索适应任务目标。

Result: 生成了超过4400万个SE(3)场景，覆盖五种环境，并提出了新的MCTS推理搜索策略。

Conclusion: 该方法能够高效生成物理可行的任务导向场景，适用于多样化机器人训练需求。

Abstract: Training robots in simulation requires diverse 3D scenes that reflect the
specific challenges of downstream tasks. However, scenes that satisfy strict
task requirements, such as high-clutter environments with plausible spatial
arrangement, are rare and costly to curate manually. Instead, we generate
large-scale scene data using procedural models that approximate realistic
environments for robotic manipulation, and adapt it to task-specific goals. We
do this by training a unified diffusion-based generative model that predicts
which objects to place from a fixed asset library, along with their SE(3)
poses. This model serves as a flexible scene prior that can be adapted using
reinforcement learning-based post training, conditional generation, or
inference-time search, steering generation toward downstream objectives even
when they differ from the original data distribution. Our method enables
goal-directed scene synthesis that respects physical feasibility and scales
across scene types. We introduce a novel MCTS-based inference-time search
strategy for diffusion models, enforce feasibility via projection and
simulation, and release a dataset of over 44 million SE(3) scenes spanning five
diverse environments. Website with videos, code, data, and model weights:
https://steerable-scene-generation.github.io/

</details>

### [236] [CubeDAgger: Improved Robustness of Interactive Imitation Learning without Violation of Dynamic Stability](https://arxiv.org/abs/2505.04897)
*Taisuke Kobayashi*

Main category: cs.RO

TLDR: CubeDAgger是一种改进的交互模仿学习方法，通过优化监督时机选择、动作候选共识系统和引入自回归噪声，提升鲁棒性并减少动态稳定性破坏。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过专家-代理切换系统减少专家负担，但精确选择监督时机困难且切换导致动作突变，破坏动态稳定性。

Method: 1. 添加正则化以明确激活监督时机阈值；2. 将切换系统转为多动作候选的最优共识系统；3. 引入自回归有色噪声以保持随机探索一致性。

Result: 仿真验证表明，学习到的策略在交互中保持鲁棒性的同时维护了动态稳定性。

Conclusion: CubeDAgger通过三项改进显著提升了交互模仿学习的性能，解决了动态稳定性问题。

Abstract: Interactive imitation learning makes an agent's control policy robust by
stepwise supervisions from an expert. The recent algorithms mostly employ
expert-agent switching systems to reduce the expert's burden by limitedly
selecting the supervision timing. However, the precise selection is difficult
and such a switching causes abrupt changes in actions, damaging the dynamic
stability. This paper therefore proposes a novel method, so-called CubeDAgger,
which improves robustness while reducing dynamic stability violations by making
three improvements to a baseline method, EnsembleDAgger. The first improvement
adds a regularization to explicitly activate the threshold for deciding the
supervision timing. The second transforms the expert-agent switching system to
an optimal consensus system of multiple action candidates. Third,
autoregressive colored noise to the actions is introduced to make the
stochastic exploration consistent over time. These improvements are verified by
simulations, showing that the learned policies are sufficiently robust while
maintaining dynamic stability during interaction.

</details>

### [237] [CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations](https://arxiv.org/abs/2505.04999)
*Anthony Liang,Pavel Czempin,Matthew Hong,Yutai Zhou,Erdem Biyik,Stephen Tu*

Main category: cs.RO

TLDR: 论文提出了一种名为CLAM的方法，通过无监督学习从无标签观察数据中学习连续潜在动作标签，解决了模仿学习中需要大量标记专家数据的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 模仿学习需要大量标记专家数据，成本高昂且限制了训练规模。利用无标签观察数据（如视频演示）学习潜在动作标签是一种有前景的解决方案。

Method: 设计了连续潜在动作模型（CLAM），包含两个关键部分：使用连续潜在动作标签而非离散表示，并联合训练动作解码器以确保潜在动作空间能轻松映射到真实动作。

Result: 在DMControl（运动）和MetaWorld（操作）的连续控制基准测试中，以及真实WidowX机器人上，CLAM显著优于现有方法，任务成功率提高了2-3倍。

Conclusion: CLAM无需标记专家数据即可学习高性能策略，为非最优数据提供了有效的解决方案。

Abstract: Learning robot policies using imitation learning requires collecting large
amounts of costly action-labeled expert demonstrations, which fundamentally
limits the scale of training data. A promising approach to address this
bottleneck is to harness the abundance of unlabeled observations-e.g., from
video demonstrations-to learn latent action labels in an unsupervised way.
However, we find that existing methods struggle when applied to complex robot
tasks requiring fine-grained motions. We design continuous latent action models
(CLAM) which incorporate two key ingredients we find necessary for learning to
solve complex continuous control tasks from unlabeled observation data: (a)
using continuous latent action labels instead of discrete representations, and
(b) jointly training an action decoder to ensure that the latent action space
can be easily grounded to real actions with relatively few labeled examples.
Importantly, the labeled examples can be collected from non-optimal play data,
enabling CLAM to learn performant policies without access to any action-labeled
expert data. We demonstrate on continuous control benchmarks in DMControl
(locomotion) and MetaWorld (manipulation), as well as on a real WidowX robot
arm that CLAM significantly outperforms prior state-of-the-art methods,
remarkably with a 2-3x improvement in task success rate compared to the best
baseline. Videos and code can be found at clamrobot.github.io.

</details>

### [238] [The City that Never Settles: Simulation-based LiDAR Dataset for Long-Term Place Recognition Under Extreme Structural Changes](https://arxiv.org/abs/2505.05076)
*Hyunho Song,Dongjae Lee,Seunghun Oh,Minwoo Jung,Ayoung Kim*

Main category: cs.RO

TLDR: 论文提出了CNS数据集，用于模拟大规模城市环境变化，并提出了TCR_sym度量方法，以评估现有LiDAR定位算法的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集未能充分反映大规模户外环境变化，限制了长期位置识别算法的研究。

Method: 使用CARLA模拟器创建CNS数据集，并提出对称度量TCR_sym。

Result: CNS数据集比现有真实数据集包含更广泛的环境变化，现有LiDAR定位算法在CNS上表现显著下降。

Conclusion: CNS数据集填补了研究空白，并揭示了现有算法在大规模环境变化下的不足。

Abstract: Large-scale construction and demolition significantly challenge long-term
place recognition (PR) by drastically reshaping urban and suburban
environments. Existing datasets predominantly reflect limited or indoor-focused
changes, failing to adequately represent extensive outdoor transformations. To
bridge this gap, we introduce the City that Never Settles (CNS) dataset, a
simulation-based dataset created using the CARLA simulator, capturing major
structural changes-such as building construction and demolition-across diverse
maps and sequences. Additionally, we propose TCR_sym, a symmetric version of
the original TCR metric, enabling consistent measurement of structural changes
irrespective of source-target ordering. Quantitative comparisons demonstrate
that CNS encompasses more extensive transformations than current real-world
benchmarks. Evaluations of state-of-the-art LiDAR-based PR methods on CNS
reveal substantial performance degradation, underscoring the need for robust
algorithms capable of handling significant environmental changes. Our dataset
is available at https://github.com/Hyunho111/CNS_dataset.

</details>

### [239] [Multi-Objective Reinforcement Learning for Adaptive Personalized Autonomous Driving](https://arxiv.org/abs/2505.05223)
*Hendrik Surmann,Jorge de Heuvel,Maren Bennewitz*

Main category: cs.RO

TLDR: 提出了一种基于多目标强化学习（MORL）的方法，用于自动驾驶的动态驾驶风格偏好适应，无需重新训练策略。


<details>
  <summary>Details</summary>
Motivation: 人类驾驶员有独特的驾驶风格偏好，适应这些偏好对提升自动驾驶的用户信任和满意度至关重要。现有方法依赖预定义风格或持续用户反馈，无法支持动态偏好。

Method: 使用MORL和偏好驱动优化，将偏好编码为连续权重向量，调节可解释的风格目标（如效率、舒适性、速度和激进性）。

Result: 在CARLA模拟器中评估，代理能根据动态偏好调整驾驶行为，同时保持避碰和路线完成性能。

Conclusion: 该方法实现了运行时动态适应驾驶风格偏好，为自动驾驶的个性化提供了新思路。

Abstract: Human drivers exhibit individual preferences regarding driving style.
Adapting autonomous vehicles to these preferences is essential for user trust
and satisfaction. However, existing end-to-end driving approaches often rely on
predefined driving styles or require continuous user feedback for adaptation,
limiting their ability to support dynamic, context-dependent preferences. We
propose a novel approach using multi-objective reinforcement learning (MORL)
with preference-driven optimization for end-to-end autonomous driving that
enables runtime adaptation to driving style preferences. Preferences are
encoded as continuous weight vectors to modulate behavior along interpretable
style objectives$\unicode{x2013}$including efficiency, comfort, speed, and
aggressiveness$\unicode{x2013}$without requiring policy retraining. Our
single-policy agent integrates vision-based perception in complex mixed-traffic
scenarios and is evaluated in diverse urban environments using the CARLA
simulator. Experimental results demonstrate that the agent dynamically adapts
its driving behavior according to changing preferences while maintaining
performance in terms of collision avoidance and route completion.

</details>

### [240] [Morphologically Symmetric Reinforcement Learning for Ambidextrous Bimanual Manipulation](https://arxiv.org/abs/2505.05287)
*Zechu Li,Yufeng Jin,Daniel Ordonez Apraez,Claudio Semini,Puze Liu,Georgia Chalvatzaki*

Main category: cs.RO

TLDR: SYMDEX是一个强化学习框架，利用机器人固有的双侧对称性实现双手灵巧操作，通过分解任务和对称神经网络提升效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 人类具有双侧对称性，而机器人应能实现双手灵巧操作，但现有方法缺乏对称性利用。

Method: SYMDEX将复杂任务分解为子任务，利用对称神经网络共享经验，最终训练出全局灵巧策略。

Result: 在模拟和真实任务中表现优异，尤其在双手分工任务中显著优于基线方法，并可扩展至四臂操作。

Conclusion: 对称性作为归纳偏置能提升样本效率、鲁棒性和泛化能力，适用于多样化的灵巧操作任务。

Abstract: Humans naturally exhibit bilateral symmetry in their gross manipulation
skills, effortlessly mirroring simple actions between left and right hands.
Bimanual robots-which also feature bilateral symmetry-should similarly exploit
this property to perform tasks with either hand. Unlike humans, who often favor
a dominant hand for fine dexterous skills, robots should ideally execute
ambidextrous manipulation with equal proficiency. To this end, we introduce
SYMDEX (SYMmetric DEXterity), a reinforcement learning framework for
ambidextrous bi-manipulation that leverages the robot's inherent bilateral
symmetry as an inductive bias. SYMDEX decomposes complex bimanual manipulation
tasks into per-hand subtasks and trains dedicated policies for each. By
exploiting bilateral symmetry via equivariant neural networks, experience from
one arm is inherently leveraged by the opposite arm. We then distill the
subtask policies into a global ambidextrous policy that is independent of the
hand-task assignment. We evaluate SYMDEX on six challenging simulated
manipulation tasks and demonstrate successful real-world deployment on two of
them. Our approach strongly outperforms baselines on complex task in which the
left and right hands perform different roles. We further demonstrate SYMDEX's
scalability by extending it to a four-arm manipulation setup, where our
symmetry-aware policies enable effective multi-arm collaboration and
coordination. Our results highlight how structural symmetry as inductive bias
in policy learning enhances sample efficiency, robustness, and generalization
across diverse dexterous manipulation tasks.

</details>

<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [241] [Moments of Causal Effects](https://arxiv.org/abs/2505.04971)
*Yuta Kawakami,Jin Tian*

Main category: stat.ME

TLDR: 该论文提出了因果效应的矩和乘积矩的定义、识别定理和界限，以分析其分布和关系，并通过实验展示了从有限样本中估计因果效应矩的方法及其在实际医学数据集中的应用。


<details>
  <summary>Details</summary>
Motivation: 传统因果效应评估主要关注平均因果效应，而忽略了更高阶的矩和变量间关系。本文旨在填补这一空白，提供更全面的因果效应分布和关系分析。

Method: 提出了因果效应的矩和乘积矩的定义及识别定理，并通过实验从有限样本中估计这些矩，使用真实医学数据集进行验证。

Result: 实验展示了如何从有限样本中估计因果效应的矩，并验证了这些矩在实际应用中的有效性。

Conclusion: 本文扩展了因果效应的分析范围，提供了高阶矩和变量间关系的评估方法，为更全面的因果推断提供了工具。

Abstract: The moments of random variables are fundamental statistical measures for
characterizing the shape of a probability distribution, encompassing metrics
such as mean, variance, skewness, and kurtosis. Additionally, the product
moments, including covariance and correlation, reveal the relationships between
multiple random variables. On the other hand, the primary focus of causal
inference is the evaluation of causal effects, which are defined as the
difference between two potential outcomes. While traditional causal effect
assessment focuses on the average causal effect, this work provides
definitions, identification theorems, and bounds for moments and product
moments of causal effects to analyze their distribution and relationships. We
conduct experiments to illustrate the estimation of the moments of causal
effects from finite samples and demonstrate their practical application using a
real-world medical dataset.

</details>

### [242] [Decomposition of Probabilities of Causation with Two Mediators](https://arxiv.org/abs/2505.04983)
*Yuta Kawakami,Jin Tian*

Main category: stat.ME

TLDR: 该研究通过路径特定的必要性及充分性概率（PNS）分解总PNS，分析因果中介效应，并验证了估计器的性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过分解总PNS为路径特定成分，评估治疗通过不同因果路径的必要性和充分性。

Method: 定义了路径特定PNS，提出了识别定理，并通过数值实验和真实教育数据集验证估计器。

Result: 研究成功分解了总PNS，验证了估计器在有限样本中的性能，并展示了实际应用效果。

Conclusion: 路径特定PNS分解为因果中介分析提供了有效工具，适用于实际数据应用。

Abstract: Mediation analysis for probabilities of causation (PoC) provides a
fundamental framework for evaluating the necessity and sufficiency of treatment
in provoking an event through different causal pathways. One of the primary
objectives of causal mediation analysis is to decompose the total effect into
path-specific components. In this study, we investigate the path-specific
probability of necessity and sufficiency (PNS) to decompose the total PNS into
path-specific components along distinct causal pathways between treatment and
outcome, incorporating two mediators. We define the path-specific PNS for
decomposition and provide an identification theorem. Furthermore, we conduct
numerical experiments to assess the properties of the proposed estimators from
finite samples and demonstrate their practical application using a real-world
educational dataset.

</details>

<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [243] [From Dialect Gaps to Identity Maps: Tackling Variability in Speaker Verification](https://arxiv.org/abs/2505.04629)
*Abdulhady Abas Abdullah,Soran Badawi,Dana A. Abdullah,Dana Rasul Hamad,Hanan Abdulrahman Taher,Sabat Salih Muhamad,Aram Mahmood Ahmed,Bryar A. Hassan,Sirwan Abdolwahed Aula,Tarik A. Rashid*

Main category: eess.AS

TLDR: 本文研究了库尔德语多方言中说话人识别的复杂性，提出了改进方法以提高准确性。


<details>
  <summary>Details</summary>
Motivation: 库尔德语的多方言（如Kurmanji、Sorani和Hawrami）在语音和词汇上差异显著，给说话人识别系统带来挑战。

Method: 采用高级机器学习方法、数据增强策略及构建方言特定语料库。

Result: 针对各方言的定制策略及跨方言训练显著提升了识别性能。

Conclusion: 通过定制化方法和跨方言训练，可有效提高库尔德语说话人识别系统的准确性和可靠性。

Abstract: The complexity and difficulties of Kurdish speaker detection among its
several dialects are investigated in this work. Because of its great phonetic
and lexical differences, Kurdish with several dialects including Kurmanji,
Sorani, and Hawrami offers special challenges for speaker recognition systems.
The main difficulties in building a strong speaker identification system
capable of precisely identifying speakers across several dialects are
investigated in this work. To raise the accuracy and dependability of these
systems, it also suggests solutions like sophisticated machine learning
approaches, data augmentation tactics, and the building of thorough
dialect-specific corpus. The results show that customized strategies for every
dialect together with cross-dialect training greatly enhance recognition
performance.

</details>

<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [244] [ICNN-enhanced 2SP: Leveraging input convex neural networks for solving two-stage stochastic programming](https://arxiv.org/abs/2505.05261)
*Yu Liu,Fabricio Oliveira*

Main category: math.OC

TLDR: 提出了一种基于输入凸神经网络（ICNN）的两阶段随机规划方法，替代传统混合整数规划（MIP），显著提升计算效率并保持解的质量。


<details>
  <summary>Details</summary>
Motivation: 传统基于MIP的两阶段随机规划方法计算复杂度高，限制了其可扩展性。

Method: 利用ICNN的凸性特性，通过线性规划（LP）实现精确推理，避免整数变量需求。

Result: 实验表明，ICNN方法训练时间略长但验证精度相当，计算速度显著提升（最高100倍），且解质量更优。

Conclusion: ICNN增强的两阶段随机规划方法在计算效率和解质量上均优于传统MIP方法，尤其适用于大规模问题。

Abstract: Two-stage stochastic programming (2SP) offers a basic framework for modelling
decision-making under uncertainty, yet scalability remains a challenge due to
the computational complexity of recourse function evaluation. Existing
learning-based methods like Neural Two-Stage Stochastic Programming (Neur2SP)
employ neural networks (NNs) as recourse function surrogates but rely on
computationally intensive mixed-integer programming (MIP) formulations. We
propose ICNN-enhanced 2SP, a method that leverages Input Convex Neural Networks
(ICNNs) to exploit linear programming (LP) representability in convex 2SP
problems. By architecturally enforcing convexity and enabling exact inference
through LP, our approach eliminates the need for integer variables inherent to
the conventional MIP-based formulation while retaining an exact embedding of
the ICNN surrogate within the 2SP framework. This results in a more
computationally efficient alternative that maintains solution quality.
Comprehensive experiments reveal that ICNNs incur only marginally longer
training times while achieving validation accuracy on par with their MIP-based
counterparts. Across benchmark problems, ICNN-enhanced 2SP often exhibits
considerably faster solution times than the MIP-based formulations while
preserving solution quality, with these advantages becoming significantly more
pronounced as problem scale increases. For the most challenging instances, the
method achieves speedups of up to 100$\times$ and solution quality superior to
MIP-based formulations.

</details>

<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [245] [Integrating Communication, Sensing, and Security: Progress and Prospects of PLS in ISAC Systems](https://arxiv.org/abs/2505.05090)
*Waqas Aman,El-Mehdi Illi,Marwa Qaraqe,Saif Al-Kuwari*

Main category: cs.ET

TLDR: 本文综述了从物理层安全（PLS）角度设计的集成感知与通信（ISAC）系统，探讨了通信可靠性、感知与安全之间的平衡，并分析了相关技术和攻击。


<details>
  <summary>Details</summary>
Motivation: 随着第六代无线网络的发展，如何在共享频谱和硬件资源下实现高效通信与感知的同时确保安全性成为关键问题。

Method: 通过系统综述和理论分析，研究了PLS与ISAC的结合，探讨了多种物理层技术和无线技术对感知-安全权衡的影响。

Result: 分析了针对数据保密性、通信隐蔽性和感知欺骗的攻击，并提供了ISAC和PLS的理论基础。

Conclusion: 本文为未来网络（如5G、6G）中安全ISAC系统的设计提供了实用指南和理论基础。

Abstract: The sixth generation of wireless networks defined several key performance
indicators (KPIs) for assessing its networks, mainly in terms of reliability,
coverage, and sensing. In this regard, remarkable attention has been paid
recently to the integrated sensing and communication (ISAC) paradigm as an
enabler for efficiently and jointly performing communication and sensing using
the same spectrum and hardware resources. On the other hand, ensuring
communication and data security has been an imperative requirement for wireless
networks throughout their evolution. The physical-layer security (PLS) concept
paved the way to catering to the security needs in wireless networks in a
sustainable way while guaranteeing theoretically secure transmissions,
independently of the computational capacity of adversaries. Therefore, it is of
paramount importance to consider a balanced trade-off between communication
reliability, sensing, and security in future networks, such as the 5G and
beyond, and the 6G. In this paper, we provide a comprehensive and system-wise
review of designed secure ISAC systems from a PLS point of view. In particular,
the impact of various physical-layer techniques, schemes, and wireless
technologies to ensure the sensing-security trade-off is studied from the
surveyed work. Furthermore, the amalgamation of PLS and ISAC is analyzed in a
broader impact by considering attacks targeting data confidentiality,
communication covertness, and sensing spoofing. The paper also serves as a
tutorial by presenting several theoretical foundations on ISAC and PLS, which
represent a practical guide for readers to develop novel secure ISAC network
designs.

</details>

<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [246] [Comparative Study of Generative Models for Early Detection of Failures in Medical Devices](https://arxiv.org/abs/2505.04845)
*Binesh Sadanandan,Bahareh Arghavani Nobar,Vahid Behzadan*

Main category: eess.SP

TLDR: 论文探讨了三种基于生成式机器学习的故障检测方法，用于医疗设备（如手术缝合器），以提高其安全性。


<details>
  <summary>Details</summary>
Motivation: 医疗设备中复杂电子系统的故障模式难以用传统方法检测，而手术缝合器等低风险设备的故障可能导致严重后果。

Method: 利用传感器数据，评估三种生成式机器学习方法在故障检测中的性能和数据需求。

Result: 研究表明这些方法有潜力提升医疗设备的安全性。

Conclusion: 生成式机器学习方法为医疗设备故障检测提供了有效解决方案。

Abstract: The medical device industry has significantly advanced by integrating
sophisticated electronics like microchips and field-programmable gate arrays
(FPGAs) to enhance the safety and usability of life-saving devices. These
complex electro-mechanical systems, however, introduce challenging failure
modes that are not easily detectable with conventional methods. Effective fault
detection and mitigation become vital as reliance on such electronics grows.
This paper explores three generative machine learning-based approaches for
fault detection in medical devices, leveraging sensor data from surgical
staplers,a class 2 medical device. Historically considered low-risk, these
devices have recently been linked to an increasing number of injuries and
fatalities. The study evaluates the performance and data requirements of these
machine-learning approaches, highlighting their potential to enhance device
safety.

</details>

### [247] [Integrated Image Reconstruction and Target Recognition based on Deep Learning Technique](https://arxiv.org/abs/2505.04836)
*Cien Zhang,Jiaming Zhang,Jiajun He,Okan Yurduseven*

Main category: eess.SP

TLDR: Att-ClassiGAN结合注意力机制改进ClassiGAN，显著提升计算微波成像的图像重建和分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决计算微波成像（CMI）在图像重建和分类阶段的高计算需求问题。

Method: 在ClassiGAN中引入注意力门模块，动态聚焦重要特征并抑制无关信息。

Result: Att-ClassiGAN减少了重建时间，提升了NMSE、SSIM和分类准确性。

Conclusion: Att-ClassiGAN优于传统CMI方法，为计算微波成像提供了高效解决方案。

Abstract: Computational microwave imaging (CMI) has gained attention as an alternative
technique for conventional microwave imaging techniques, addressing their
limitations such as hardware-intensive physical layer and slow data collection
acquisition speed to name a few. Despite these advantages, CMI still encounters
notable computational bottlenecks, especially during the image reconstruction
stage. In this setting, both image recovery and object classification present
significant processing demands. To address these challenges, our previous work
introduced ClassiGAN, which is a generative deep learning model designed to
simultaneously reconstruct images and classify targets using only
back-scattered signals. In this study, we build upon that framework by
incorporating attention gate modules into ClassiGAN. These modules are intended
to refine feature extraction and improve the identification of relevant
information. By dynamically focusing on important features and suppressing
irrelevant ones, the attention mechanism enhances the overall model
performance. The proposed architecture, named Att-ClassiGAN, significantly
reduces the reconstruction time compared to traditional CMI approaches.
Furthermore, it outperforms current advanced methods, delivering improved
Normalized Mean Squared Error (NMSE), higher Structural Similarity Index
(SSIM), and better classification outcomes for the reconstructed targets.

</details>

### [248] [From Sleep Staging to Spindle Detection: Evaluating End-to-End Automated Sleep Analysis](https://arxiv.org/abs/2505.05371)
*Niklas Grieger,Siamak Mehrkanoon,Philipp Ritter,Stephan Bialonski*

Main category: eess.SP

TLDR: 论文研究了自动化睡眠分析的可行性，结合了睡眠分期和纺锤波检测，验证了其在双相情感障碍研究中的效果，并展示了自动化工具在大规模睡眠研究中的潜力。


<details>
  <summary>Details</summary>
Motivation: 自动化睡眠分析可以减少人为误差并提高效率，但目前多步骤自动化分析的可行性尚不明确。

Method: 使用RobustSleepNet进行睡眠分期，SUMOv2进行纺锤波检测，并与专家研究结果对比。

Result: 自动化分析在定性上复现了专家研究的关键发现，但定量结果存在差异；模型性能达到或超过评分者间一致性。

Conclusion: 全自动化方法有助于大规模睡眠研究，并公开了相关工具和平台。

Abstract: Automation of sleep analysis, including both macrostructural (sleep stages)
and microstructural (e.g., sleep spindles) elements, promises to enable
large-scale sleep studies and to reduce variance due to inter-rater
incongruencies. While individual steps, such as sleep staging and spindle
detection, have been studied separately, the feasibility of automating
multi-step sleep analysis remains unclear. Here, we evaluate whether a fully
automated analysis using state-of-the-art machine learning models for sleep
staging (RobustSleepNet) and subsequent spindle detection (SUMOv2) can
replicate findings from an expert-based study of bipolar disorder. The
automated analysis qualitatively reproduced key findings from the expert-based
study, including significant differences in fast spindle densities between
bipolar patients and healthy controls, accomplishing in minutes what previously
took months to complete manually. While the results of the automated analysis
differed quantitatively from the expert-based study, possibly due to biases
between expert raters or between raters and the models, the models individually
performed at or above inter-rater agreement for both sleep staging and spindle
detection. Our results demonstrate that fully automated approaches have the
potential to facilitate large-scale sleep research. We are providing public
access to the tools used in our automated analysis by sharing our code and
introducing SomnoBot, a privacy-preserving sleep analysis platform.

</details>

<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [249] [Robustly optimal dynamics for active matter reservoir computing](https://arxiv.org/abs/2505.05420)
*Mario U. Gaimann,Miriam Klopotek*

Main category: nlin.AO

TLDR: 研究发现活性物质在储层计算中具有优异的信息处理能力，揭示了一个被忽视的动态机制，该机制在多种物理参数和任务中表现稳健，为物理系统的计算提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 探索活性物质在储层计算中的信息处理能力，以理解物理系统如何高效完成计算和推断任务。

Method: 使用模拟系统研究活性物质的动态行为，特别关注其内在松弛能力对信息处理的影响。

Result: 发现一个动态机制，位于临界阻尼阈值以下，表现出多阶段松弛特性，在混沌驱动下具有适应性。

Conclusion: 该研究为物理系统的计算和推断提供了新视角，揭示了多体非平衡物理在信息处理中的潜力。

Abstract: We study the information processing abilities of active matter in the
reservoir computing (RC) paradigm, using a model that is externally driven to
infer the future state of a chaotic signal. The simulated system closely
follows a previously reported model. We uncover an exceptional dynamical regime
of agent dynamics that has been overlooked heretofore. It appears robustly
optimal across varying physical parameters and inference tasks, thus providing
valuable insights into computation and inference with physical systems more
generally. The ability to form effective mechanisms for information processing
are primarily determined by the system's own intrinsic relaxation abilities.
These are identifiable when probing the system without a specific inference
goal and manifest when testing minimalistic single-particle reservoirs. The
regime that achieves optimal computation is situated just below the critical
damping threshold, involving a microscopic dynamical relaxation with multiple
stages. The optimal system is adaptable under chaotic external driving, due to
a diversity in response mechanisms that emerge like rapid alternations between
quasi-stationary and highly nonlinear dynamical states. Both coherent and
incoherent dynamics contribute to their operation, partly at dissimilar scales
of space and delay time. Correlations on agent dynamics can indicate the
best-performing regimes and onsets of tight relationships between the
responding system and the fluctuating driver. As this model of computation is
interpretable in physical terms, it facilitates re-framing inquiries regarding
learning and unconventional computing with a fresh rationale for many-body
physics out of equilibrium.

</details>

<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [250] [Exploring Zero-Shot App Review Classification with ChatGPT: Challenges and Potential](https://arxiv.org/abs/2505.04759)
*Mohit Chaudhary,Chirag Jain,Preethu Rose Anish*

Main category: cs.SE

TLDR: 该论文探讨了利用ChatGPT进行零样本学习，将应用评论分类为功能需求、非功能需求、两者兼具或两者皆非，并在1880条手动标注的评论数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 应用评论是用户反馈的重要来源，但传统分类方法需要大量领域特定数据，成本高且耗时。研究旨在探索零样本学习的潜力，以更高效地分类评论。

Method: 使用ChatGPT进行零样本学习，对来自10个不同应用的1880条评论进行分类，并评估其性能。

Result: ChatGPT在评论分类中达到了0.842的F1分数，同时分析了评论可读性和长度对分类准确性的影响。

Conclusion: 尽管存在挑战，ChatGPT在零样本学习下能有效分类应用评论，为开发决策提供支持。

Abstract: App reviews are a critical source of user feedback, offering valuable
insights into an app's performance, features, usability, and overall user
experience. Effectively analyzing these reviews is essential for guiding app
development, prioritizing feature updates, and enhancing user satisfaction.
Classifying reviews into functional and non-functional requirements play a
pivotal role in distinguishing feedback related to specific app features
(functional requirements) from feedback concerning broader quality attributes,
such as performance, usability, and reliability (non-functional requirements).
Both categories are integral to informed development decisions. Traditional
approaches to classifying app reviews are hindered by the need for large,
domain-specific datasets, which are often costly and time-consuming to curate.
This study explores the potential of zero-shot learning with ChatGPT for
classifying app reviews into four categories: functional requirement,
non-functional requirement, both, or neither. We evaluate ChatGPT's performance
on a benchmark dataset of 1,880 manually annotated reviews from ten diverse
apps spanning multiple domains. Our findings demonstrate that ChatGPT achieves
a robust F1 score of 0.842 in review classification, despite certain challenges
and limitations. Additionally, we examine how factors such as review
readability and length impact classification accuracy and conduct a manual
analysis to identify review categories more prone to misclassification.

</details>

### [251] [PR2: Peephole Raw Pointer Rewriting with LLMs for Translating C to Safer Rust](https://arxiv.org/abs/2505.04852)
*Yifei Gao,Chengpeng Wang,Pengxiang Huang,Xuwei Liu,Mingwei Zheng,Xiangyu Zhang*

Main category: cs.SE

TLDR: 该论文提出了一种名为PR2的技术，通过消除C2RUST生成的Rust代码中的原始指针，提升内存安全性。


<details>
  <summary>Details</summary>
Motivation: 由于Rust的内存和线程安全特性，将C代码转换为Rust的需求增加，但现有工具生成的Rust代码仍依赖不安全的原始指针。

Method: 采用基于决策树的提示技术（peephole raw pointer rewriting）将原始指针提升为合适的Rust数据结构，并结合代码变更分析修复错误。

Result: 在28个真实C项目中，PR2成功消除了13.22%的本地原始指针，平均每个项目转换耗时5.44小时，成本1.46美元。

Conclusion: PR2显著提升了转换后Rust代码的安全性，且具备实用性和经济性。

Abstract: There has been a growing interest in translating C code to Rust due to Rust's
robust memory and thread safety guarantees. Tools such as C2RUST enable
syntax-guided transpilation from C to semantically equivalent Rust code.
However, the resulting Rust programs often rely heavily on unsafe
constructs--particularly raw pointers--which undermines Rust's safety
guarantees. This paper aims to improve the memory safety of Rust programs
generated by C2RUST by eliminating raw pointers. Specifically, we propose a
peephole raw pointer rewriting technique that lifts raw pointers in individual
functions to appropriate Rust data structures. Technically, PR2 employs
decision-tree-based prompting to guide the pointer lifting process.
Additionally, it leverages code change analysis to guide the repair of errors
introduced during rewriting, effectively addressing errors encountered during
compilation and test case execution. We implement PR2 as a prototype and
evaluate it using gpt-4o-mini on 28 real-world C projects. The results show
that PR2 successfully eliminates 13.22% of local raw pointers across these
projects, significantly enhancing the safety of the translated Rust code. On
average, PR2 completes the transformation of a project in 5.44 hours, at an
average cost of $1.46.

</details>

### [252] [Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents](https://arxiv.org/abs/2505.05283)
*Kaixin Wang,Tianlin Li,Xiaoyu Zhang,Chong Wang,Weisong Sun,Yang Liu,Bin Shi*

Main category: cs.SE

TLDR: 本文综述了181个CodeLLMs和智能体基准测试，发现其在软件开发生命周期（SDLC）中的分布不均，主要集中在开发阶段，而需求工程和设计阶段覆盖较少。Python是主导语言。


<details>
  <summary>Details</summary>
Motivation: 填补CodeLLMs和智能体基准测试缺乏全面综述的空白，评估其能力并指导未来发展。

Method: 分析461篇相关论文中的181个基准测试，覆盖SDLC各阶段。

Result: 60%基准测试聚焦开发阶段，需求工程和设计阶段仅占5%和3%；Python为主流语言。

Conclusion: 当前研究存在不平衡，需缩小CodeLLMs和智能体理论与实际应用的差距。

Abstract: Code large language models (CodeLLMs) and agents have shown great promise in
tackling complex software engineering tasks.Compared to traditional software
engineering methods, CodeLLMs and agents offer stronger abilities, and can
flexibly process inputs and outputs in both natural and code. Benchmarking
plays a crucial role in evaluating the capabilities of CodeLLMs and agents,
guiding their development and deployment. However, despite their growing
significance, there remains a lack of comprehensive reviews of benchmarks for
CodeLLMs and agents. To bridge this gap, this paper provides a comprehensive
review of existing benchmarks for CodeLLMs and agents, studying and analyzing
181 benchmarks from 461 relevant papers, covering the different phases of the
software development life cycle (SDLC). Our findings reveal a notable imbalance
in the coverage of current benchmarks, with approximately 60% focused on the
software development phase in SDLC, while requirements engineering and software
design phases receive minimal attention at only 5% and 3%, respectively.
Additionally, Python emerges as the dominant programming language across the
reviewed benchmarks. Finally, this paper highlights the challenges of current
research and proposes future directions, aiming to narrow the gap between the
theoretical capabilities of CodeLLMs and agents and their application in
real-world scenarios.

</details>

<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [253] [Proceedings The 13th International Workshop on Theorem proving components for Educational software](https://arxiv.org/abs/2505.04677)
*Julien Narboux,Walther Neuper,Pedro Quaresma*

Main category: cs.LO

TLDR: ThEdu系列旨在通过定理证明技术促进中学数学到STEM教育的过渡，本次会议汇集了相关研究论文。


<details>
  <summary>Details</summary>
Motivation: 推动数学教育从直觉化向形式化过渡，并利用定理证明技术提供软件支持。

Method: 通过国际研讨会（ThEdu'24）征集和评审论文，涵盖从自动推理研究到教育应用的广泛主题。

Result: 收录了8篇论文，展示了定理证明在教育中的应用潜力。

Conclusion: 希望这些研究能促进定理证明软件的发展，并加强计算机科学家、数学家和教育工作者之间的合作。

Abstract: The ThEdu series pursues the smooth transition from an intuitive way of doing
mathematics at secondary school to a more formal approach to the subject in
STEM education while favoring software support for this transition by
exploiting the power of theorem-proving technologies. What follows is a brief
description of how the present volume contributes to this enterprise. The 13th
International Workshop on Theorem Proving Components for Educational Software
(ThEdu'24), was a satellite event of the CADE29, part of IJCAR 2024, Nancy,
France. ThEdu'24 was a vibrant workshop, with one invited talk by Jeremy Avigad
(Carnegie Mellon University) and 14 submitted talks. An open call for papers
was then issued and attracted 9 submissions. Eight of those submissions have
been accepted by our reviewers. The resulting revised papers are collected in
the present volume. The contributions in this volume are a faithful
representation of the wide spectrum of ThEdu, ranging from those more focused
on the automated deduction research, not losing track of the possible
applications in an educational setting, to those focused on the applications,
in educational settings, of automated deduction tools and methods. We, the
volume editors, hope that this collection of papers will further promote the
development of theorem-proving-based software and that it will allow to improve
the mutual understanding between computer scientists, mathematicians, and
stakeholders in education. While this volume goes to press, the next edition of
the ThEdu workshop is being prepared: ThEdu'25 will be a satellite event of the
30th international Conference on Automated DEduction (CADE-30), July 28th -
August 2nd, 2025, Stuttgart, Germany.

</details>

<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [254] [Multimodal Benchmarking and Recommendation of Text-to-Image Generation Models](https://arxiv.org/abs/2505.04650)
*Kapil Wanaskar,Gaytri Jena,Magdalini Eirinaki*

Main category: cs.GR

TLDR: 本文提出了一个开源的文本到图像生成模型评估框架，重点关注元数据增强提示的影响，并通过定量和定性分析验证其效果。


<details>
  <summary>Details</summary>
Motivation: 研究元数据增强提示对文本到图像生成模型性能的影响，并提供统一的评估框架。

Method: 利用DeepFashion-MultiModal数据集，结合多种定量指标（如Weighted Score、CLIP相似性、LPIPS、FID等）和定性分析评估模型输出。

Result: 结果表明，结构化元数据增强显著提升了视觉真实性、语义保真度和模型鲁棒性。

Conclusion: 该框架虽非传统推荐系统，但能基于评估指标为模型选择和提示设计提供任务特定建议。

Abstract: This work presents an open-source unified benchmarking and evaluation
framework for text-to-image generation models, with a particular focus on the
impact of metadata augmented prompts. Leveraging the DeepFashion-MultiModal
dataset, we assess generated outputs through a comprehensive set of
quantitative metrics, including Weighted Score, CLIP (Contrastive Language
Image Pre-training)-based similarity, LPIPS (Learned Perceptual Image Patch
Similarity), FID (Frechet Inception Distance), and retrieval-based measures, as
well as qualitative analysis. Our results demonstrate that structured metadata
enrichments greatly enhance visual realism, semantic fidelity, and model
robustness across diverse text-to-image architectures. While not a traditional
recommender system, our framework enables task-specific recommendations for
model selection and prompt design based on evaluation metrics.

</details>

### [255] [ChannelExplorer: Exploring Class Separability Through Activation Channel Visualization](https://arxiv.org/abs/2505.04647)
*Md Rahat-uz- Zaman,Bei Wang,Paul Rosen*

Main category: cs.GR

TLDR: ChannelExplorer是一个交互式可视化工具，用于分析DNN模型中不同层和通道对类别可分性的贡献，支持多种模型架构，并通过四个用例展示其功能。


<details>
  <summary>Details</summary>
Motivation: 理解DNN内部行为，尤其是不同层和激活通道如何影响类别可分性，是当前研究的挑战。

Method: 开发了ChannelExplorer工具，提供散点图、Jaccard相似性和热力图三种视图，支持多种模型架构。

Result: 工具在ImageNet类别层次生成、错误标记图像识别、激活通道贡献分析和Stable Diffusion潜在状态定位中表现出色。

Conclusion: ChannelExplorer为DNN行为分析提供了有效工具，并通过专家评估验证了其实用性。

Abstract: Deep neural networks (DNNs) achieve state-of-the-art performance in many
vision tasks, yet understanding their internal behavior remains challenging,
particularly how different layers and activation channels contribute to class
separability. We introduce ChannelExplorer, an interactive visual analytics
tool for analyzing image-based outputs across model layers, emphasizing
data-driven insights over architecture analysis for exploring class
separability. ChannelExplorer summarizes activations across layers and
visualizes them using three primary coordinated views: a Scatterplot View to
reveal inter- and intra-class confusion, a Jaccard Similarity View to quantify
activation overlap, and a Heatmap View to inspect activation channel patterns.
Our technique supports diverse model architectures, including CNNs, GANs,
ResNet and Stable Diffusion models. We demonstrate the capabilities of
ChannelExplorer through four use-case scenarios: (1) generating class hierarchy
in ImageNet, (2) finding mislabeled images, (3) identifying activation channel
contributions, and(4) locating latent states' position in Stable Diffusion
model. Finally, we evaluate the tool with expert users.

</details>

### [256] [ADD: Physics-Based Motion Imitation with Adversarial Differential Discriminators](https://arxiv.org/abs/2505.04961)
*Ziyu Zhang,Sergey Bashkirov,Dun Yang,Michael Taylor,Xue Bin Peng*

Main category: cs.GR

TLDR: 提出了一种新型对抗性多目标优化技术，适用于包括运动跟踪在内的多目标优化问题，无需手动调整奖励函数。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖手动调整聚合函数，耗时且依赖专家经验，限制了适用性。

Method: 使用对抗性差分判别器，仅需单个正样本即可指导优化过程。

Result: 实现了高质量的运动跟踪效果，与现有方法相当，无需手动调整奖励函数。

Conclusion: 该方法在多目标优化问题中具有广泛适用性，尤其在运动跟踪领域表现优异。

Abstract: Multi-objective optimization problems, which require the simultaneous
optimization of multiple terms, are prevalent across numerous applications.
Existing multi-objective optimization methods often rely on manually tuned
aggregation functions to formulate a joint optimization target. The performance
of such hand-tuned methods is heavily dependent on careful weight selection, a
time-consuming and laborious process. These limitations also arise in the
setting of reinforcement-learning-based motion tracking for physically
simulated characters, where intricately crafted reward functions are typically
used to achieve high-fidelity results. Such solutions not only require domain
expertise and significant manual adjustment, but also limit the applicability
of the resulting reward function across diverse skills. To bridge this gap, we
present a novel adversarial multi-objective optimization technique that is
broadly applicable to a range of multi-objective optimization problems,
including motion tracking. The proposed adversarial differential discriminator
receives a single positive sample, yet is still effective at guiding the
optimization process. We demonstrate that our technique can enable characters
to closely replicate a variety of acrobatic and agile behaviors, achieving
comparable quality to state-of-the-art motion-tracking methods, without relying
on manually tuned reward functions. Results are best visualized through
https://youtu.be/rz8BYCE9E2w.

</details>

### [257] [WIR3D: Visually-Informed and Geometry-Aware 3D Shape Abstraction](https://arxiv.org/abs/2505.04813)
*Richard Liu,Daniel Fu,Noah Tan,Itai Lang,Rana Hanocka*

Main category: cs.GR

TLDR: WIR3D是一种通过稀疏的视觉有意义曲线抽象3D形状的技术，利用Bezier曲线优化和CLIP模型指导，分两阶段优化几何和细节特征，支持用户控制和形状变形。


<details>
  <summary>Details</summary>
Motivation: 旨在通过稀疏曲线高效且直观地表示3D形状的几何和视觉特征，同时支持用户对抽象特征的操控。

Method: 分两阶段优化Bezier曲线参数：第一阶段捕捉粗粒度几何，第二阶段通过局部关键点损失和神经SDF损失细化特征。

Result: 成功应用于多种复杂度和纹理的3D形状抽象，并展示了特征控制和形状变形的下游应用。

Conclusion: WIR3D提供了一种高效且可控的3D形状抽象方法，适用于多种应用场景。

Abstract: We present WIR3D, a technique for abstracting 3D shapes through a sparse set
of visually meaningful curves in 3D. We optimize the parameters of Bezier
curves such that they faithfully represent both the geometry and salient visual
features (e.g. texture) of the shape from arbitrary viewpoints. We leverage the
intermediate activations of a pre-trained foundation model (CLIP) to guide our
optimization process. We divide our optimization into two phases: one for
capturing the coarse geometry of the shape, and the other for representing
fine-grained features. Our second phase supervision is spatially guided by a
novel localized keypoint loss. This spatial guidance enables user control over
abstracted features. We ensure fidelity to the original surface through a
neural SDF loss, which allows the curves to be used as intuitive deformation
handles. We successfully apply our method for shape abstraction over a broad
dataset of shapes with varying complexity, geometric structure, and texture,
and demonstrate downstream applications for feature control and shape
deformation.

</details>

### [258] [Inter-Diffusion Generation Model of Speakers and Listeners for Effective Communication](https://arxiv.org/abs/2505.04996)
*Jinhe Huang,Yongkang Cheng,Yuming Hang,Gaoge Han,Jinewei Li,Jing Zhang,Xingjian Gu*

Main category: cs.GR

TLDR: 该论文提出了一种创新的交互扩散生成模型，首次将听众的全身动作纳入生成框架，通过设计交互扩散机制，实现了说话者和听众之间的动态互动。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注说话者的动作生成，忽略了听众在互动中的关键作用，未能充分探索两者间的动态互动。

Method: 基于扩散模型架构，引入交互条件和GAN模型以增加去噪步长，实现说话者和听众的协同互动。

Result: 实验表明，该模型在生成动作的自然性、连贯性和语音-动作同步性上显著优于现有方法。

Conclusion: 该模型更接近真实的人类互动场景，为有效沟通提供了更强支持。

Abstract: Full-body gestures play a pivotal role in natural interactions and are
crucial for achieving effective communication. Nevertheless, most existing
studies primarily focus on the gesture generation of speakers, overlooking the
vital role of listeners in the interaction process and failing to fully explore
the dynamic interaction between them. This paper innovatively proposes an
Inter-Diffusion Generation Model of Speakers and Listeners for Effective
Communication. For the first time, we integrate the full-body gestures of
listeners into the generation framework. By devising a novel inter-diffusion
mechanism, this model can accurately capture the complex interaction patterns
between speakers and listeners during communication. In the model construction
process, based on the advanced diffusion model architecture, we innovatively
introduce interaction conditions and the GAN model to increase the denoising
step size. As a result, when generating gesture sequences, the model can not
only dynamically generate based on the speaker's speech information but also
respond in realtime to the listener's feedback, enabling synergistic
interaction between the two. Abundant experimental results demonstrate that
compared with the current state-of-the-art gesture generation methods, the
model we proposed has achieved remarkable improvements in the naturalness,
coherence, and speech-gesture synchronization of the generated gestures. In the
subjective evaluation experiments, users highly praised the generated
interaction scenarios, believing that they are closer to real life human
communication situations. Objective index evaluations also show that our model
outperforms the baseline methods in multiple key indicators, providing more
powerful support for effective communication.

</details>

### [259] [An Active Contour Model for Silhouette Vectorization using Bézier Curves](https://arxiv.org/abs/2505.05132)
*Luis Alvarez,Jean-Michel Morel*

Main category: cs.GR

TLDR: 提出了一种基于三次贝塞尔曲线的主动轮廓模型，用于轮廓矢量化，显著减少了轮廓边界与矢量化结果的平均距离。


<details>
  <summary>Details</summary>
Motivation: 改进现有轮廓矢量化方法的精度，尤其是在处理贝塞尔曲线时优化端点位置和切线方向。

Method: 通过最小化贝塞尔曲线与轮廓边界的距离，优化端点位置、切线方向和曲线参数，并可利用其他方法的矢量化结果作为初始猜测。

Result: 相比世界级图形软件（如Inkscape、Adobe Illustrator）和基于曲率的矢量化方法，显著减少了平均距离。

Conclusion: 该方法不仅提高了矢量化精度，还能通过减少曲线长度增加贝塞尔曲线的规则性。

Abstract: In this paper, we propose an active contour model for silhouette
vectorization using cubic B\'ezier curves. Among the end points of the B\'ezier
curves, we distinguish between corner and regular points where the orientation
of the tangent vector is prescribed. By minimizing the distance of the B\'ezier
curves to the silhouette boundary, the active contour model optimizes the
location of the B\'ezier curves end points, the orientation of the tangent
vectors in the regular points, and the estimation of the B\'ezier curve
parameters. This active contour model can use the silhouette vectorization
obtained by any method as an initial guess. The proposed method significantly
reduces the average distance between the silhouette boundary and its
vectorization obtained by the world-class graphic software Inkscape, Adobe
Illustrator, and a curvature-based vectorization method, which we introduce for
comparison. Our method also allows us to impose additional regularity on the
B\'ezier curves by reducing their lengths.

</details>

### [260] [Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields](https://arxiv.org/abs/2505.05356)
*Runfeng Li,Mikhail Okunev,Zixuan Guo,Anh Ha Duong,Christian Richardt,Matthew O'Toole,James Tompkin*

Main category: cs.GR

TLDR: 提出一种基于单目连续波飞行时间（C-ToF）相机的动态场景重建方法，比神经体积方法更准确且快100倍。


<details>
  <summary>Details</summary>
Motivation: 从单视角快速实现高保真动态3D重建是计算机视觉中的重大挑战，而C-ToF中的深度信息不直接测量增加了难度。

Method: 在优化中引入两种启发式方法，改进高斯表示的场景几何精度。

Result: 实验表明，该方法在受限C-ToF感知条件下（如快速运动的棒球棒）能准确重建。

Conclusion: 该方法在动态场景重建中表现出色，解决了C-ToF数据优化的脆弱性问题。

Abstract: We present a method to reconstruct dynamic scenes from monocular
continuous-wave time-of-flight (C-ToF) cameras using raw sensor samples that
achieves similar or better accuracy than neural volumetric approaches and is
100x faster. Quickly achieving high-fidelity dynamic 3D reconstruction from a
single viewpoint is a significant challenge in computer vision. In C-ToF
radiance field reconstruction, the property of interest-depth-is not directly
measured, causing an additional challenge. This problem has a large and
underappreciated impact upon the optimization when using a fast primitive-based
scene representation like 3D Gaussian splatting, which is commonly used with
multi-view data to produce satisfactory results and is brittle in its
optimization otherwise. We incorporate two heuristics into the optimization to
improve the accuracy of scene geometry represented by Gaussians. Experimental
results show that our approach produces accurate reconstructions under
constrained C-ToF sensing conditions, including for fast motions like swinging
baseball bats. https://visual.cs.brown.edu/gftorf

</details>

<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [261] [BitHEP -- The Limits of Low-Precision ML in HEP](https://arxiv.org/abs/2504.03387)
*Claudius Krause,Daohan Wang,Ramon Winterhalder*

Main category: hep-ph

TLDR: BitNet在分类任务中表现优异，但在回归和生成任务中表现因网络规模和类型而异，存在改进空间。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络架构的复杂性增加，需要快速且内存高效的实现以缓解计算瓶颈。

Method: 评估BitNet在HEP应用中的性能，包括分类、回归和生成建模任务，并与现有方法比较效率和准确性。

Result: BitNet在分类任务中表现优异，但在回归和生成任务中表现不稳定，受网络规模和类型影响。

Conclusion: BitNet在分类任务中具有竞争力，但在其他任务中需进一步优化，以提升性能。

Abstract: The increasing complexity of modern neural network architectures demands fast
and memory-efficient implementations to mitigate computational bottlenecks. In
this work, we evaluate the recently proposed BitNet architecture in HEP
applications, assessing its performance in classification, regression, and
generative modeling tasks. Specifically, we investigate its suitability for
quark-gluon discrimination, SMEFT parameter estimation, and detector
simulation, comparing its efficiency and accuracy to state-of-the-art methods.
Our results show that while BitNet consistently performs competitively in
classification tasks, its performance in regression and generation varies with
the size and type of the network, highlighting key limitations and potential
areas for improvement.

</details>

<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [262] [Local linear Fréchet curve regression in manifolds](https://arxiv.org/abs/2505.05168)
*M. D. Ruiz-Medina,A. Torres--Signes*

Main category: math.ST

TLDR: 论文解决了从时间相关的双变量曲线数据中局部线性逼近Fréchet条件均值的问题，提出了外在和内在两种方法，并通过模拟和实际数据验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 针对流形中评估的时间相关双变量曲线数据，解决局部线性逼近Fréchet条件均值的问题。

Method: 外在方法通过投影到希尔伯特空间的正交基中实现；内在方法采用加权Fréchet均值。两种方法均通过指数和对数映射计算。

Result: 证明了内在局部逼近的渐近最优性，并通过模拟和NASA的MAGSAT卫星数据验证了预测器的性能。

Conclusion: 论文提出的外在和内在局部线性Fréchet功能回归预测器在实际应用中表现良好，具有理论保证。

Abstract: Global Fr\'echet functional regression has been recently addressed from time
correlated bivariate curve data evaluated in a manifold (see Torres et al.
2025). For this type of curve data sets, the present paper solves the problem
of local linear approximation of the Fr\'echet conditional mean in an extrinsic
and intrinsic way. The extrinsic local linear Fr\'echet functional regression
predictor is obtained in the time varying tangent space by projection into an
orthornormal basis of the ambient Hilbert space. The conditions assumed ensure
the existence and uniqueness of this predictor, and its computation via
exponential and logarithmic maps. A weighted Fr\'echet mean approach is adopted
in the computation of an intrinsic local linear Fr\'echet functional regression
predictor. The asymptotic optimality of this intrinsic local approximation is
also proved. The performance of the empirical version of both, extrinsic and
intrinsic functional predictors, and of a Nadaraya-Watson type Fr\'echet curve
predictor is illustrated in the simulation study undertaken. The finite-sample
size properties are also tested in a real-data application via
cross-validation. Specifically, functional prediction of the magnetic vector
field from the time-varying geocentric latitude and longitude of the satellite
NASA's MAGSAT spacecraft is addressed.

</details>

<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [263] [SSH-Net: A Self-Supervised and Hybrid Network for Noisy Image Watermark Removal](https://arxiv.org/abs/2505.05088)
*Wenyang Liu,Jianjun Gao,Kim-Hui Yap*

Main category: cs.MM

TLDR: SSH-Net是一种自监督混合网络，用于去除图像中的可见水印和噪声，无需成对数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖成对数据集，但实际中难以获取，因此提出自监督方法解决这一问题。

Method: 采用双网络设计：上层网络（轻量CNN）处理噪声，下层网络（含Transformer块）同时去水印和噪声；共享CNN编码器提取共同特征。

Result: SSH-Net有效去除水印和噪声，无需成对数据。

Conclusion: SSH-Net为水印去除提供了一种实用且高效的解决方案。

Abstract: Visible watermark removal is challenging due to its inherent complexities and
the noise carried within images. Existing methods primarily rely on supervised
learning approaches that require paired datasets of watermarked and
watermark-free images, which are often impractical to obtain in real-world
scenarios. To address this challenge, we propose SSH-Net, a Self-Supervised and
Hybrid Network specifically designed for noisy image watermark removal. SSH-Net
synthesizes reference watermark-free images using the watermark distribution in
a self-supervised manner and adopts a dual-network design to address the task.
The upper network, focused on the simpler task of noise removal, employs a
lightweight CNN-based architecture, while the lower network, designed to handle
the more complex task of simultaneously removing watermarks and noise,
incorporates Transformer blocks to model long-range dependencies and capture
intricate image features. To enhance the model's effectiveness, a shared
CNN-based feature encoder is introduced before dual networks to extract common
features that both networks can leverage. Our code will be available at
https://github.com/wenyang001/SSH-Net.

</details>

<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [264] [Facets of Disparate Impact: Evaluating Legally Consistent Bias in Machine Learning](https://arxiv.org/abs/2505.05471)
*Jarren Briscoe,Assefaw Gebremedhin*

Main category: cs.CY

TLDR: 论文提出了一种名为'客观公平指数'的新指标，结合了边际效益和客观测试，用于衡量机器学习应用中的偏见，并在COMPAS等敏感应用中验证了其理论和实践意义。


<details>
  <summary>Details</summary>
Motivation: 当前法律标准下，如何定义和衡量机器学习中的偏见是一个重要问题。研究旨在通过结合边际效益和客观测试，提出一个法律一致且可靠的衡量标准。

Method: 提出'客观公平指数'，结合上下文客观测试和指标稳定性，用于区分歧视性测试和系统性差异。

Result: 该指数在COMPAS等敏感机器学习应用中提供了新的见解，验证了其理论和实践意义。

Conclusion: '客观公平指数'为衡量机器学习中的偏见提供了一种法律一致且可靠的方法，具有重要的理论和应用价值。

Abstract: Leveraging current legal standards, we define bias through the lens of
marginal benefits and objective testing with the novel metric "Objective
Fairness Index". This index combines the contextual nuances of objective
testing with metric stability, providing a legally consistent and reliable
measure. Utilizing the Objective Fairness Index, we provide fresh insights into
sensitive machine learning applications, such as COMPAS (recidivism
prediction), highlighting the metric's practical and theoretical significance.
The Objective Fairness Index allows one to differentiate between discriminatory
tests and systemic disparities.

</details>

<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [265] [Generalization Analysis for Contrastive Representation Learning under Non-IID Settings](https://arxiv.org/abs/2505.04937)
*Nong Minh Hieu,Antoine Ledent*

Main category: stat.ML

TLDR: 论文分析了对比表示学习（CRL）在非独立同分布（non-i.i.d.）设置下的泛化行为，提出了基于U统计量的泛化界限。


<details>
  <summary>Details</summary>
Motivation: 现有理论仅分析独立同分布假设下的CRL泛化界限，而实践中数据常被重复使用，导致独立性假设失效。本文旨在填补这一理论空白。

Method: 借鉴U统计量理论，推导非独立同分布下的泛化界限，并应用于线性映射和神经网络等常见函数类。

Result: 泛化界限表明，每类所需样本数与可学习特征表示类的覆盖数对数成正比。

Conclusion: 本文为CRL在非独立同分布设置下的泛化行为提供了理论支持，并验证了其在实际应用中的有效性。

Abstract: Contrastive Representation Learning (CRL) has achieved impressive success in
various domains in recent years. Nevertheless, the theoretical understanding of
the generalization behavior of CRL is limited. Moreover, to the best of our
knowledge, the current literature only analyzes generalization bounds under the
assumption that the data tuples used for contrastive learning are independently
and identically distributed. However, in practice, we are often limited to a
fixed pool of reusable labeled data points, making it inevitable to recycle
data across tuples to create sufficiently large datasets. Therefore, the
tuple-wise independence condition imposed by previous works is invalidated. In
this paper, we provide a generalization analysis for the CRL framework under
non-$i.i.d.$ settings that adheres to practice more realistically. Drawing
inspiration from the literature on U-statistics, we derive generalization
bounds which indicate the required number of samples in each class scales as
the logarithm of the covering number of the class of learnable feature
representations associated to each class. Next, we apply our main results to
derive excess risk bounds for common function classes such as linear maps and
neural networks.

</details>

### [266] [Learning Linearized Models from Nonlinear Systems under Initialization Constraints with Finite Data](https://arxiv.org/abs/2505.04954)
*Lei Xin,Baike She,Qi Dou,George Chiu,Shreyas Sundaram*

Main category: stat.ML

TLDR: 论文提出了一种在非线性动态系统中学习线性化模型的方法，通过多轨迹数据采集和正则化最小二乘法，提供了有限样本误差界。


<details>
  <summary>Details</summary>
Motivation: 现有线性系统辨识方法通常假设动态系统是线性的，并使用单一长轨迹数据。本文研究在非线性动态系统中学习线性化模型的问题，并考虑实验初始化的区域约束。

Method: 提出基于多轨迹的确定性数据采集算法和正则化最小二乘算法。

Result: 提供了有限样本误差界，表明可以一致地学习线性化动态，并展示了非线性和噪声误差之间的权衡。数值实验验证了结果。

Conclusion: 论文证明了在非线性系统中学习线性化模型的可行性，并揭示了单轨迹方法的不足。

Abstract: The identification of a linear system model from data has wide applications
in control theory. The existing work that provides finite sample guarantees for
linear system identification typically uses data from a single long system
trajectory under i.i.d. random inputs, and assumes that the underlying dynamics
is truly linear. In contrast, we consider the problem of identifying a
linearized model when the true underlying dynamics is nonlinear, given that
there is a certain constraint on the region where one can initialize the
experiments. We provide a multiple trajectories-based deterministic data
acquisition algorithm followed by a regularized least squares algorithm, and
provide a finite sample error bound on the learned linearized dynamics. Our
error bound shows that one can consistently learn the linearized dynamics, and
demonstrates a trade-off between the error due to nonlinearity and the error
due to noise. We validate our results through numerical experiments, where we
also show the potential insufficiency of linear system identification using a
single trajectory with i.i.d. random inputs, when nonlinearity does exist.

</details>

### [267] [Conformal Prediction with Cellwise Outliers: A Detect-then-Impute Approach](https://arxiv.org/abs/2505.04986)
*Qian Peng,Yajie Bao,Haojie Ren,Zhaojun Wang,Changliang Zou*

Main category: stat.ML

TLDR: 论文提出了一种名为‘detect-then-impute conformal prediction’的新框架，用于处理测试特征中的异常值，通过检测和填补异常值来保证预测区间的覆盖性。


<details>
  <summary>Details</summary>
Motivation: 传统共形预测在测试特征存在异常值时无法保证交换性，导致覆盖性失效。

Method: 框架先检测测试特征中的异常值，然后填补这些异常值，并通过校准集构建交换性特征。提出了PDI-CP和JDI-CP两种算法。

Result: JDI-CP在有限样本下实现了1-2α的覆盖性保证，实验显示算法具有稳健的覆盖性和与基线相当的效率。

Conclusion: 新框架有效解决了异常值对共形预测的影响，提升了预测区间的可靠性。

Abstract: Conformal prediction is a powerful tool for constructing prediction intervals
for black-box models, providing a finite sample coverage guarantee for
exchangeable data. However, this exchangeability is compromised when some
entries of the test feature are contaminated, such as in the case of cellwise
outliers. To address this issue, this paper introduces a novel framework called
detect-then-impute conformal prediction. This framework first employs an
outlier detection procedure on the test feature and then utilizes an imputation
method to fill in those cells identified as outliers. To quantify the
uncertainty in the processed test feature, we adaptively apply the detection
and imputation procedures to the calibration set, thereby constructing
exchangeable features for the conformal prediction interval of the test label.
We develop two practical algorithms, PDI-CP and JDI-CP, and provide a
distribution-free coverage analysis under some commonly used detection and
imputation procedures. Notably, JDI-CP achieves a finite sample $1-2\alpha$
coverage guarantee. Numerical experiments on both synthetic and real datasets
demonstrate that our proposed algorithms exhibit robust coverage properties and
comparable efficiency to the oracle baseline.

</details>

### [268] [Boosting Statistic Learning with Synthetic Data from Pretrained Large Models](https://arxiv.org/abs/2505.04992)
*Jialong Jiang,Wenkang Hu,Jian Huang,Yuling Jiao,Xu Liu*

Main category: stat.ML

TLDR: 论文提出了一种端到端框架，通过领域特定统计方法生成并筛选合成数据，选择性整合高质量样本以提升预测模型性能。实验表明其有效性，但也指出生成模型在数据增强中的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究生成模型（如Stable Diffusion）生成的合成数据如何有效提升预测模型性能，解决现有方法中仅部分数据能真正提升性能的问题。

Method: 提出一种端到端框架，结合生成模型和领域特定统计方法，系统筛选高质量合成数据用于数据增强。

Result: 实验显示该框架能一致提升预测性能，但也表明生成模型生成的有效数据比例有限。

Conclusion: 框架展示了合成数据在预测建模中的潜力，但需注意生成模型在数据增强中的局限性。

Abstract: The rapid advancement of generative models, such as Stable Diffusion, raises
a key question: how can synthetic data from these models enhance predictive
modeling? While they can generate vast amounts of datasets, only a subset
meaningfully improves performance. We propose a novel end-to-end framework that
generates and systematically filters synthetic data through domain-specific
statistical methods, selectively integrating high-quality samples for effective
augmentation. Our experiments demonstrate consistent improvements in predictive
performance across various settings, highlighting the potential of our
framework while underscoring the inherent limitations of generative models for
data augmentation. Despite the ability to produce large volumes of synthetic
data, the proportion that effectively improves model performance is limited.

</details>

### [269] [A Two-Sample Test of Text Generation Similarity](https://arxiv.org/abs/2505.05269)
*Jingbin Xu,Chen Qian,Meimei Liu,Feng Guo*

Main category: stat.ML

TLDR: 提出了一种基于熵的两样本文本检验方法，用于比较两组文档的相似性，通过神经网络语言模型估计熵，并验证其统计性能。


<details>
  <summary>Details</summary>
Motivation: 数字化文本数据的激增需要可靠的推断方法，以比较两组文档的生成概率映射是否相同。

Method: 使用神经网络语言模型估计文档熵，通过估计-推断框架构建检验统计量，并结合多重数据分割策略提高检验功效。

Result: 理论证明检验统计量渐近服从正态分布，模拟和实际数据表明该方法在控制一类错误的同时具有更高的功效。

Conclusion: 该方法为大规模文本信息的差异检验提供了新解决方案，适用于文本信息关键领域。

Abstract: The surge in digitized text data requires reliable inferential methods on
observed textual patterns. This article proposes a novel two-sample text test
for comparing similarity between two groups of documents. The hypothesis is
whether the probabilistic mapping generating the textual data is identical
across two groups of documents. The proposed test aims to assess text
similarity by comparing the entropy of the documents. Entropy is estimated
using neural network-based language models. The test statistic is derived from
an estimation-and-inference framework, where the entropy is first approximated
using an estimation set, followed by inference on the remaining data set. We
showed theoretically that under mild conditions, the test statistic
asymptotically follows a normal distribution. A multiple data-splitting
strategy is proposed to enhance test power, which combines p-values into a
unified decision. Various simulation studies and a real data example
demonstrated that the proposed two-sample text test maintains the nominal Type
one error rate while offering greater power compared to existing methods. The
proposed method provides a novel solution to assert differences in document
classes, particularly in fields where large-scale textual information is
crucial.

</details>

### [270] [A Connection Between Learning to Reject and Bhattacharyya Divergences](https://arxiv.org/abs/2505.05273)
*Alexander Soen*

Main category: stat.ML

TLDR: 论文提出了一种基于联合理想分布的学习拒绝机制，通过比较统计散度的阈值来实现，发现Bhattacharyya散度比Chow规则更温和。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过学习理想分布来改进模型的拒绝预测能力，特别是通过联合分布而非边际分布。

Method: 提出学习输入和标签的联合理想分布，并基于统计散度（如Bhattacharyya散度）的阈值实现拒绝机制。

Result: 发现基于Bhattacharyya散度的拒绝机制比传统的Chow规则（基于KL散度）更温和。

Conclusion: 联合理想分布和Bhattacharyya散度为拒绝机制提供了新的视角，其表现优于传统方法。

Abstract: Learning to reject provide a learning paradigm which allows for our models to
abstain from making predictions. One way to learn the rejector is to learn an
ideal marginal distribution (w.r.t. the input domain) - which characterizes a
hypothetical best marginal distribution - and compares it to the true marginal
distribution via a density ratio. In this paper, we consider learning a joint
ideal distribution over both inputs and labels; and develop a link between
rejection and thresholding different statistical divergences. We further find
that when one considers a variant of the log-loss, the rejector obtained by
considering the joint ideal distribution corresponds to the thresholding of the
skewed Bhattacharyya divergence between class-probabilities. This is in
contrast to the marginal case - that is equivalent to a typical
characterization of optimal rejection, Chow's Rule - which corresponds to a
thresholding of the Kullback-Leibler divergence. In general, we find that
rejecting via a Bhattacharyya divergence is less aggressive than Chow's Rule.

</details>

<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [271] [Advancing 3D Medical Image Segmentation: Unleashing the Potential of Planarian Neural Networks in Artificial Intelligence](https://arxiv.org/abs/2505.04664)
*Ziyuan Huang,Kevin Huggins,Srikar Bellur*

Main category: eess.IV

TLDR: PNN-UNet是一种基于涡虫神经网络结构的深度学习方法，用于3D医学图像分割，性能优于传统UNet及其变体。


<details>
  <summary>Details</summary>
Motivation: 受涡虫神经系统中大脑和神经索的协调机制启发，设计了一种新型网络结构以提高医学图像分割的准确性。

Method: 结合Deep-UNet和Wide-UNet作为神经索，并通过密集连接的自动编码器模拟大脑功能，形成PNN-UNet架构。

Result: 在3D MRI海马体数据集上，PNN-UNet在图像分割任务中表现优于基准UNet和其他变体。

Conclusion: PNN-UNet通过模仿生物神经网络结构，显著提升了医学图像分割的性能。

Abstract: Our study presents PNN-UNet as a method for constructing deep neural networks
that replicate the planarian neural network (PNN) structure in the context of
3D medical image data. Planarians typically have a cerebral structure
comprising two neural cords, where the cerebrum acts as a coordinator, and the
neural cords serve slightly different purposes within the organism's
neurological system. Accordingly, PNN-UNet comprises a Deep-UNet and a
Wide-UNet as the nerve cords, with a densely connected autoencoder performing
the role of the brain. This distinct architecture offers advantages over both
monolithic (UNet) and modular networks (Ensemble-UNet). Our outcomes on a 3D
MRI hippocampus dataset, with and without data augmentation, demonstrate that
PNN-UNet outperforms the baseline UNet and several other UNet variants in image
segmentation.

</details>

### [272] [Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction](https://arxiv.org/abs/2505.05054)
*Navya Sonal Agarwal,Jan Philipp Schneider,Kanchana Vaishnavi Gandikota,Syed Muhammad Kazim,John Meshreki,Ivo Ihrke,Michael Moeller*

Main category: eess.IV

TLDR: 该论文提出了一种直接在FPM测量数据上分类的方法，避免了高分辨率图像重建的计算成本，使用CNN显著提高了分类性能，并减少了数据量和采集时间。


<details>
  <summary>Details</summary>
Motivation: FPM技术虽然能实现高分辨率和大视场成像，但重建过程计算成本高，尤其是在大视场情况下。因此，研究直接在测量数据上分类的方法以提高效率和性能。

Method: 使用卷积神经网络（CNN）直接从FPM测量序列中提取信息进行分类，并探索通过学习多路复用来减少数据量和采集时间。

Result: CNN在测量序列上的分类性能显著优于单幅带限图像（提升达12%），且比高分辨率图像重建更高效。多路复用技术能在保持分类精度的同时显著减少数据量和采集时间。

Conclusion: 直接在FPM测量数据上分类是一种高效且性能优越的方法，CNN和多路复用技术的结合为实际应用提供了可行的解决方案。

Abstract: The computational imaging technique of Fourier Ptychographic Microscopy (FPM)
enables high-resolution imaging with a wide field of view and can serve as an
extremely valuable tool, e.g. in the classification of cells in medical
applications. However, reconstructing a high-resolution image from tens or even
hundreds of measurements is computationally expensive, particularly for a wide
field of view. Therefore, in this paper, we investigate the idea of classifying
the image content in the FPM measurements directly without performing a
reconstruction step first. We show that Convolutional Neural Networks (CNN) can
extract meaningful information from measurement sequences, significantly
outperforming the classification on a single band-limited image (up to 12 %)
while being significantly more efficient than a reconstruction of a
high-resolution image. Furthermore, we demonstrate that a learned multiplexing
of several raw measurements allows maintaining the classification accuracy
while reducing the amount of data (and consequently also the acquisition time)
significantly.

</details>

### [273] [Rethinking Boundary Detection in Deep Learning-Based Medical Image Segmentation](https://arxiv.org/abs/2505.04652)
*Yi Lin,Dong Zhang,Xiao Fang,Yufan Chen,Kwang-Ting Cheng,Hao Chen*

Main category: eess.IV

TLDR: 提出了一种名为CTO的新型网络架构，结合CNN、ViT和边缘检测算子，用于提升医学图像边界区域的分割精度。


<details>
  <summary>Details</summary>
Motivation: 当前方法在医学图像分割中边界区域的分割效果不佳，需要更精确的解决方案。

Method: CTO采用双流编码器（CNN和StitchViT）和边界引导的解码器，利用边缘检测算子生成二进制边界掩码指导解码过程。

Result: 在多个医学图像数据集上，CTO实现了最先进的精度，同时保持较低的模型复杂度。

Conclusion: CTO通过结合多种技术有效提升了边界分割的准确性，且无需额外数据或标签注入。

Abstract: Medical image segmentation is a pivotal task within the realms of medical
image analysis and computer vision. While current methods have shown promise in
accurately segmenting major regions of interest, the precise segmentation of
boundary areas remains challenging. In this study, we propose a novel network
architecture named CTO, which combines Convolutional Neural Networks (CNNs),
Vision Transformer (ViT) models, and explicit edge detection operators to
tackle this challenge. CTO surpasses existing methods in terms of segmentation
accuracy and strikes a better balance between accuracy and efficiency, without
the need for additional data inputs or label injections. Specifically, CTO
adheres to the canonical encoder-decoder network paradigm, with a dual-stream
encoder network comprising a mainstream CNN stream for capturing local features
and an auxiliary StitchViT stream for integrating long-range dependencies.
Furthermore, to enhance the model's ability to learn boundary areas, we
introduce a boundary-guided decoder network that employs binary boundary masks
generated by dedicated edge detection operators to provide explicit guidance
during the decoding process. We validate the performance of CTO through
extensive experiments conducted on seven challenging medical image segmentation
datasets, namely ISIC 2016, PH2, ISIC 2018, CoNIC, LiTS17, and BTCV. Our
experimental results unequivocally demonstrate that CTO achieves
state-of-the-art accuracy on these datasets while maintaining competitive model
complexity. The codes have been released at:
https://github.com/xiaofang007/CTO.

</details>

### [274] [Advanced 3D Imaging Approach to TSV/TGV Metrology and Inspection Using Only Optical Microscopy](https://arxiv.org/abs/2505.04913)
*Gugeong Sung*

Main category: eess.IV

TLDR: 提出了一种结合混合场显微镜和光度立体视觉的创新方法，用于硅和玻璃通孔的检测，克服了传统光学显微镜的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统光学显微镜技术仅能进行表面检测，难以有效观察硅和玻璃通孔的内部结构。

Method: 通过结合光度立体视觉和传统光学显微镜，利用多种光照条件进行3D重建。

Result: 实验结果表明，该方法能有效捕捉微观缺陷和内部结构，显著提升检测能力。

Conclusion: 该方法在保持高精度和可重复性的同时提高了成本效益，为硅和玻璃通孔检测技术带来重大进步。

Abstract: This paper introduces an innovative approach to silicon and glass via
inspection, which combines hybrid field microscopy with photometric stereo.
Conventional optical microscopy techniques are generally limited to superficial
inspections and struggle to effectively visualize the internal structures of
silicon and glass vias. By utilizing various lighting conditions for 3D
reconstruction, the proposed method surpasses these limitations. By integrating
photometric stereo to the traditional optical microscopy, the proposed method
not only enhances the capability to detect micro-scale defects but also
provides a detailed visualization of depth and edge abnormality, which are
typically not visible with conventional optical microscopy inspection. The
experimental results demonstrated that the proposed method effectively captures
intricate surface details and internal structures. Quantitative comparisons
between the reconstructed models and actual measurements present the capability
of the proposed method to significantly improve silicon and glass via
inspection process. As a result, the proposed method achieves enhanced
cost-effectiveness while maintaining high accuracy and repeatability,
suggesting substantial advancements in silicon and glass via inspection
techniques

</details>

### [275] [MoRe-3DGSMR: Motion-resolved reconstruction framework for free-breathing pulmonary MRI based on 3D Gaussian representation](https://arxiv.org/abs/2505.04959)
*Tengya Peng,Ruyi Zha,Qing Zou*

Main category: eess.IV

TLDR: 提出了一种基于3D高斯表示的无监督运动解析重建框架，用于高分辨率自由呼吸肺部MRI，通过数据平滑和空间变换实现高质量重建。


<details>
  <summary>Details</summary>
Motivation: 解决自由呼吸肺部MRI中运动解析和3D各向同性重建的挑战。

Method: 使用黄金角度径向采样轨迹获取数据，提取呼吸运动信号并分类，应用3DGS重建参考图像，训练患者特异性CNN估计变形向量场生成其余运动状态。

Result: 在六组数据上验证，相比现有方法，图像质量更高（信噪比和对比噪声比更优）。

Conclusion: 该无监督3DGS方法为临床肺部MRI提供了一种高性能的解决方案。

Abstract: This study presents an unsupervised, motion-resolved reconstruction framework
for high-resolution, free-breathing pulmonary magnetic resonance imaging (MRI),
utilizing a three-dimensional Gaussian representation (3DGS). The proposed
method leverages 3DGS to address the challenges of motion-resolved 3D isotropic
pulmonary MRI reconstruction by enabling data smoothing between voxels for
continuous spatial representation. Pulmonary MRI data acquisition is performed
using a golden-angle radial sampling trajectory, with respiratory motion
signals extracted from the center of k-space in each radial spoke. Based on the
estimated motion signal, the k-space data is sorted into multiple respiratory
phases. A 3DGS framework is then applied to reconstruct a reference image
volume from the first motion state. Subsequently, a patient-specific
convolutional neural network is trained to estimate the deformation vector
fields (DVFs), which are used to generate the remaining motion states through
spatial transformation of the reference volume. The proposed reconstruction
pipeline is evaluated on six datasets from six subjects and bench-marked
against three state-of-the-art reconstruction methods. The experimental
findings demonstrate that the proposed reconstruction framework effectively
reconstructs high-resolution, motion-resolved pulmonary MR images. Compared
with existing approaches, it achieves superior image quality, reflected by
higher signal-to-noise ratio and contrast-to-noise ratio. The proposed
unsupervised 3DGS-based reconstruction method enables accurate motion-resolved
pulmonary MRI with isotropic spatial resolution. Its superior performance in
image quality metrics over state-of-the-art methods highlights its potential as
a robust solution for clinical pulmonary MR imaging.

</details>

### [276] [ADNP-15: An Open-Source Histopathological Dataset for Neuritic Plaque Segmentation in Human Brain Whole Slide Images with Frequency Domain Image Enhancement for Stain Normalization](https://arxiv.org/abs/2505.05041)
*Chenxi Zhao,Jianqiang Li,Qing Zhao,Jing Bai,Susana Boluda,Benoit Delatour,Lev Stimmer,Daniel Racoceanu,Gabriel Jimenez,Guanghui Fu*

Main category: eess.IV

TLDR: 该研究提出了一个开源数据集ADNP-15，用于阿尔茨海默病中神经炎斑块的分割，并评估了五种深度学习模型和四种染色归一化技术，同时提出了一种新的图像增强方法以提高分割准确性。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的神经炎斑块分割因缺乏大规模标注数据集和染色变异的影响而具有挑战性，研究旨在解决这些问题。

Method: 研究引入ADNP-15数据集，评估五种深度学习模型和四种染色归一化技术，并提出一种新的图像增强方法。

Result: 实验结果表明，提出的图像增强方法显著提高了模型泛化能力和分割准确性。

Conclusion: 研究提供了开源数据集和代码，促进了阿尔茨海默病病理图像分割领域的透明性和可重复性。

Abstract: Alzheimer's Disease (AD) is a neurodegenerative disorder characterized by
amyloid-beta plaques and tau neurofibrillary tangles, which serve as key
histopathological features. The identification and segmentation of these
lesions are crucial for understanding AD progression but remain challenging due
to the lack of large-scale annotated datasets and the impact of staining
variations on automated image analysis. Deep learning has emerged as a powerful
tool for pathology image segmentation; however, model performance is
significantly influenced by variations in staining characteristics,
necessitating effective stain normalization and enhancement techniques. In this
study, we address these challenges by introducing an open-source dataset
(ADNP-15) of neuritic plaques (i.e., amyloid deposits combined with a crown of
dystrophic tau-positive neurites) in human brain whole slide images. We
establish a comprehensive benchmark by evaluating five widely adopted deep
learning models across four stain normalization techniques, providing deeper
insights into their influence on neuritic plaque segmentation. Additionally, we
propose a novel image enhancement method that improves segmentation accuracy,
particularly in complex tissue structures, by enhancing structural details and
mitigating staining inconsistencies. Our experimental results demonstrate that
this enhancement strategy significantly boosts model generalization and
segmentation accuracy. All datasets and code are open-source, ensuring
transparency and reproducibility while enabling further advancements in the
field.

</details>

### [277] [RepSNet: A Nucleus Instance Segmentation model based on Boundary Regression and Structural Re-parameterization](https://arxiv.org/abs/2505.05073)
*Shengchun Xiong,Xiangru Li,Yunpeng Zhong,Wanfen Peng*

Main category: eess.IV

TLDR: RepSNet是一种基于核边界回归和结构重参数化的神经网络模型，用于H&E染色组织病理图像中核的分割和分类，解决了计算效率和重叠目标处理的挑战。


<details>
  <summary>Details</summary>
Motivation: 病理诊断是肿瘤诊断的金标准，核实例分割是数字病理分析和病理诊断的关键步骤，但计算效率和重叠目标处理是主要挑战。

Method: RepSNet通过核边界位置信息（BPI）估计和边界投票机制（BVM）实现核边界分割，并采用结构重参数化技术减少模型参数和计算负担。

Result: 实验表明，RepSNet在多个典型基准模型上表现出优越性。

Conclusion: RepSNet通过宏观信息引导和结构优化，显著提升了核分割的准确性和效率。

Abstract: Pathological diagnosis is the gold standard for tumor diagnosis, and nucleus
instance segmentation is a key step in digital pathology analysis and
pathological diagnosis. However, the computational efficiency of the model and
the treatment of overlapping targets are the major challenges in the studies of
this problem. To this end, a neural network model RepSNet was designed based on
a nucleus boundary regression and a structural re-parameterization scheme for
segmenting and classifying the nuclei in H\&E-stained histopathological images.
First, RepSNet estimates the boundary position information (BPI) of the parent
nucleus for each pixel. The BPI estimation incorporates the local information
of the pixel and the contextual information of the parent nucleus. Then, the
nucleus boundary is estimated by aggregating the BPIs from a series of pixels
using a proposed boundary voting mechanism (BVM), and the instance segmentation
results are computed from the estimated nucleus boundary using a connected
component analysis procedure. The BVM intrinsically achieves a kind of
synergistic belief enhancement among the BPIs from various pixels. Therefore,
different from the methods available in literature that obtain nucleus
boundaries based on a direct pixel recognition scheme, RepSNet computes its
boundary decisions based on some guidances from macroscopic information using
an integration mechanism. In addition, RepSNet employs a re-parametrizable
encoder-decoder structure. This model can not only aggregate features from some
receptive fields with various scales which helps segmentation accuracy
improvement, but also reduce the parameter amount and computational burdens in
the model inference phase through the structural re-parameterization technique.
Extensive experiments demonstrated the superiorities of RepSNet compared to
several typical benchmark models.

</details>

### [278] [Benchmarking Ophthalmology Foundation Models for Clinically Significant Age Macular Degeneration Detection](https://arxiv.org/abs/2505.05291)
*Benjamin A. Cohen,Jonathan Fhima,Meishar Meisel,Baskin Meital,Luis Filipe Nakayama,Eran Berkowitz,Joachim A. Behar*

Main category: eess.IV

TLDR: 研究比较了自监督学习（SSL）预训练的ViTs在视网膜图像任务中的表现，发现自然图像预训练的模型优于领域特定模型，挑战了领域内预训练的必要性。


<details>
  <summary>Details</summary>
Motivation: 探讨在视网膜成像任务中，领域内预训练是否比自然图像预训练的模型更具优势。

Method: 在七个数字眼底图像数据集（共70,000张专家标注图像）上，对六种SSL预训练的ViTs进行基准测试，任务为识别中度至晚期年龄相关性黄斑变性（AMD）。

Result: 自然图像预训练的iBOT表现最佳（AUROC 0.80-0.97），优于领域特定模型（AUROC 0.78-0.96）和未预训练的ViT-L（AUROC 0.68-0.91）。

Conclusion: 自然图像预训练的模型在AMD识别中表现优异，挑战了领域内预训练的必要性，并发布了巴西的开放数据集BRAMD。

Abstract: Self-supervised learning (SSL) has enabled Vision Transformers (ViTs) to
learn robust representations from large-scale natural image datasets, enhancing
their generalization across domains. In retinal imaging, foundation models
pretrained on either natural or ophthalmic data have shown promise, but the
benefits of in-domain pretraining remain uncertain. To investigate this, we
benchmark six SSL-pretrained ViTs on seven digital fundus image (DFI) datasets
totaling 70,000 expert-annotated images for the task of moderate-to-late
age-related macular degeneration (AMD) identification. Our results show that
iBOT pretrained on natural images achieves the highest out-of-distribution
generalization, with AUROCs of 0.80-0.97, outperforming domain-specific models,
which achieved AUROCs of 0.78-0.96 and a baseline ViT-L with no pretraining,
which achieved AUROCs of 0.68-0.91. These findings highlight the value of
foundation models in improving AMD identification and challenge the assumption
that in-domain pretraining is necessary. Furthermore, we release BRAMD, an
open-access dataset (n=587) of DFIs with AMD labels from Brazil.

</details>

### [279] [MDAA-Diff: CT-Guided Multi-Dose Adaptive Attention Diffusion Model for PET Denoising](https://arxiv.org/abs/2505.05112)
*Xiaolong Niu,Zanting Ye,Xu Han,Yanchao Huang,Hao Sun,Hubing Wu,Lijun Lu*

Main category: eess.IV

TLDR: 提出了一种CT引导的多剂量自适应注意力去噪扩散模型（MDAA-Diff），用于低剂量PET图像去噪，结合解剖学指导和剂量适应，显著提升去噪性能。


<details>
  <summary>Details</summary>
Motivation: 高剂量放射性示踪剂会增加辐射风险，而现有研究多关注单剂量去噪，忽略了患者间剂量响应差异和CT图像的解剖学约束。

Method: 通过CT引导的高频小波注意力模块（HWA）提取解剖边界特征，并结合剂量自适应注意力模块（DAA）动态整合剂量信息。

Result: 在18F-FDG和68Ga-FAPI数据集上，MDAA-Diff在低剂量条件下优于现有方法，保持了诊断质量。

Conclusion: MDAA-Diff通过解剖学指导和剂量适应，为低剂量PET图像去噪提供了高效解决方案。

Abstract: Acquiring high-quality Positron Emission Tomography (PET) images requires
administering high-dose radiotracers, which increases radiation exposure risks.
Generating standard-dose PET (SPET) from low-dose PET (LPET) has become a
potential solution. However, previous studies have primarily focused on single
low-dose PET denoising, neglecting two critical factors: discrepancies in dose
response caused by inter-patient variability, and complementary anatomical
constraints derived from CT images. In this work, we propose a novel CT-Guided
Multi-dose Adaptive Attention Denoising Diffusion Model (MDAA-Diff) for
multi-dose PET denoising. Our approach integrates anatomical guidance and
dose-level adaptation to achieve superior denoising performance under low-dose
conditions. Specifically, this approach incorporates a CT-Guided High-frequency
Wavelet Attention (HWA) module, which uses wavelet transforms to separate
high-frequency anatomical boundary features from CT images. These extracted
features are then incorporated into PET imaging through an adaptive weighted
fusion mechanism to enhance edge details. Additionally, we propose the
Dose-Adaptive Attention (DAA) module, a dose-conditioned enhancement mechanism
that dynamically integrates dose levels into channel-spatial attention weight
calculation. Extensive experiments on 18F-FDG and 68Ga-FAPI datasets
demonstrate that MDAA-Diff outperforms state-of-the-art approaches in
preserving diagnostic quality under reduced-dose conditions. Our code is
publicly available.

</details>

### [280] [Improved Brain Tumor Detection in MRI: Fuzzy Sigmoid Convolution in Deep Learning](https://arxiv.org/abs/2505.05208)
*Muhammad Irfan,Anum Nawaz,Riku Klen,Abdulhamit Subasi,Tomi Westerlund,Wei Chen*

Main category: eess.IV

TLDR: 提出了一种基于模糊Sigmoid卷积（FSC）的轻量级深度学习模型，用于肿瘤检测，显著减少参数数量且保持高分类准确率。


<details>
  <summary>Details</summary>
Motivation: 现有卷积神经网络（CNN）在肿瘤检测中存在过参数化问题，限制了性能提升，需改进模型效率和准确性。

Method: 引入FSC及两个模块（top-of-the-funnel和middle-of-the-funnel），采用模糊Sigmoid激活函数和新型卷积算子，减少参数并增强特征提取。

Result: 在三个基准数据集上分类准确率分别达99.17%、99.75%和99.89%，参数数量比传统模型少100倍。

Conclusion: FSC模型为医学影像应用提供了高效、轻量化的深度学习解决方案，适用于早期脑肿瘤检测。

Abstract: Early detection and accurate diagnosis are essential to improving patient
outcomes. The use of convolutional neural networks (CNNs) for tumor detection
has shown promise, but existing models often suffer from overparameterization,
which limits their performance gains. In this study, fuzzy sigmoid convolution
(FSC) is introduced along with two additional modules: top-of-the-funnel and
middle-of-the-funnel. The proposed methodology significantly reduces the number
of trainable parameters without compromising classification accuracy. A novel
convolutional operator is central to this approach, effectively dilating the
receptive field while preserving input data integrity. This enables efficient
feature map reduction and enhances the model's tumor detection capability. In
the FSC-based model, fuzzy sigmoid activation functions are incorporated within
convolutional layers to improve feature extraction and classification. The
inclusion of fuzzy logic into the architecture improves its adaptability and
robustness. Extensive experiments on three benchmark datasets demonstrate the
superior performance and efficiency of the proposed model. The FSC-based
architecture achieved classification accuracies of 99.17%, 99.75%, and 99.89%
on three different datasets. The model employs 100 times fewer parameters than
large-scale transfer learning architectures, highlighting its computational
efficiency and suitability for detecting brain tumors early. This research
offers lightweight, high-performance deep-learning models for medical imaging
applications.

</details>

### [281] [White Light Specular Reflection Data Augmentation for Deep Learning Polyp Detection](https://arxiv.org/abs/2505.05248)
*Jose Angel Nuñez,Fabian Vazquez,Diego Adame,Xiaoyan Fu,Pengfei Gu,Bin Fu*

Main category: eess.IV

TLDR: 提出了一种新的数据增强方法，通过在训练图像中添加人工白光反射，以改善深度学习息肉检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习息肉检测器因误将内窥镜的白光反射识别为息肉而导致假阳性问题。

Method: 生成人工白光反射库，确定不应添加反射的区域，并使用滑动窗口方法将反射添加到合适区域以增强训练数据。

Result: 实验结果表明，新数据增强方法有效提高了息肉检测性能。

Conclusion: 通过增加模型犯错和学习的机会，新方法显著提升了深度学习息肉检测器的准确性。

Abstract: Colorectal cancer is one of the deadliest cancers today, but it can be
prevented through early detection of malignant polyps in the colon, primarily
via colonoscopies. While this method has saved many lives, human error remains
a significant challenge, as missing a polyp could have fatal consequences for
the patient. Deep learning (DL) polyp detectors offer a promising solution.
However, existing DL polyp detectors often mistake white light reflections from
the endoscope for polyps, which can lead to false positives.To address this
challenge, in this paper, we propose a novel data augmentation approach that
artificially adds more white light reflections to create harder training
scenarios. Specifically, we first generate a bank of artificial lights using
the training dataset. Then we find the regions of the training images that we
should not add these artificial lights on. Finally, we propose a sliding window
method to add the artificial light to the areas that fit of the training
images, resulting in augmented images. By providing the model with more
opportunities to make mistakes, we hypothesize that it will also have more
chances to learn from those mistakes, ultimately improving its performance in
polyp detection. Experimental results demonstrate the effectiveness of our new
data augmentation method.

</details>

### [282] [Augmented Deep Contexts for Spatially Embedded Video Coding](https://arxiv.org/abs/2505.05309)
*Yifan Bian,Chuanbo Tang,Li Li,Dong Liu*

Main category: eess.IV

TLDR: SEVC通过引入空间参考和时空上下文增强，解决了传统神经视频编码器在大运动或新物体出现时的局限性，并优化了比特分配。


<details>
  <summary>Details</summary>
Motivation: 传统神经视频编码器仅依赖时间参考，导致在大运动或新物体出现时表现不佳。

Method: 提出SEVC，结合空间和时间参考生成增强的运动向量和上下文，并引入空间引导的潜在先验和联合时空优化。

Result: SEVC有效处理大运动和新物体，比特率降低11.9%，并提供额外的低分辨率比特流。

Conclusion: SEVC通过空间嵌入和时空优化显著提升了视频编码性能。

Abstract: Most Neural Video Codecs (NVCs) only employ temporal references to generate
temporal-only contexts and latent prior. These temporal-only NVCs fail to
handle large motions or emerging objects due to limited contexts and misaligned
latent prior. To relieve the limitations, we propose a Spatially Embedded Video
Codec (SEVC), in which the low-resolution video is compressed for spatial
references. Firstly, our SEVC leverages both spatial and temporal references to
generate augmented motion vectors and hybrid spatial-temporal contexts.
Secondly, to address the misalignment issue in latent prior and enrich the
prior information, we introduce a spatial-guided latent prior augmented by
multiple temporal latent representations. At last, we design a joint
spatial-temporal optimization to learn quality-adaptive bit allocation for
spatial references, further boosting rate-distortion performance. Experimental
results show that our SEVC effectively alleviates the limitations in handling
large motions or emerging objects, and also reduces 11.9% more bitrate than the
previous state-of-the-art NVC while providing an additional low-resolution
bitstream. Our code and model are available at https://github.com/EsakaK/SEVC.

</details>

### [283] [OcularAge: A Comparative Study of Iris and Periocular Images for Pediatric Age Estimation](https://arxiv.org/abs/2505.05374)
*Naveenkumar G Venkataswamy,Poorna Ravi,Stephanie Schuckers,Masudul H. Imtiaz*

Main category: eess.IV

TLDR: 该研究比较了虹膜和眼周图像在4至16岁儿童年龄估计中的表现，使用多任务深度学习框架，发现眼周模型优于虹膜模型，平均绝对误差为1.33年。


<details>
  <summary>Details</summary>
Motivation: 儿童年龄估计因生理变化细微和纵向数据稀缺而具挑战性，现有研究多关注成人面部特征，儿童眼周和虹膜区域研究较少。

Method: 利用包含21,000多张近红外图像的纵向数据集，采用多任务深度学习框架进行年龄预测和年龄组分类。

Result: 眼周模型表现最佳，平均绝对误差1.33年，年龄组分类准确率83.82%，且模型在不同传感器上表现稳健。

Conclusion: 研究首次证明儿童眼周图像可用于可靠年龄估计，为儿童生物识别系统设计奠定了基础，并适合实时应用。

Abstract: Estimating a child's age from ocular biometric images is challenging due to
subtle physiological changes and the limited availability of longitudinal
datasets. Although most biometric age estimation studies have focused on facial
features and adult subjects, pediatric-specific analysis, particularly of the
iris and periocular regions, remains relatively unexplored. This study presents
a comparative evaluation of iris and periocular images for estimating the ages
of children aged between 4 and 16 years. We utilized a longitudinal dataset
comprising more than 21,000 near-infrared (NIR) images, collected from 288
pediatric subjects over eight years using two different imaging sensors. A
multi-task deep learning framework was employed to jointly perform age
prediction and age-group classification, enabling a systematic exploration of
how different convolutional neural network (CNN) architectures, particularly
those adapted for non-square ocular inputs, capture the complex variability
inherent in pediatric eye images. The results show that periocular models
consistently outperform iris-based models, achieving a mean absolute error
(MAE) of 1.33 years and an age-group classification accuracy of 83.82%. These
results mark the first demonstration that reliable age estimation is feasible
from children's ocular images, enabling privacy-preserving age checks in
child-centric applications. This work establishes the first longitudinal
benchmark for pediatric ocular age estimation, providing a foundation for
designing robust, child-focused biometric systems. The developed models proved
resilient across different imaging sensors, confirming their potential for
real-world deployment. They also achieved inference speeds of less than 10
milliseconds per image on resource-constrained VR headsets, demonstrating their
suitability for real-time applications.

</details>

<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [284] [Quantum-Inspired Optimization Process for Data Imputation](https://arxiv.org/abs/2505.04841)
*Nishikanta Mohanty,Bikash K. Behera,Badsah Mukherjee,Christopher Ferrie*

Main category: quant-ph

TLDR: 提出了一种基于量子启发的数据填补框架，结合PCA和量子辅助旋转，显著提升了填补效果。


<details>
  <summary>Details</summary>
Motivation: 解决数据预处理中缺失值或不可靠值的问题，特别是在医疗领域。

Method: 整合PCA与量子辅助旋转，通过无梯度优化器（COBYLA、模拟退火、差分进化）优化填补缺失值。

Result: 填补效果显著改进，Wasserstein距离平均减少85%，Kolmogorov-Smirnov检验p值优于传统方法。

Conclusion: 该方法为医疗和AI领域提供了一种高效且稳健的数据填补解决方案。

Abstract: Data imputation is a critical step in data pre-processing, particularly for
datasets with missing or unreliable values. This study introduces a novel
quantum-inspired imputation framework evaluated on the UCI Diabetes dataset,
which contains biologically implausible missing values across several clinical
features. The method integrates Principal Component Analysis (PCA) with
quantum-assisted rotations, optimized through gradient-free classical
optimizers -COBYLA, Simulated Annealing, and Differential Evolution to
reconstruct missing values while preserving statistical fidelity. Reconstructed
values are constrained within +/-2 standard deviations of original feature
distributions, avoiding unrealistic clustering around central tendencies. This
approach achieves a substantial and statistically significant improvement,
including an average reduction of over 85% in Wasserstein distance and
Kolmogorov-Smirnov test p-values between 0.18 and 0.22, compared to p-values >
0.99 in classical methods such as Mean, KNN, and MICE. The method also
eliminates zero-value artifacts and enhances the realism and variability of
imputed data. By combining quantum-inspired transformations with a scalable
classical framework, this methodology provides a robust solution for imputation
tasks in domains such as healthcare and AI pipelines, where data quality and
integrity are crucial.

</details>

### [285] [GroverGPT-2: Simulating Grover's Algorithm via Chain-of-Thought Reasoning and Quantum-Native Tokenization](https://arxiv.org/abs/2505.04880)
*Min Chen,Jinglei Cheng,Pingzhi Li,Haoran Wang,Tianlong Chen,Junyu Liu*

Main category: quant-ph

TLDR: GroverGPT-2是一种基于大语言模型（LLM）的方法，通过思维链推理和量子原生标记化模拟Grover算法，展示了经典模型可以捕捉量子算法的结构。


<details>
  <summary>Details</summary>
Motivation: 探索经典机器（如LLM）能否学习和模拟量子算法，以界定量子计算的实际优势边界。

Method: 利用GroverGPT-2，结合思维链推理和量子原生标记化，直接从量子电路表示中模拟算法，并生成结构化和可解释的输出。

Result: GroverGPT-2能够通过高效处理量子原生标记学习和内化量子电路逻辑，同时输出结合电路数据和自然语言的推理过程。

Conclusion: GroverGPT-2为量子算法的机器理解和量子电路逻辑建模提供了原型，并为未来量子计算基础模型奠定了基础。

Abstract: Quantum computing offers theoretical advantages over classical computing for
specific tasks, yet the boundary of practical quantum advantage remains an open
question. To investigate this boundary, it is crucial to understand whether,
and how, classical machines can learn and simulate quantum algorithms. Recent
progress in large language models (LLMs) has demonstrated strong reasoning
abilities, prompting exploration into their potential for this challenge. In
this work, we introduce GroverGPT-2, an LLM-based method for simulating
Grover's algorithm using Chain-of-Thought (CoT) reasoning and quantum-native
tokenization. Building on its predecessor, GroverGPT-2 performs simulation
directly from quantum circuit representations while producing logically
structured and interpretable outputs. Our results show that GroverGPT-2 can
learn and internalize quantum circuit logic through efficient processing of
quantum-native tokens, providing direct evidence that classical models like
LLMs can capture the structure of quantum algorithms. Furthermore, GroverGPT-2
outputs interleave circuit data with natural language, embedding explicit
reasoning into the simulation. This dual capability positions GroverGPT-2 as a
prototype for advancing machine understanding of quantum algorithms and
modeling quantum circuit logic. We also identify an empirical scaling law for
GroverGPT-2 with increasing qubit numbers, suggesting a path toward scalable
classical simulation. These findings open new directions for exploring the
limits of classical simulatability, enhancing quantum education and research,
and laying groundwork for future foundation models in quantum computing.

</details>

### [286] [Quantum QSAR for drug discovery](https://arxiv.org/abs/2505.04648)
*Alejandro Giraldo,Daniel Ruiz,Mariano Caruso,Guido Bellomo*

Main category: quant-ph

TLDR: 研究提出用量子支持向量机（QSVM）增强QSAR建模，以解决高维数据和复杂分子交互的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统QSAR方法在处理高维数据和复杂分子交互时存在局限性。

Method: 采用量子数据编码和量子核函数，利用量子计算原理在希尔伯特空间中处理信息。

Result: 目标是开发更准确和高效的预测模型。

Conclusion: 量子支持向量机有望提升QSAR建模的性能。

Abstract: Quantitative Structure-Activity Relationship (QSAR) modeling is key in drug
discovery, but classical methods face limitations when handling
high-dimensional data and capturing complex molecular interactions. This
research proposes enhancing QSAR techniques through Quantum Support Vector
Machines (QSVMs), which leverage quantum computing principles to process
information Hilbert spaces. By using quantum data encoding and quantum kernel
functions, we aim to develop more accurate and efficient predictive models.

</details>

### [287] [Overcoming Dimensional Factorization Limits in Discrete Diffusion Models through Quantum Joint Distribution Learning](https://arxiv.org/abs/2505.05151)
*Chuangtao Chen,Qinglin Zhao,MengChu Zhou,Zhimin He,Haozhen Situ*

Main category: quant-ph

TLDR: 论文提出了一种量子离散去噪扩散概率模型（QD3PM），通过量子计算解决经典离散扩散模型在高维分布学习中的局限性，实现了单步采样和更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 经典离散扩散模型在高维分布学习中存在计算复杂度高和KL散度线性增长的问题，需要一种更高效的方法。

Method: 提出QD3PM，利用量子贝叶斯定理推导后验状态，设计量子电路进行去噪，实现联合概率学习。

Result: 模拟结果表明，QD3PM在复杂分布建模中优于经典方法，且支持单步采样。

Conclusion: 论文通过量子优势在联合分布学习中建立了生成模型的新理论范式。

Abstract: This study explores quantum-enhanced discrete diffusion models to overcome
classical limitations in learning high-dimensional distributions. We rigorously
prove that classical discrete diffusion models, which calculate per-dimension
transition probabilities to avoid exponential computational cost, exhibit
worst-case linear scaling of Kullback-Leibler (KL) divergence with data
dimension. To address this, we propose a Quantum Discrete Denoising Diffusion
Probabilistic Model (QD3PM), which enables joint probability learning through
diffusion and denoising in exponentially large Hilbert spaces. By deriving
posterior states through quantum Bayes' theorem, similar to the crucial role of
posterior probabilities in classical diffusion models, and by learning the
joint probability, we establish a solid theoretical foundation for
quantum-enhanced diffusion models. For denoising, we design a quantum circuit
using temporal information for parameter sharing and learnable
classical-data-controlled rotations for encoding. Exploiting joint distribution
learning, our approach enables single-step sampling from pure noise,
eliminating iterative requirements of existing models. Simulations demonstrate
the proposed model's superior accuracy in modeling complex distributions
compared to factorization methods. Hence, this paper establishes a new
theoretical paradigm in generative models by leveraging the quantum advantage
in joint distribution learning.

</details>

### [288] [Operator-Level Quantum Acceleration of Non-Logconcave Sampling](https://arxiv.org/abs/2505.05301)
*Jiaqi Leng,Zhiyan Ding,Zherui Chen,Lin Lin*

Main category: quant-ph

TLDR: 论文提出了一种量子算法，用于加速非对数凹分布中的采样任务，首次证明了在非对数凹设置中量子优势。


<details>
  <summary>Details</summary>
Motivation: 解决经典方法（如Langevin动力学）在非凸势能函数下的采样性能不佳问题。

Method: 通过将目标Gibbs测度编码到量子态振幅中，利用Witten Laplacian算子的分解矩阵核实现采样。

Result: 首次在非对数凹设置中证明了量子优势，并进一步开发了加速副本交换Langevin扩散的量子算法。

Conclusion: 该量子算法为复杂能量景观下的采样提供了新的高效解决方案。

Abstract: Sampling from probability distributions of the form $\sigma \propto e^{-\beta
V}$, where $V$ is a continuous potential, is a fundamental task across physics,
chemistry, biology, computer science, and statistics. However, when $V$ is
non-convex, the resulting distribution becomes non-logconcave, and classical
methods such as Langevin dynamics often exhibit poor performance. We introduce
the first quantum algorithm that provably accelerates a broad class of
continuous-time sampling dynamics. For Langevin dynamics, our method encodes
the target Gibbs measure into the amplitudes of a quantum state, identified as
the kernel of a block matrix derived from a factorization of the Witten
Laplacian operator. This connection enables Gibbs sampling via singular value
thresholding and yields the first provable quantum advantage with respect to
the Poincar\'e constant in the non-logconcave setting. Building on this
framework, we further develop the first quantum algorithm that accelerates
replica exchange Langevin diffusion, a widely used method for sampling from
complex, rugged energy landscapes.

</details>

<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [289] [Enhancing Text2Cypher with Schema Filtering](https://arxiv.org/abs/2505.05118)
*Makbule Gulcin Ozsoy*

Main category: cs.DB

TLDR: 该论文探讨了在Text2Cypher任务中，通过模式过滤优化自然语言到Cypher查询的转换，以减少噪声和计算成本。


<details>
  <summary>Details</summary>
Motivation: 知识图谱的复杂模式可能导致噪声、幻觉和计算成本增加，因此需要一种方法来优化查询生成。

Method: 研究采用模式过滤方法，仅包含相关模式元素，分析其对令牌长度、性能和成本的影响。

Result: 结果显示模式过滤有效优化了Text2Cypher任务，尤其对小模型效果显著；大模型因上下文能力较强受益较少，但仍能降低成本。

Conclusion: 模式过滤在Text2Cypher任务中具有显著优势，尤其适用于小模型，同时对大模型也有成本优化作用。

Abstract: Knowledge graphs represent complex data using nodes, relationships, and
properties. Cypher, a powerful query language for graph databases, enables
efficient modeling and querying. Recent advancements in large language models
allow translation of natural language questions into Cypher queries -
Text2Cypher. A common approach is incorporating database schema into prompts.
However, complex schemas can introduce noise, increase hallucinations, and
raise computational costs. Schema filtering addresses these challenges by
including only relevant schema elements, improving query generation while
reducing token costs. This work explores various schema filtering methods for
Text2Cypher task and analyzes their impact on token length, performance, and
cost. Results show that schema filtering effectively optimizes Text2Cypher,
especially for smaller models. Consistent with prior research, we find that
larger models benefit less from schema filtering due to their longer context
capabilities. However, schema filtering remains valuable for both larger and
smaller models in cost reduction.

</details>

### [290] [Text2Cypher: Data Pruning using Hard Example Selection](https://arxiv.org/abs/2505.05122)
*Makbule Gulcin Ozsoy*

Main category: cs.DB

TLDR: 本文提出五种硬样本选择技术，用于修剪Text2Cypher数据集，以减少资源使用同时保持或提升性能。结果表明，这些方法可将训练时间和成本减半，且对性能影响极小。


<details>
  <summary>Details</summary>
Motivation: 随着数据集规模增加，微调成本上升，因此需要小型高质量数据集以降低成本并保持性能。

Method: 提出五种硬样本选择技术，用于修剪Text2Cypher数据集。

Result: 硬样本选择方法可将训练时间和成本减半，且对性能影响极小。

Conclusion: 硬样本选择是一种成本效益高的解决方案。

Abstract: Database query languages such as SQL for relational databases and Cypher for
graph databases have been widely adopted. Recent advancements in large language
models (LLMs) enable natural language interactions with databases through
models like Text2SQL and Text2Cypher. Fine-tuning these models typically
requires large, diverse datasets containing non-trivial examples. However, as
dataset size increases, the cost of fine-tuning also rises. This makes smaller,
high-quality datasets essential for reducing costs for the same or better
performance. In this paper, we propose five hard-example selection techniques
for pruning the Text2Cypher dataset, aiming to preserve or improve performance
while reducing resource usage. Our results show that these hard-example
selection approaches can halve training time and costs with minimal impact on
performance, and demonstrates that hard-example selection provides a
cost-effective solution.

</details>

<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [291] [High-fidelity Grain Growth Modeling: Leveraging Deep Learning for Fast Computations](https://arxiv.org/abs/2505.05354)
*Pungponhavoan Tep,Marc Bernacki*

Main category: cond-mat.mtrl-sci

TLDR: 论文提出了一种结合卷积LSTM和自动编码器的机器学习框架，用于高效预测金属材料晶粒生长，显著提升了计算速度。


<details>
  <summary>Details</summary>
Motivation: 传统基于偏微分方程的晶粒生长模拟方法计算成本高，限制了材料设计和制造效率。

Method: 采用卷积LSTM网络和自动编码器，结合复合损失函数（MSE、SSIM和边界保持），捕捉晶粒生长的时空特征。

Result: 方法将计算时间从10分钟缩短至约10秒，加速89倍，同时保持高保真预测（结构相似性86.71%，平均晶粒尺寸误差0.07%）。

Conclusion: 该框架为材料科学和制造中的快速微观结构预测提供了高效解决方案，有望加速创新。

Abstract: Grain growth simulation is crucial for predicting metallic material
microstructure evolution during annealing and resulting final mechanical
properties, but traditional partial differential equation-based methods are
computationally expensive, creating bottlenecks in materials design and
manufacturing. In this work, we introduce a machine learning framework that
combines a Convolutional Long Short-Term Memory networks with an Autoencoder to
efficiently predict grain growth evolution. Our approach captures both spatial
and temporal aspects of grain evolution while encoding high-dimensional grain
structure data into a compact latent space for pattern learning, enhanced by a
novel composite loss function combining Mean Squared Error, Structural
Similarity Index Measurement, and Boundary Preservation to maintain structural
integrity of grain boundary topology of the prediction. Results demonstrated
that our machine learning approach accelerates grain growth prediction by up to
\SI{89}{\times} faster, reducing computation time from \SI{10}{\minute} to
approximately \SI{10}{\second} while maintaining high-fidelity predictions. The
best model (S-30-30) achieving a structural similarity score of
\SI{86.71}{\percent} and mean grain size error of just \SI{0.07}{\percent}. All
models accurately captured grain boundary topology, morphology, and size
distributions. This approach enables rapid microstructural prediction for
applications where conventional simulations are prohibitively time-consuming,
potentially accelerating innovation in materials science and manufacturing.

</details>

<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [292] [Walrus: An Efficient Decentralized Storage Network](https://arxiv.org/abs/2505.05370)
*George Danezis,Giacomo Giuliari,Eleftherios Kokoris Kogias,Markus Legner,Jean-Pierre Smith,Alberto Sonnino,Karl Wüst*

Main category: cs.DC

TLDR: Walrus是一个去中心化存储系统，通过RedStuff协议和二维擦除编码技术，解决了复制开销、恢复效率和安全性之间的权衡问题，支持异步网络并高效处理节点流失。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化存储系统在复制开销、恢复效率和安全性之间存在矛盾，Walrus旨在通过技术创新解决这些问题。

Method: Walrus采用RedStuff协议（二维擦除编码）和自愈恢复机制，支持异步网络，并引入多阶段纪元变更协议处理节点流失。

Result: 实验表明，Walrus在保证高完整性和可用性的同时，实现了合理的开销，适合大规模应用。

Conclusion: Walrus通过技术创新，为去中心化应用提供了高效、安全的存储解决方案。

Abstract: Decentralized storage systems face a fundamental trade-off between
replication overhead, recovery efficiency, and security guarantees. Current
approaches either rely on full replication, incurring substantial storage
costs, or employ trivial erasure coding schemes that struggle with efficient
recovery especially under high storage-node churn. We present Walrus, a novel
decentralized blob storage system that addresses these limitations through
multiple technical innovations. At the core of Walrus is RedStuff, a
two-dimensional erasure coding protocol that achieves high security with only
4.5x replication factor, while enabling self-healing recovery that requires
bandwidth proportional to only the lost data $(O(|blob|/n)$ versus $O(|blob|)$
in traditional systems). Crucially, RedStuff is the first protocol to support
storage challenges in asynchronous networks, preventing adversaries from
exploiting network delays to pass verification without actually storing data.
Walrus also introduces a novel multi-stage epoch change protocol that
efficiently handles storage node churn while maintaining uninterrupted
availability during committee transitions. Our system incorporates
authenticated data structures to defend against malicious clients and ensures
data consistency throughout storage and retrieval processes. Experimental
evaluation demonstrates that Walrus achieves practical performance at scale,
making it suitable for a wide range of decentralized applications requiring
high-integrity, available blob storage with reasonable overhead.

</details>

<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [293] [Toward Holistic Evaluation of Recommender Systems Powered by Generative Models](https://arxiv.org/abs/2504.06667)
*Yashar Deldjoo,Nikhil Mehta,Maheswaran Sathiamoorthy,Shuai Zhang,Pablo Castells,Julian McAuley*

Main category: cs.IR

TLDR: 论文探讨了生成模型驱动的推荐系统（Gen-RecSys）的评估挑战，提出了两类问题：现有问题的加剧和新风险的出现，并提出了一种综合评估方法。


<details>
  <summary>Details</summary>
Motivation: 生成模型驱动的推荐系统在提供丰富用户体验的同时，也带来了新的风险，如虚假内容生成和隐私泄露，传统评估方法无法全面衡量这些挑战。

Method: 将评估挑战分为两类：现有问题的加剧和新风险的出现，并提出了一种结合场景评估和多指标检查的综合评估方法。

Result: 提出了一个全面的评估框架，包括相关性、事实基础、偏见检测和政策合规性等多维度指标。

Conclusion: 该框架旨在帮助研究者和从业者全面评估Gen-RecSys，确保其个性化效果和负责任的应用。

Abstract: Recommender systems powered by generative models (Gen-RecSys) extend beyond
classical item ranking by producing open-ended content, which simultaneously
unlocks richer user experiences and introduces new risks. On one hand, these
systems can enhance personalization and appeal through dynamic explanations and
multi-turn dialogues. On the other hand, they might venture into unknown
territory-hallucinating nonexistent items, amplifying bias, or leaking private
information. Traditional accuracy metrics cannot fully capture these
challenges, as they fail to measure factual correctness, content safety, or
alignment with user intent.
  This paper makes two main contributions. First, we categorize the evaluation
challenges of Gen-RecSys into two groups: (i) existing concerns that are
exacerbated by generative outputs (e.g., bias, privacy) and (ii) entirely new
risks (e.g., item hallucinations, contradictory explanations). Second, we
propose a holistic evaluation approach that includes scenario-based assessments
and multi-metric checks-incorporating relevance, factual grounding, bias
detection, and policy compliance. Our goal is to provide a guiding framework so
researchers and practitioners can thoroughly assess Gen-RecSys, ensuring
effective personalization and responsible deployment.

</details>

### [294] [QBD-RankedDataGen: Generating Custom Ranked Datasets for Improving Query-By-Document Search Using LLM-Reranking with Reduced Human Effort](https://arxiv.org/abs/2505.04732)
*Sriram Gopalakrishnan,Sunandita Patra*

Main category: cs.IR

TLDR: 论文提出了一种生成自定义QBD搜索数据集的方法（QBD-RankedDatagen），并比较了多种方法在成本、速度和与领域专家交互方面的表现，显著减少了人工工作量。


<details>
  <summary>Details</summary>
Motivation: 解决QBD问题中领域特定数据集创建成本高、耗时的问题，提升检索性能。

Method: 利用大型语言模型（LLMs）结合领域专家输入生成文档评分和排名，并优化BM25模型参数。

Result: 在TREC的QBD数据集上评估，显著减少了人工工作量，同时保持了足够的专家知识。

Conclusion: 提出的方法和流程能高效生成QBD数据集，适用于专利匹配、法律检索等任务。

Abstract: The Query-By-Document (QBD) problem is an information retrieval problem where
the query is a document, and the retrieved candidates are documents that match
the query document, often in a domain or query specific manner. This can be
crucial for tasks such as patent matching, legal or compliance case retrieval,
and academic literature review. Existing retrieval methods, including keyword
search and document embeddings, can be optimized with domain-specific datasets
to improve QBD search performance. However, creating these domain-specific
datasets is often costly and time-consuming. Our work introduces a process to
generate custom QBD-search datasets and compares a set of methods to use in
this problem, which we refer to as QBD-RankedDatagen. We provide a comparative
analysis of our proposed methods in terms of cost, speed, and the human
interface with the domain experts. The methods we compare leverage Large
Language Models (LLMs) which can incorporate domain expert input to produce
document scores and rankings, as well as explanations for human review. The
process and methods for it that we present can significantly reduce human
effort in dataset creation for custom domains while still obtaining sufficient
expert knowledge for tuning retrieval models. We evaluate our methods on QBD
datasets from the Text Retrieval Conference (TREC) and finetune the parameters
of the BM25 model -- which is used in many industrial-strength search engines
like OpenSearch -- using the generated data.

</details>

### [295] [HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights](https://arxiv.org/abs/2505.04846)
*Ozan Gokdemir,Carlo Siebenschuh,Alexander Brace,Azton Wells,Brian Hsu,Kyle Hippe,Priyanka V. Setty,Aswathy Ajith,J. Gregory Pauloski,Varuni Sastry,Sam Foreman,Huihuo Zheng,Heng Ma,Bharat Kale,Nicholas Chia,Thomas Gibbs,Michael E. Papka,Thomas Brettin,Francis J. Alexander,Anima Anandkumar,Ian Foster,Rick Stevens,Venkatram Vishwanath,Arvind Ramanathan*

Main category: cs.IR

TLDR: HiPerRAG是一种基于高性能计算的RAG工作流，用于索引和检索360万篇科学文章，显著提升了科学问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 科学文献数量激增导致发现利用率低、重复工作和跨学科合作有限，需要更高效的方法处理信息。

Method: 结合Oreo（多模态文档解析模型）和ColTrast（查询感知编码器微调算法），利用对比学习和延迟交互技术提升检索准确性。

Result: 在SciQ和PubMedQA基准测试中分别达到90%和76%的准确率，优于领域特定模型和商用LLM。

Conclusion: HiPerRAG通过高性能计算实现了大规模科学知识的统一，促进了跨学科创新。

Abstract: The volume of scientific literature is growing exponentially, leading to
underutilized discoveries, duplicated efforts, and limited cross-disciplinary
collaboration. Retrieval Augmented Generation (RAG) offers a way to assist
scientists by improving the factuality of Large Language Models (LLMs) in
processing this influx of information. However, scaling RAG to handle millions
of articles introduces significant challenges, including the high computational
costs associated with parsing documents and embedding scientific knowledge, as
well as the algorithmic complexity of aligning these representations with the
nuanced semantics of scientific content. To address these issues, we introduce
HiPerRAG, a RAG workflow powered by high performance computing (HPC) to index
and retrieve knowledge from more than 3.6 million scientific articles. At its
core are Oreo, a high-throughput model for multimodal document parsing, and
ColTrast, a query-aware encoder fine-tuning algorithm that enhances retrieval
accuracy by using contrastive learning and late-interaction techniques.
HiPerRAG delivers robust performance on existing scientific question answering
benchmarks and two new benchmarks introduced in this work, achieving 90%
accuracy on SciQ and 76% on PubMedQA-outperforming both domain-specific models
like PubMedGPT and commercial LLMs such as GPT-4. Scaling to thousands of GPUs
on the Polaris, Sunspot, and Frontier supercomputers, HiPerRAG delivers million
document-scale RAG workflows for unifying scientific knowledge and fostering
interdisciplinary innovation.

</details>

### [296] [Prompt-Based LLMs for Position Bias-Aware Reranking in Personalized Recommendations](https://arxiv.org/abs/2505.04948)
*Md Aminul Islam,Ahmed Sayeed Faruk*

Main category: cs.IR

TLDR: 论文探讨了基于大语言模型（LLM）的推荐系统在重排序任务中的局限性，并提出了一种结合传统推荐模型和LLM的混合框架。实验表明，随机化用户历史记录可提升排序质量，但LLM重排序未能超越基础模型。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在推荐系统中的局限性，如上下文窗口限制、位置偏差等，并提出解决方案。

Method: 提出混合框架，结合传统推荐模型和LLM，通过结构化提示重排序top-k项目。

Result: 实验显示随机化用户历史记录改善排序质量，但LLM重排序效果未优于基础模型，且位置偏差缓解指令无效。

Conclusion: LLM在建模排序上下文和缓解偏差方面存在局限性，需进一步研究改进。

Abstract: Recommender systems are essential for delivering personalized content across
digital platforms by modeling user preferences and behaviors. Recently, large
language models (LLMs) have been adopted for prompt-based recommendation due to
their ability to generate personalized outputs without task-specific training.
However, LLM-based methods face limitations such as limited context window
size, inefficient pointwise and pairwise prompting, and difficulty handling
listwise ranking due to token constraints. LLMs can also be sensitive to
position bias, as they may overemphasize earlier items in the prompt regardless
of their true relevance. To address and investigate these issues, we propose a
hybrid framework that combines a traditional recommendation model with an LLM
for reranking top-k items using structured prompts. We evaluate the effects of
user history reordering and instructional prompts for mitigating position bias.
Experiments on MovieLens-100K show that randomizing user history improves
ranking quality, but LLM-based reranking does not outperform the base model.
Explicit instructions to reduce position bias are also ineffective. Our
evaluations reveal limitations in LLMs' ability to model ranking context and
mitigate bias. Our code is publicly available at
https://github.com/aminul7506/LLMForReRanking.

</details>

### [297] [QBR: A Question-Bank-Based Approach to Fine-Grained Legal Knowledge Retrieval for the General Public](https://arxiv.org/abs/2505.04883)
*Mingruo Yuan,Ben Kao,Tien-Hsuan Wu*

Main category: cs.IR

TLDR: QBR方法通过问题库（QB）缩小法律知识检索中的技术鸿沟，提升检索的准确性、效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 普通公众因缺乏专业知识，难以有效检索法律知识，传统检索方法假设用户能提出精确查询，但实际存在技术内容与用户能力之间的鸿沟。

Method: 提出QBR方法，利用问题库（QB）作为知识桥梁，通过QB生成训练样本，优化文档中知识单元的嵌入，实现细粒度知识检索。

Result: 实验表明，QBR比传统方法更准确、高效、可解释，提升检索结果的理解性，并有效支持细粒度检索。案例研究显示其社会价值。

Conclusion: QBR通过问题库有效解决法律知识检索难题，具有实际应用价值和社会影响。

Abstract: Retrieval of legal knowledge by the general public is a challenging problem
due to the technicality of the professional knowledge and the lack of
fundamental understanding by laypersons on the subject. Traditional information
retrieval techniques assume that users are capable of formulating succinct and
precise queries for effective document retrieval. In practice, however, the
wide gap between the highly technical contents and untrained users makes legal
knowledge retrieval very difficult. We propose a methodology, called QBR, which
employs a Questions Bank (QB) as an effective medium for bridging the knowledge
gap. We show how the QB is used to derive training samples to enhance the
embedding of knowledge units within documents, which leads to effective
fine-grained knowledge retrieval. We discuss and evaluate through experiments
various advantages of QBR over traditional methods. These include more
accurate, efficient, and explainable document retrieval, better comprehension
of retrieval results, and highly effective fine-grained knowledge retrieval. We
also present some case studies and show that QBR achieves social impact by
assisting citizens to resolve everyday legal concerns.

</details>

<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [298] [Fairness Perceptions in Regression-based Predictive Models](https://arxiv.org/abs/2505.04886)
*Mukund Telukunta,Venkata Sriram Siddhardh Nadendla,Morgan Stuart,Casey Canfield*

Main category: cs.HC

TLDR: 论文提出了三种新的基于分歧的群体公平性概念，并通过众包反馈研究了公平性偏好，发现分离性和充分性公平性概念更受青睐。


<details>
  <summary>Details</summary>
Motivation: 现代肾脏移植中基于回归的预测分析存在训练数据带来的偏见，导致社会歧视和器官利用效率低下，但相关研究较少。

Method: 引入独立性、分离性和充分性三种公平性概念，并通过众包平台收集85名参与者的反馈，使用混合Logit离散选择模型分析公平性偏好。

Result: 研究发现分离性和充分性公平性概念更受青睐，预测分析在性别和种族上公平，但在年龄上不公平。

Conclusion: 研究为评估回归分析工具的公平性提供了新方法，并揭示了社会对公平性的偏好。

Abstract: Regression-based predictive analytics used in modern kidney transplantation
is known to inherit biases from training data. This leads to social
discrimination and inefficient organ utilization, particularly in the context
of a few social groups. Despite this concern, there is limited research on
fairness in regression and its impact on organ utilization and placement. This
paper introduces three novel divergence-based group fairness notions: (i)
independence, (ii) separation, and (iii) sufficiency to assess the fairness of
regression-based analytics tools. In addition, fairness preferences are
investigated from crowd feedback, in order to identify a socially accepted
group fairness criterion for evaluating these tools. A total of 85 participants
were recruited from the Prolific crowdsourcing platform, and a Mixed-Logit
discrete choice model was used to model fairness feedback and estimate social
fairness preferences. The findings clearly depict a strong preference towards
the separation and sufficiency fairness notions, and that the predictive
analytics is deemed fair with respect to gender and race groups, but unfair in
terms of age groups.

</details>

### [299] [Dukawalla: Voice Interfaces for Small Businesses in Africa](https://arxiv.org/abs/2505.05170)
*Elizabeth Ankrah,Stephanie Nyairo,Mercy Muchai,Kagonya Awori,Millicent Ochieng,Mark Kariuki,Jacki O'Neill*

Main category: cs.HC

TLDR: Dukawalla是一款语音交互智能助手，帮助非洲中小型企业通过生成式AI实现数据驱动的决策。


<details>
  <summary>Details</summary>
Motivation: 非洲中小型企业因缺乏适合的工具而难以进行数据驱动决策，Dukawalla旨在解决这一问题。

Method: 开发语音交互助手Dukawalla，利用生成式AI将原始数据转化为可操作洞察。

Result: 在Nairobi的中小型企业中部署Dukawalla，成功简化数据收集并提供业务洞察。

Conclusion: Dukawalla通过语音交互和AI技术，有效支持中小型企业的数据驱动决策。

Abstract: Small and medium sized businesses often struggle with data driven decision
making do to a lack of advanced analytics tools, especially in African
countries where they make up a majority of the workforce. Though many tools
exist they are not designed to fit into the ways of working of SMB workers who
are mobile first, have limited time to learn new workflows, and for whom social
and business are tightly coupled. To address this, the Dukawalla prototype was
created. This intelligent assistant bridges the gap between raw business data,
and actionable insights by leveraging voice interaction and the power of
generative AI. Dukawalla provides an intuitive way for business owners to
interact with their data, aiding in informed decision making. This paper
examines Dukawalla's deployment across SMBs in Nairobi, focusing on their
experiences using this voice based assistant to streamline data collection and
provide business insights

</details>

<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [300] [Community and hyperedge inference in multiple hypergraphs](https://arxiv.org/abs/2505.04967)
*Li Ni,Ziqi Deng,Lin Mu,Lei Zhang,Wenjian Luo,Yiwen Zhang*

Main category: cs.SI

TLDR: 该论文提出了一种基于随机块模型的超图分析方法，用于整合多个超图的信息，揭示潜在的高阶结构，并在社区检测、超边预测和超图间边预测任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的生物和社会系统通过超图表示高阶交互，但现有方法难以整合多个超图的信息以揭示其潜在结构。

Method: 提出了一种基于随机块模型的框架，引入超边内部度量化节点对超边形成的贡献，支持社区挖掘、超边预测和超图间边推断。

Result: 实验证明该模型在社区检测、超边预测和超图间边预测任务中表现优异，并能分析不同类型超图或单一超图。

Conclusion: 该模型为分析多个超图提供了实用灵活的工具，显著提升了对现实世界高阶系统组织的理解。

Abstract: Hypergraphs, capable of representing high-order interactions via hyperedges,
have become a powerful tool for modeling real-world biological and social
systems. Inherent relationships within these real-world systems, such as the
encoding relationship between genes and their protein products, drive the
establishment of interconnections between multiple hypergraphs. Here, we
demonstrate how to utilize those interconnections between multiple hypergraphs
to synthesize integrated information from multiple higher-order systems,
thereby enhancing understanding of underlying structures. We propose a model
based on the stochastic block model, which integrates information from multiple
hypergraphs to reveal latent high-order structures. Real-world hyperedges
exhibit preferential attachment, where certain nodes dominate hyperedge
formation. To characterize this phenomenon, our model introduces hyperedge
internal degree to quantify nodes' contributions to hyperedge formation. This
model is capable of mining communities, predicting missing hyperedges of
arbitrary sizes within hypergraphs, and inferring inter-hypergraph edges
between hypergraphs. We apply our model to high-order datasets to evaluate its
performance. Experimental results demonstrate strong performance of our model
in community detection, hyperedge prediction, and inter-hypergraph edge
prediction tasks. Moreover, we show that our model enables analysis of multiple
hypergraphs of different types and supports the analysis of a single hypergraph
in the absence of inter-hypergraph edges. Our work provides a practical and
flexible tool for analyzing multiple hypergraphs, greatly advancing the
understanding of the organization in real-world high-order systems.

</details>

<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [301] [Confabulation dynamics in a reservoir computer: Filling in the gaps with untrained attractors](https://arxiv.org/abs/2505.04792)
*Jack O'Hagan,Andrew Keane,Andrew Flynn*

Main category: math.DS

TLDR: 论文分析了人工神经网络（ANNs）中虚假信息生成（confabulation）的现象，特别是储层计算机（RCs）中未训练吸引子（UAs）的作用。


<details>
  <summary>Details</summary>
Motivation: 探索ANNs中虚假信息生成的机制，尤其是RCs中UAs对学习失败和吸引子重建的影响。

Method: 通过分析RCs在重建吸引子时生成UAs的行为，研究其失败原因及对模型过渡的影响。

Result: UAs是学习系统的固有特征，尤其在状态空间受限时，这种现象可能不仅限于RCs。

Conclusion: UAs是学习系统的内在特性，虚假信息生成可能广泛存在于其他系统中。

Abstract: Artificial Intelligence has advanced significantly in recent years thanks to
innovations in the design and training of artificial neural networks (ANNs).
Despite these advancements, we still understand relatively little about how
elementary forms of ANNs learn, fail to learn, and generate false information
without the intent to deceive, a phenomenon known as `confabulation'. To
provide some foundational insight, in this paper we analyse how confabulation
occurs in reservoir computers (RCs): a dynamical system in the form of an ANN.
RCs are particularly useful to study as they are known to confabulate in a
well-defined way: when RCs are trained to reconstruct the dynamics of a given
attractor, they sometimes construct an attractor that they were not trained to
construct, a so-called `untrained attractor' (UA). This paper sheds light on
the role played by UAs when reconstruction fails and their influence when
modelling transitions between reconstructed attractors. Based on our results,
we conclude that UAs are an intrinsic feature of learning systems whose state
spaces are bounded, and that this means of confabulation may be present in
systems beyond RCs.

</details>

### [302] [Learning dynamically inspired invariant subspaces for Koopman and transfer operator approximation](https://arxiv.org/abs/2505.05085)
*Gary Froyland,Kevin Kühl*

Main category: math.DS

TLDR: 论文提出了一种通过机器学习学习正交、局部支持的基函数来近似线性算子的方法，以解决从数据中高效估计转移和Koopman算子的问题。


<details>
  <summary>Details</summary>
Motivation: 转移和Koopman算子方法为复杂非线性动力系统提供了线性变换框架，但其谱的高效估计仍具挑战性。

Method: 通过机器学习学习正交、局部支持的基函数，动态适应系统特性，近似线性算子。

Result: 学习到的基函数能准确近似算子作用，并形成几乎不变的有限维子空间，成功恢复算子的谱特性。

Conclusion: 该方法通过动态适应的机器学习基函数，有效解决了算子估计问题，并展示了其适应性优势。

Abstract: Transfer and Koopman operator methods offer a framework for representing
complex, nonlinear dynamical systems via linear transformations, enabling for a
deeper understanding of the underlying dynamics. The spectrum of these
operators provide important insights into system predictability and emergent
behaviour, although efficiently estimating them from data can be challenging.
We tackle this issue through the lens of general operator and representational
learning, in which we approximate these linear operators using efficient
finite-dimensional representations. Specifically, we machine-learn orthonormal,
locally supported basis functions that are dynamically tailored to the system.
This learned basis provides a particularly accurate approximation of the
operator's action as well as a nearly invariant finite-dimensional subspace. We
illustrate our approach with examples that showcase the retrieval of spectral
properties from the estimated operator, and emphasise the dynamically adaptive
quality of the machine-learned basis.

</details>